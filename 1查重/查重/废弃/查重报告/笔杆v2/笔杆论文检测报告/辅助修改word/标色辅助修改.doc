
<html xmlns:o="urn:schemas-microsoft-com:office:office"xmlns:w="urn:schemas-microsoft-com:office:word"xmlns="http://www.w3.org/TR/REC-html40">
<body>
    <p>    摘要</p><p>    在现今社会的信息发展过程中,各种来源的数据不断累积,但是原始累积的数据往往含有脏数据,例如错误的、相似重复的和缺失的数据等,对于脏数据进行清洗的一个关键点在于去除数据集中的重复数据。</p><p>    本文主要对重复数据检测进行了研究,并做出改进与创新。相似重复记录检测是指准确检测出源数据集中的重复数据,以达到清洗数据的目的。真实情景中,数据规模庞大,数据来源多样,这都增加了重复数据检测的难度。虽然存在解决这类问题的优秀算法,例如SNM算法和MPN算法等,但是已有的算法在解决实际应用中的重复记录检测问题时,仍存在不足之处。</p><p>    本文首先研究了传统的多趟近邻排序算法,并对该算法的缺点进行改进,提出了改进的多趟近邻排序算法(OMPN),以适用于实际问题;然后,通过研究基于遗传神经网络(GA-ANN)求解重复检测问题的算法,将OMPN算法与GA-ANN相结合,得到准确度更高的A-OMPN算法和BP-OMPN算法;最后,将本文提出的OMPN算法应用于实际的&quot;航天情报信息管理系统&quot;的数据清洗模块。本文的主要内容如下:</p><p>    1.提出了基于MPN算法思想的OMPN算法。多趟近邻排序算法首先对数据集中的数据记录依据预先选取的排序关键字进行排序,使得相似重复记录排序后位置相近,然后使用滑动窗口对排序后的数据进行判等。但是,该过程需要依赖专家经验知识进行关键字的选取和判等字段的选取,同时,真实的数据可能存在数据缺失,然而,MPN算法并没有考虑这种情况。MPN算法所使用的固定大小的滑动窗口不仅会导致对重复数据的检测不全面,而且会导致对非重复数据的冗余检测。本文在多趟近邻排序算法的基础上,提出基于字段区分度的关键字选取方法,根据数据特点进行关键字的选取,同时,在判等过程中,同样根据字段区分度为字段赋予不同权值,避免人为因素;然后,使用所提出的公式计算得到滑动窗口的大小,由该公式得到的大小是不固定的,可以根据数据情况自动调整,减少了漏检记录数量和冗余操作;最后,对源数据中存在缺失值的记录进行标记和单独检测。通过实验验证,本文所提出的改进的多趟近邻排序算法具有较高的查全率,且更适用于真实问题场景。</p><p>    2.基于神经网络的多趟近邻排序算法。基于遗传神经网络进行相似重复记录检测的算法效果较好,但是该算法不仅训练过程耗时严重,而且在检测过程中存在冗余操作。本文在多趟近邻排序算法与遗传神经网络这两种算法的基础上,使用遗传神经网络对MPN算法中滑动窗口内的记录进行判等,将这个算法记作A-OMPN,使得神经网络可以仅对同一个滑动窗口内的记录进行判等,避免了传统的遗传神经网络对数据全集上的任意两个不同记录进行判等,极大地提高了算法运行效率。同时,考虑到遗传神经网络训练速度慢的缺点,本文尝试使用单一的神经网络执行判等操作,得到了基于单一神经网络的多趟近邻排序算法(A-OMPN)。实验结果表明,本文所提出的这两种算法准确度和运行效率较高。</p><p>    3.本文所提出的算法在&quot;航天情报信息管理系统&quot;中的应用。本文主要完成了该系统的数据清洗模块和APP模块的开发。在真实业务场景中,航天情报管理系统的数据清洗模块需要实现对源数据的去重和清洗,该系统所使用的数据是真实的不带标签的数据,且数据规模相对较小,综合分析OMPN算法、A-OMPN算法与A-OMPN算法的优势与适用场景,最终采用OMPN算法实现系统的数据清洗模块。<br />关键词:相似重复检测,数据清洗,多趟近邻排序,神经网络,遗传算法</p><p>    ABSTRACT</p><p>    With the development of the information technology and the information construction, the size of the data becomes larger and larger. Variety of dirty data are inevitable, such as wrong data, reduplicative data and half-baked data and so on. As a result, effective algorithms are necessary for data cleaning. The duplicate records detection problem is one of the most important problem in data cleaning.</p><p>    In this paper, we have researched and improved the algorithms for the duplicate records detection problem. The duplicate records detection problem is to find the reduplicative records for a given dataset. In real world, it&rsquo;s difficult to design effective algorithms for the problem since the large size and the different sources of the data. Although there are some algorithms for solving this problem, such as the Sorted-Neighborhood Method (SNM) and the Multi-Pass Sorted-Neighborhood Method (MPN), they all have shortcomings when tackle the real-world duplicate records detection problems.</p><p>    The effectiveness of the SNM and the MPN relies on the expert knowledge of the dataset. So it&rsquo;s hard to solve dataset with no priori knowledge. With the goal of overcoming the shortcomings of the SNM and the MPN, we proposed the Optimized Multi-Pass Sorted-Neighborhood Method (OMPN). In addition, we make a combination of the OMPN and the genetic-based artificial neural network to solve the problem and propose the Advanced Multi-Pass Sorted-Neighborhood Method (A-OMPN) and the BP network based Multi-Pass Sorted-Neighborhood Method (A-OMPN). The A-OMPN and the A-OMPN are superior to the other algorithms. Finally, we apply the proposed algorithm to the spaceflight information management system to accomplish the data-cleaning in the real-world problem. The main contributions of this paper are as follows:</p><p>    1. The Optimized Multi-Pass Sorted-Neighborhood Method (OMPN) is proposed. The MPN first sort all the records and then use a scale-fixed sliding window to check the duplicate records. However, it need the expert knowledge to select the key and to check the duplicate records in a sliding windows. In the OMPN, the field distinction degree-based method is proposed to select the key without the expert knowledge. In the meantime, the OMPN uses the scalable sliding window to make the checking process more precise. The OMPN also take the half-baked data into account by pre-label scheme. Compared with other algorithms, the OMPN performs well and it&rsquo;s suitable for solving the real-world duplicate records detection problem.</p><p>    2. The Advanced Multi-Pass Sorted-Neighborhood Method(A-OMPN) is proposed. The genetic-based artificial neural network that used to solve the problem should select two different records in the whole dataset to check whether they are duplicate or not. It&rsquo;s very time-consuming and the check stage can be simplified. The A-OMPN makes a combination of the genetic-based artificial neural network and the OMPN to select records only in a sliding windows. It can not only improve the precision ratio and the recall ratio but also reduce the runtime compared with the genetic-based artificial neural network. However, to train an appropriate genetic-based artificial neural network is still time-consuming. We also do experiments with the signal BP network and then generate the BP network based Multi-Pass Sorted-Neighborhood Method(A-OMPN). Experimental results show that the A-OMPN and the A-OMPN all perform well.</p><p>    3. We apply the proposed algorithm to the spaceflight information management system. The data cleaning module is one of the most important modules in this system. We do experiments by the OMPN, the A-OMPN and the A-OMPN with the given aerospace craft dataset. Finally, we choose the OMPN to accomplish this module.<br />Keywords: Duplicate Record Detection, Data Cleaning, Sorted-Neighborhood, Neural Network, Genetic Algorithm</p><br />第一章 绪论<br /><p>    1.1研究的背景和意义</p><p>    在现今的信息时代,形形色色的企业信息化系统应运而生,数据库的信息量也与日逐增[]。</p><p>    从规模庞大的数据库中提取重要信息,从而对企业单位的发展提供参考,为决策者提供帮助,是数据处理方面的一个重点方向。由于不可避免的人为录入错误,或者是不同的数据表示方法,抑或是从不同的数据源合并数据甚至数据存储于不同的操作系统和物理设备,都不可避免地降低了系统的数据质量,从而产生各种类型的&quot;脏数据&quot;,例如不可避免的数据重复、缺失、错误等[][]。如果这些数据不能被正确清洗,则会影响信息化系统的正确运行,使得数据中提取的信息不再可靠,为企业决策支持和商务应用带来负面影响。因此,为了确保数据的准确性、一致性,需要高效的对数据进行清洗的算法。</p><p>    最早的数据清洗过程需要大量的人为操作,所以当遇到较大规模的数据集,就会凸显出人为操作的低准确性和低效性。所以在当前数据规模急剧加大的情况下,只有借助计算机技术,数据清洗才能实现其高效性。目前的信息化清洗过程中,仍不能完全离开专家的经验、人工的操作等行为,所以研究的一个重要方向就是尽可能减少人为的参与和影响[]。</p><p>    在众多降低数据质量的原因中,最突出的一类原因是数据记录的重复,所以如何高效地检测和去除重复数据是数据清洗研究范畴的一个热点问题[][]。</p><p>    同一个实体在数据库中不同的展现形式是相似重复记录的本质,它主要会引发以下的问题[5]:<br />(1)资源浪费[5]:重复的记录需要更多的存储资源。</p><p>    (2)数据的一致性被破坏[5]:数据集中重复的记录之间可能存在互补、自相矛盾和多余等关系。它们共同对应的现实中的实体发生变化会导致这些记录中只有某个或者某些记录发生改变,而其余无法同步更新。</p><p>    对数据集检测与消除重复记录,既可以节省存储资源,又可以保证数据的一致性,是数据清洗的重要环节[6]。<br />1.2国内外研究现状</p><p>    早在上个世纪50年代,数据清洗已经开始了相关研究。现实中,数据的来源是不确定的、多种多样的,针对这些数据,对它们进行清洗是一种极其复杂的问题,在数据连接[]、数据实体识别[]、对象识别等问题上,已经存在较早的研究结果,这些数据处理的研究对于商业保险、医疗等领域来说,具有非常重大的意义。美国清除全美社会保险号数据集中的错误数据被视为数据清洗技术研究的开端[]。</p><p>    数据清洗的研究重点包括:检测重复记录、检测异常数据、有效处理缺失数据。数据仓库的出现以及数据挖掘相关技术的发展和应用,造成了多源数据进行合并容易出现大量重复数据的问题[9]。因而数据清洗领域的一个重点研究方向即为相似重复记录检测。</p><p>    在重复记录清洗方面,国外展开了大量的研究,主要的工作有两个方面&mdash;&mdash;属性匹配[]和重复检测[11]。</p><p>    相似重复记录检测领域一种主流的算法是&quot;排序/归并&quot;法,即先将数据连接成一整个数据集,之后按照某种规则进行排序,将相似重复的记录排列在附近,最后通过某种相似判断方法检测出重复的记录。最基本的算法是&quot;排序/合并&quot;算法[]。这种方法有很大的不足,许多研究人员在此基础上提出了各种各样的改进思路和算法实现,主要的改进方向包括对字段相似度匹配算法的改进和对相似记录判断方法的改进。</p><p>    用于属性匹配问题的方法主要有编辑距离算法[12]和递归属性匹配算法[10]等。</p><p>    Monge等人将数据库中的一条记录视为一个字符串,在排序和比较的时候采用优先级队列的方法,检测相似重复时则使用了基于字符串的编辑距离[]。Hernandez等提出了一种有效的MPN算法[][],该算法的操作过程是对SNM算法独立执行多次,MPN算法中的每一次近邻排序操作的关键字都是不同的,并且,检测过程中使用尺寸固定的滑动窗口,最后使用C语言重写的OPS5[]规则编程判定记录是否相似。SC Hong等提出了基于优先级队列的方式进行相似重复记录检测[]。Gianni Costa等人采用文本聚类中的增量技术将新数据划分到最近的已知重复的聚类中,解决了大文本库中的相似检测问题[]。Alfredo Ferro使用了基于q-grams的相似度衡量函数[],可以避免许多不必要的比较和判断,提高了时间效率。</p><p>    国内的针对重复数据的检测问题的研究主要是改进已有的效果较好的算法,实现对算法精度和效率的提高[]。另外还有基于N-Gram进行检测的算法[],该算法以一条数据的N-Gram值作为排序键,这种基于N-Gram的算法在对因为拼写错误而造成的重复记录进行检测时表现良好。另外,还有基于权重的检测方法[],具体实现过程是,首先按照字段的等级划分进行权重赋值,然后结合长度过滤的思路减少冗余的字段相似度计算。</p><p>    在数据清洗市场化领域,也存在着相关的可以进行数据清洗的软件,这些软件同样需要高效的算法的支持[][]。</p><p>    虽然国内外科研人员已经在重复记录检测问题上探索到了很多有效算法,但仍旧或多或少存在适用局限性或者检测效率和精度不足等问题,所以仍然有研究的价值和改进的空间。<br />1.3论文研究的主要内容</p><p>    相似重复记录检测领域的发展虽然已经取得诸多有效成果,但是还有一些不足之处,比如[4]:</p><p>    (1)检测效率与查全率存在提升空间,特别的,当数据规模非常庞大时,现有的算法尚需改进。</p><p>    (2)大多数数据清理方法具有适应局限性,只针对特定的业务场景而设计,各行业需要更加通用的相似记录检测方案。</p><p>    (3)相似重复记录检测大多基于&quot;排序/归并&quot;的思想,排序的效果以及最终归并的结果受排序关键字影响较大,尤其是当数据库排序关键字对应的字段为空或者是错误数据时,部分重复记录无法被正确的检测到,从而影响数据清洗的质量。</p><p>    在本文中,首先,针对传统的多趟近邻排序算法MPN在时间消耗和检测精度的不足,提出了改进的OMPN算法。OMPN算法有三个改进点:(1)通过统计字段区分度改善了传统的MPN算法在选择排序关键字时过于依赖专家经验的缺点;(2)通过动态调整滑动窗口大小以节约时间并减少被遗漏的重复记录;(3)通过标记排序关键字为空的记录提高算法应对缺失字段的能力,增强了鲁棒性。其次,在OMPN算法的基础上,本文使用反向传播神经网络对OMPN算法中的的滑动窗口内的记录进行判等操作。传统的基于遗传神经网络进行重复记录检测的算法时间复杂度高,该算法的判断操作是针对待处理的数据全集的,而OMPN算法将数据全集缩小至可伸缩的滑动窗口内进行判断。在本文中,将两种算法的优势相结合,提出基遗传神经网络判等的A-OMPN算法和基于BP神经网络判等的A-OMPN算法,与OMPN算法相比,这两种算法在查准率性能方面得到很大提升。<br />1.4论文结构</p><p>    论文一共分为六章,每一章的主要内容如下:</p><p>    第一章是绪论。针对数据清洗的研究展开了介绍,并介绍了相似重复记录的国内外的研究与发展现状,简单描述了论文的主要研究目的以及研究内容,展示了论文的组织架构。</p><p>    第二章介绍已存在的有关算法,首先简单介绍了衡量字段相似度的相似度检测有关算法,分析了它们各自的优缺点以及适用条件。然后介绍了最基本的近邻排序算法和多趟近邻排序算法,对算法原理、设计以及执行流程和算法的优缺点都进行了介绍。除此之外还介绍了其它常用算法包括优先级队列算法、N-Gram算法等。然后对本文用到的BP神经网络理论基础进行说明。最后介绍了在该领域中衡量算法效果的几个常用标准及其计算方法。</p><p>    第三章,首先阐述OMPN算法的创新灵感来源,然后详细介绍了OMPN的操作思路,并采用SNM算法和MPN算法作为对比,通过实验结果,证明了OMPN算法查全率较高的优势,并对算法的优缺点进行了详细分析。</p><p>    第四章首先介绍了GA-ANN算法的主要思路,通过分析该算法的优缺点,在结合OMPN算法的基础上,提出A-OMPN算法和BP-OMPN算法这两种针对OMPN算法的改进算法,详细介绍了算法思路,最后给出了详细的实验结果。</p><p>    第五章,主要介绍了航天情报信息管理系统中的数据清理模块,该模块是OMPN算法在该系统中的应用,主要内容包括数据清理模块的设计、重复记录产生的原因、OMPN算法在系统中的应用方式以及该算法对数据质量的提高等。<br /><span style='color:red;'>第六章是总结,对本文的研究内容和未来的研究方向进行了分析。</span></p><p>    Equation Section (Next)</p><br />第二章 重复记录检测相关算法概述<br /><p>    2.1相似重复记录概述</p><p>    相似重复记录是指,对于两条记录、,它们的内容相同或者相似,且都对应着同一个现实实体,则记录对互相重复[]。实际数据库中可能存在多对互为相似重复的记录,它们的存在降低了数据的质量,可能会妨碍系统的正常运行,甚至会影响企业信息管理系统的决策正确性。<br />表2.1给出了学生信息表中的相似重复记录示例:</p><p>    表2.1学生信息表中的重复记录</p><p>    Stu_ID Name Gender Brithday Date School</p><p>    1801001 Sam Water M 1993/01/02 School of Computer Science,<span style='color:red;'> Xi&rsquo;an University of Electronic Science and Technology</span></p><p>    1802002 Jack Panda Female 1990/07/20 School of Artificial Intelligence, Xi&rsquo;an University of Electronic Science and Technology</p><p>    1801003 S. Water Male 1993/1/2 Schol of Computer Science,<span style='color:red;'> Xi&rsquo;an University of Electronic Science and Technology</span></p><p>    1802004 Jack Panda Female 1990/07/20 School of Artificial Intelligence, Xi&rsquo;an University of Electronic Science and Technology</p><p>    1801005 Mr.Sam W Male 1993-01-02 College of Computer Science,<span style='color:red;'> Xi&rsquo;an University of Electronic Science and Technology</span></p><p>    表2.1展示了5条学生记录,其中Stu_ID为1802002和1802004的两条记录的所有字段内容完全一致,说明这两条记录对应现实世界中的同一个学生的信息,所以它们互为相似重复记录。表中Stu_ID为1802001、1802003、1802005的三条记录表面上内容是不一样的,它们的区别在于:Name字段值分别为&quot;Sam Water&quot;、&quot;S. Water&quot;、&quot;Mr.Sam W&quot;,是由&quot;Sam Water&quot;采用了不同的书写方式而产生的;Gender字段值&quot;Male&quot;、&quot;M&quot;则是全称和缩写的区别,均代指男性;Brithday Date字段则是使用的不同的时间格式,但它们都是代表相同的一天&quot;1993/01/02&quot;;所属学院字段中,出现了&quot;Schol&quot;这样的拼写错误;经过以上观察分析可以发现,这三条内容相似的记录同样对应同一个学生。</p><p>    有众多原因造成数据重复,包括人工操作过程中的录入错误或者管理错误造成的重复、不同来源的数据集进行合并时产生的重复、信息系统重构时新旧版本的数据库合并造成的重复等[4][19]。</p><p>    相似重复记录检测目前应用最广泛的手段是基于&quot;排序/合并&quot;的方法[11][13]:首先对包含重复记录的数据集进行排序,排序使用的关键字按照某种固定的方式(如某字段的前三个辅音字母等)从记录的相应字段中提取,排序之后相似重复的记录汇聚在相邻的位置,然后通过对相邻位置的记录进行对比判等,可以检测出相似重复记录。<br />2.2相似度匹配算法</p><p>    相似重复记录检测过程中需要对不同的记录对进行整体相似性判断,这就需要用到字段相似度匹配算法。数据库中的每条记录均由不同的字段组成,如果不同记录的字段取值十分相近,那么它们极有可能是重复的。所以,可以通过计算记录在不同字段的相似性实现检测。目前主要有两类字段相似度匹配的算法,本节分别对其进行阐述。<br />2.2.1基于单字段的相似度匹配</p><p>    基于单字段的相似度匹配算法在相似重复记录检测中的应用过程是,通过计算两条记录相同字段对应内容的相似度来衡量记录整体的相似程度。编辑距离算法[25]、S-W算法[26]、Jaro算法[27]等都是用于这类问题的有效算法。</p><p>    基于字符进行相似度匹配的编辑距离算法是1965年提出的,又名L-距离算法[]。两个字符串和的编辑距离是指:变成需要对其单个字符进行各种操作的操作数,例如插入、替换、删除等操作。编辑距离越小代表和越相似[25]。</p><p>    如图2.1所示,字符串&quot;change&quot;经过3次插入操作和一次删除操作可以变成字符串&quot;challenge&quot;,所以这两个字段的编辑距离为4。计算两个字符串间的L距离的经典解法是使用动态规划方法。L-距离算法在应对字母书写错误、缩写等场景下效果较好。</p><p>    Smith-Waterman算法(简记S-W算法)[]最早是在生物学序列比对领域被提出的,是一种用于匹配遗传序列的动态规划算法。它的主要思路是通过罚分和空位计算不同字段内容的相似度。S-W算法可以有效应对包含不正确值的相似重复记录,但处理字符串缩写、字母颠倒情况的能力较差。<br />图2.1编辑距离示意图</p><p>    Jaro算法[]由Jaro在1976年提出的基于字符串公共子集的相似度匹配算法。Jaro距离也是字符串相似度的一种评价方式,对于给定的字符串和,两者的Jaro距离如下公式(2-1)所示[27]:<br />(2-1)</p><p>    另一种Jaro-Winkler相似度匹配算法在Jaro算法的基础上,使相同的字符串的分数更高,减小了原算法对于字符距离限制的影响,提高了算法在面对较分散的长字符串时的检测准度。Jaro-Winkler距离的计算如公式(2-2)所示:<br />(2-2)</p><p>    在公式(2-2)中,是Jaro距离,可以调整前缀匹配的权值,0.25。<br />2.2.2基于多字段的相似度匹配</p><p>    基于多字段的相似度匹配算法的思想是将一条记录视为一个整体,通过计算两条记录整体上的相似度判断是否互为相似重复记录。常用的算法包括余弦相似度匹配算法、基于监督训练的机器学习方法等[28]。</p><p>    余弦相似度()[]是一种基于TF-IDF加权算法的多字段相似度匹配方法。算法的步骤如算法2.1所示:<br />算法2.1:余弦相似度匹配算法</p><p>    1.将需要匹配的字段内容进行分词,得到互相独立的单词;</p><p>    2.对每个单词分配权重,,其中单词出现的次数(词频)用表示,表示记录总数除以包含的记录个数(逆文档频率);<br />3.将待匹配的字段转化成向量和;</p><p>    4.计算向量的值:;</p><p>    5.值越接近1,则说明相似度越高,将与所给阈值相比较,判断记录的相似性。</p><p>    除此之外,机器学习领域中的分类技术可以用来检测判断重复记录[]。使用基于单个字段的相似度匹配算法进行相似重复记录检测时,拥有不同的权值的字段对记录相似与否的影响程度也不同,字段之间相似到记录整体的相似度关系是非线性的,这是一种适合使用基于训练样本的有监督学习的场景。因此,存在使用神经网络进行判定的方法,通过带标签的数据集(可以明确不同记录之间相似与否)对神经网络进行训练,然后采用训练好的网络对由记录对生成的输入向量进行计算,相当于将重复记录检测问题转化为二类分类问题,如果网络的输出的结果大于所给定的阈值,则将它们判定是重复的,否则是不重复的[29]。<br />2.3相似重复记录检测算法</p><p>    相似重复记录检测领域最直接的方法是对数据集中的数据进行一对一地判等,这种做法简单,查重效果好,但是时间复杂度为,很不高效。&quot;排序/归并&quot;是目前相似重复记录检测算法所采用的主要思想,其主要过程是:首先选取排序关键字,关键字可以使预先设定的,<span style='color:red;'>也可以按照相应算法进行计算;然后,根据关键字取值,对数据集进行排序,将相似记录汇聚到邻近位置;</span>最后,使用相似度匹配算法进行重复检测。<span style='color:red;'>常见的基于&quot;排序/归并&quot;思想算法有SNM算法(Sorted-Nighborhood Method,记为SNM)[11]、MPN算法(Multi-Pass Sorted-Neighborhood,记为MPN)[13]、PQS算法(Priority Queue Strategy,记为PQS)[16]、</span>N-Gram算法[20]等。<br />2.3.1近邻排序算法</p><p>    SNM算法的设计思路是:首先,根据数据领域的专家知识经验指定数据集排序所使用的关键字的生成方式;其次,遍历数据集对每一条记录生成排序关键字并附加到记录后,设第i条记录的排序关键字为;然后,按照记录按照各自的的完成排序,根据相似记录对应的关键字内容也相似的原理,不同的重复记录在排序完成后理论上会处于邻近的位置;最后在每一个固定尺寸的滑动窗口内,判断与当前窗口内的数据集中的每一条数据是否是重复的。SNM算法步骤如算法2.2所示:<br />算法2.2:SNM算法</p><p>    1.确认排序关键字的生成方案,滑动窗口大小为;</p><p>    2.对每条记录生成排序关键字;</p><p>    3.按照对数据集的记录进行排序(只考虑内部排序);</p><p>    4.对同一个滑动窗口内的记录进行判断。</p><p>    SNM算法的滑窗如图2.3所示:</p><p>    图2.2 SNM算法滑动窗口过程示意图</p><p>    若数据集大小为,使用SNM算法生成排序关键字过程的时间复杂度为,本文使用快速排序,其时间复杂度为,对滑动窗口内记录的判等操作具有的时间复杂度,其中为固定的窗口的尺寸。SNM算法十分简单,滑动窗口判重过程效率较高,运行速度较快。但它也存在比较明显的缺点:</p><p>    (1)过于依赖生成的排序关键字。选择不当的关键字生成方案可能导致相似重复记录相距较远,不相似的记录却处于邻近位置,这就导致算法的检测效果大打折扣。</p><p>    (2)很难选择合适的滑窗大小。若太大,虽然检测效果可能提高,但是会导致算法的运行时间增大;若太小,则检测不全,导致算法查全率下降。<br />2.3.2多趟近邻排序算法</p><p>    MPN算法改进了SNM算法。该算法的改进点在于:</p><p>    (1)对数据集互不干扰地执行多趟近邻排序算法,每一趟近邻排序的时候所选择的关键字是不相同的,并且滑动窗口的尺寸相对于传统的SNM算法所使用的滑窗尺寸可以更小。<br />(2)对执行完多趟SNM算法的结果求传递闭包。</p><p>    传递闭包的定义[]是:设是一种关系,定义在集合上,代表传递性,满足下列所有条件的关系称为的传递闭包:<br />(1);</p><p>    (2)满足性质;</p><p>    (3)如果存在集合上的关系,满足性质并且,则。</p><p>    多采用Warshall算法[]计算传递闭包,算法2.3给出了Warshall算法的伪代码:<br />算法2.3:Warshall算法</p><p>    1.W := MR</p><p>    2.FOR k:=1 to n</p><p>    FOR i :=1 to n</p><p>    FOR j :=1 to n</p><p>    3.Output W;</p><p>    MPN算法对多趟检测结果可以计算传递闭包的理论基础是相等的传递性[14]:若记录和重复,记录和重复,则和也重复。<br />MPN算法的步骤如算法2.4所示:</p><p>    算法2.4:MPN算法</p><p>    1.确认个排序关键字的生成方案,独立重复地执行步骤2~4次;</p><p>    2.对数据集生成排序关键字;</p><p>    3.按照对数据集的记录进行排序(只考虑内部排序);</p><p>    4.确定滑动窗口的大小,每次比较时将新进入窗口的记录与窗口内剩余的条记录进行相似性方面的判断得到重复记录集合;<br />5.对所得到的个集合,求传递闭包,得到最终的有重复的记录集合。</p><p>    含有两趟SNM过程的MPN算法的流程图如图2.3所示:</p><p>    图2.3 MPN算法流程图</p><p>    传递闭包的计算使得一些容易被遗漏的重复记录被检测了出来,提高了MPN算法的查全率,同时每轮SNM过程的滑动窗口也可以变得更小,缩短了滑动归并的执行时间。但是MPN算法也存在缺点:依旧没有克服SNM算法的缺点,计算传递闭包容易导致算法的误识别率上升。<br />2.3.3其它算法</p><p>    N-Gram算法是一种基于聚类思想的算法[]。N-Gram值由记录中每个单词出现的概率综合计算得出,重复记录的N-Gram值相似,算法的优势在于对常见拼写错误表现较好,例如基于N-Gram层次空间的DGHS算法效果较好[]。<br />记录、的N-Gram相似性计算方法如公式(2-3)所示[20]:</p><p>    (2-3)</p><p>    公式(2-3)中,表示记录、的N-Gram值,表示记录的所有字段组成的集合。</p><p>    另一种优先级队列算法的思想是:用含有不同重复记录簇的优先级队列来替换传统SNM算法中的滑动窗口,算法在扫描过程中,若队列中不含有当前记录则赋予其最高的优先级然后加入到队列中,如果含有该记录,则将相应的重复记录簇的优先级设为最大。采用多趟优先级队列算法进行相似重复记录检测的过程如图2.4所示[16]:<br />图2.4多趟优先队列扫描算法过程示意图</p><p>    2.4 BP神经网络理论基础</p><p>    2.4.1神经元模型</p><p>    人工神经网络简单模拟大脑处理信息的机制,它是由许多互相连接并传递信息的神经元组成的非线性处理系统[],整体表达能力强,从而可以表征真实社会中更加复杂的问题。神经网络中的一个神经元所起到的作用是接收来自其他神经元的加权输入,然后加上阈值(偏置),最后经过非线性函数的处理,得到输出结果[]。图2.5展示了一个神经元[34]:<br />图2.5神经元模型</p><p>    其中,是输入向量的第个分量,<span style='color:red;'>是第个输入分量连接到该神经元的权值,表示偏置,是加权求和操作,表示激活函数。则对于输入向量经过此神经元时,</span>得到:。许多的类似于这样的神经元则组成了人工神经网络。<br />2.4.2梯度下降法</p><p>    梯度下降法[]的主要思想是不断沿着负梯度方向进行不断的搜索的一种寻优方法。给定如公式(2-4)所示的目标函数,<span style='color:red;'>是要学习的参数,是第个输入特征向量的第个分量,,表示偏置,共有个特征上的分量。<br />(2-4)</span></p><p>    采用均方误差损失函数,如公式(2-5)所示[36],共有个训练样本,表示第个训练样本的真实类标向量,表示模型得到的对第个训练样本结果,当损失函数的值最小时,说明所训练出的模型参数最能拟合训练样本,因此求解参数的过程就是最小化损失函数[36]。<br />(2-5)</p><p>    首先按照公式(2-6)进行求导。然后,根据对参数的负梯度方向更新,如公式(2-6)所示。是梯度下降法的学习速率,一般情况下,逐渐减小,即参数在学习过程中的变化越来越小。<br />(2-6)</p><p>    (2-7)</p><p>    由公式(2-7)可以看出,对每一个参数,都需要使用全部样本来学习该参数的变化量,称作&quot;批梯度下降法&quot;。在实际操作中,由于样本个数较大,所以这种参数更新方法会使导致训练过程缓慢,难以应用于实际问题。</p><p>    为了克服批梯度下降法的缺点,出现了使用样本全集中的一个或部分样本来更新参数的方法,即随机梯度下降法和小批量梯度下降法。这样操作使得每一次并不是按照严格意义上的最优方向来更新参数,但是从整体来看,依旧是朝着负梯度的方向更新参数,这两种梯度更新方式使参数学习的速度大大提高,适用于大规模训练样本的情况。<br />2.4.3 BP网络前向传播和反向传播</p><p>    图2.6典型三层BP神经网络</p><p>    图2.6表示了3层BP网络结构,<span style='color:red;'>第一层共有个输入神经元,是输入层;中间个隐层神经元构成第二层,第三层包含个输出神经元,表示输出层[,,,]。表示第个输入节点与隐层第个节点间的权值,表示中间层第个神经元的偏置,表示中间层第个神经元与第个输出的连接权值,是偏置,表示第个输入特征值,</span>表示中间层第个的输出,<span style='color:red;'>表示第个输出位置上的输出,表示第个隐层神经元的输入,表示第个输出神经元的输入。</span></p><p>    BP网络的前向传播是指将上一层的输出与层间的对应权值相乘并求和,最终使用函数进行处理,得到下一层对应神经元的输出值,代表非线性函数。常用的非线性函数有sigmoid函数(如公式(2-8)所示)、tant函数(如公式(2-9)所示)、ReLU函数(如公式2-10所示)等[39,40,41]。<br />(2-8)</p><p>    (2-9)</p><p>    (2-10)</p><p>    如图2.6所示,前向传播过程如公式(2-11)和公<span style='color:red;'>式(2-12)所示,设使用sigmoid函数。<br />(2-11)</span></p><p>    (2-12)</p><p>    对于用于训练操作的样本,,,设神经网络得到的输出的结果为,使用均方误差损失函数,则对样本的损失函数如公式(2-13)所示,样本全集的损失函数如公式(2-14)所示,其中第一部分是在所有样本上的平均损失,第二项表示正则项,表示所有参数组成的向量,正则项可以避免过拟合。Sigmoid函数对参数求导结果如公式(2-15)所示。BP网络反向传播的目的是求得使损失函数最小时的参数,使用梯度下降法进行求解。<br />(2-13)</p><p>    (2-14)</p><p>    (2-15)</p><p>    根据链式求导法则[36],损失函数对参数和的导数分别如公式(2-16)和公式(2-17)所示。<br />(2-16)</p><p>    (2-17)</p><p>    在样本上,参数的更新如公式(2-18)所示。</p><p>    (2-18)</p><p>    BP误差反向传播算法的基本过程为:</p><p>    输入:训练集,学习率.</p><p>    输出:连接权值与偏置值确定的多层前馈神经网络.</p><p>    过程:</p><p>    初始化网络模型的所有参数;</p><p>    Repeat</p><p>    For all :</p><p>    根据当前参数执行前馈传播,计算当前样本的输出值;</p><p>    根据公式(2.17)进行反向传播,更新当前参数;</p><p>    End for</p><p>    Until 达到终止条件</p><p>    2.5本章小结</p><p>    本章首先介绍了本文主要研究内容,然后介绍了常用的基于单字段和多字段的相似度匹配算法。</p><p>    然后给出了几种不同的检测算法的过程。从算法的设计原理、实现步骤、优缺点等对SNM算法、MPN算法等进行了介绍说明。</p><p>    最后介绍了基于神经网络进行相似重复记录检测的理论基础,包括神经元模型、梯度下降法、BP网络的传播过程。<br />Equation Section (Next)</p><br />第三章 改进的OMPN算法<br /><p>    MPN算法基于SNM思想,通过计算每趟近邻排序算法重复检测结果的传递闭包,实现了更好的检测效果。它能够以更小的滑动窗口进行重复检测,并且通过计算传递闭包可以检测到一些人工难以发现的重复记录。</p><p>    但是MPN算法并没有克服SNM算法在选取排序关键字时过于依赖专家经验的缺陷,同时,如果某一条记录的排序关键字字段为缺失值时,MPN算法的检测效果很差。基于MPN算法的不足,本文在MPN算法基础上提出了一种优化的MPN算法(Optimized Multi-Pass Sorted Neighbothood,OMPN)。OMPN对MPN的改进在于三个方面,首先,OMPN采用基于统计规律的提取关键字的关键字选取方法;其次,OMPN采用动态可伸缩的自适应滑动窗口;最后,OMPN增加了对排序关键字有缺失的记录的特殊处理。<br />3.1基于字段区分度提取关键字的方法</p><p>    3.1.1传统的提取关键字的方法</p><p>    使用&quot;排序/合并&quot;思路进行检测的算法都需要预先提取排序关键字,然后依据提取关键字实现记录的排序[]。在完全理想的状态下,重复记录排序后会汇聚到邻近的位置,从而可以缩小检测范围,在小范围内进行检测,提高准确度。</p><p>    在相似重复记录检测问题上,排序关键字是指,从记录中提取出来的不同属性组成的序列或者属性的字符串子集[]。对于SNM和MPN这两个算法,关键字的选取十分关键,数据集中的记录的排序主要依赖于所选取的关键字,只有选择了恰当的关键字,才能保证排序后的重复记录聚集在相邻的位置,进而保证重复记录能够被一个滑动窗口所覆盖,从而准确地检测到重复记录。一方面,准确的排序关键字可以保证较小的滑动窗口就具有较大的检测准确度,另一方面,准确的排序关键字会使得不同的记录经排序后处于较远的位置,从而可以避免无意义的判等比较,节约检测时间。综合来看,排序关键字的选择不仅影响了算法的整体重复检测效果,还影响了算法的时间运行效率。</p><p>    排序关键字的选取方式不是唯一的,SNM和MPN这两个算法都需要根据专家经验,人为地为待处理的数据集提取准确的排序关键字,这也是这类算法的一个缺点。所以,针对特定的数据集,准确地选取合适的排序关键字,才能达到准确检测重复记录的目的,接下来,通过表3.1所示的内容说明排序关键字的选取对重复记录检测的影响。<br />表3.1四条相似重复记录的例子</p><p>    Record First Name Last Name Address ID</p><p>    Jack Stolfo 123 First Street 12345678</p><p>    Jack Stolfo 123 First Street 12345673</p><p>    Jack Stolpho 123 First Street 12345678</p><p>    Jacon Stiles 123 Forest Street 12345432</p><p>    表3.1列举了四条记录、、和,它们由四个字段组成,分别是First Name、Last Name、Address和ID,其中,、、互为重复记录,与其他记录不同。记录和的First Name、Last Name和Address字段都完全一致,ID字段因人为录入或印刷错误而不同,但是他们是重复字段。和的Last Name字段不一致,这也是由于人为错误导致的。而和的Last Name字段完全不一致,而且两者的Address字段的取值也相差甚远,它们对应着不同的实体。相似重复检测算法就是要从已有的脏数据集中,检测并去除有重复的记录,例如,对于表3.1所示的4条记录,就需要算法准确得到的结果。</p><p>    对于表3.1所示的数据,依据传统的关键字选取方法,因为主要依赖专家经验,容易因人而异,本文列举三种不同的排序关键字选取方式,然后,详细阐述每种选取方法所得到的排序关键字,并分析不同的排序关键字对检测结果的影响。<br />方式1、排序关键字的构成包含以下几个部分:</p><p>    (1)Last Name的所有部分</p><p>    (2)Address的数字部分加字母部分的前三个辅音字母</p><p>    (3)ID的前三个连续数字</p><p>    方式2、排序关键字的构成包含以下几个部分:</p><p>    (1)Last Name的前三个辅音字母</p><p>    (2)First Name的前三个连续字母</p><p>    (3)Address的数字部分加字母部分的前三个辅音字母</p><p>    (4)ID的前三个连续数字</p><p>    方式3、排序关键字的构成包含以下几个部分:</p><p>    (1)Last Name的前三个辅音字母</p><p>    (2)First Name的前三个辅音字母</p><p>    (3)Address的数字部分加字母部分的前三个辅音字母</p><p>    (4)ID的前三个连续数字</p><p>    由方式1、方式2和方式3得到的针对表3.1所示数据的排序关键字分别如表3.2-表3.4所示。<br />表3.2相似重复记录及其生成的关键字</p><p>    Record First Name Last Name Address ID Key</p><p>    Jack Stolfo 123 First Street 12345678 STOLFO123FRT123</p><p>    Jack Stolfo 123 First Street 12345673 STOLFO123FRT123</p><p>    Jack Stolpho 123 First Street 12345678 STOLPHO123FRT123</p><p>    Jacon Stiles 123 Forest Street 12345432 STILES123FRT123<br />表3.3相似重复记录及其生成的关键字</p><p>    Record First Name Last Name Address ID Key</p><p>    Jack Stolfo 123 First Street 12345678 STLJAC123FRT213</p><p>    Jack Stolfo 123 First Street 12345673 STLJAC123FRT123</p><p>    Jack Stolpho 123 First Street 12345678 STLJAC123FRT123</p><p>    Jacon Stiles 123 Forest Street 12345432 STLJAC123FRT123<br />表3.4相似重复记录及其生成的关键字</p><p>    Record First Name Last Name Address ID Key</p><p>    Jack Stolfo 123 First Street 12345678 STLJCK123FRT213</p><p>    Jack Stolfo 123 First Street 12345673 STLJCK123FRT123</p><p>    Jack Stolpho 123 First Street 12345678 STLJCK123FRT123</p><p>    Jacon Stiles 123 Forest Street 12345432 STLJCN123FRT123</p><p>    由表3.2可以看出,记录和对应的关键字相同,均为&quot;STOLFO123FRT123&quot;,记录和对应的关键字不同,经过排序后和会聚集在邻近位置,而和则不会处于邻近的位置。对于记录和,它们原本是相同的记录,但是依据这种方式对它们所选取的排序关键字是不同的,所以将导致无法准确地检测出记录和是一对重复记录。</p><p>    由表3.3可以看出,按照方式2对4条记录所选取的排序关键字均为&quot;STLJAC123FRT213&quot;,然而从表3.1和表3.3可以看出:和具有相同排序关键字是合理的;和对应的现实实体是一致的,选择辅音字母可以一定程度上克服发音上的错误,因此,和具有相同的的Key值也是合理的;然而,和则是对应着现实世界的两个不同的实体,由于&quot;Stolfo&quot;和&quot;Stiles&quot;的连续的三个辅音字母都是&quot;STL&quot;,&quot;Forest&quot;和&quot;First&quot;的前三个连续的辅音字母都是&quot;FRT&quot;,并且关键字段中所选取的ID也是相同的,所以导致和具有相同的排序关键字,经排序后,和将会与、、处于近邻的位置,从而会导致额外的判等计算,甚至可能导致将与、、判定为重复记录,产生错误的识别结果,从而影响算法的准确性。</p><p>    由表3.4可以看出,、、的排序关键字相同,它们对应的现实实体也是一致的,和则对应不同的排序关键字,这说明所选取的排序关键字可以有效地将重复数据聚集,将不同数据隔离,因此,这是针对该数据集的理想的排序关键字选取方式。</p><p>    通过以上分析可以发现,排序关键字的选取对这类基于&quot;归并/排序&quot;思想的算法的影响较大。因此需要有一种准确的、不受人为干扰的、基于数据特征的关键字选取方法。<br />3.1.2改进的字段区分度方法</p><p>    衡量排序关键字优劣的一条重要的原则是,不同的记录对应的关键字不同,相同的记录对应的关键字理应相似或一致[19]。对于真实重复的记录,无论排序关键字以何种方式选取,理论上会得到相同或近似相同的排序关键字值,所以衡量排序关键字最关键的标准是它们在区分不同记录时的表现,即对应着现实世界中不同实体的两条记录在合适的排序关键字方案下生成的排序关键字值应当不一致。所以在选择排序关键字时,应当选择有足够区分度的字段来提取关键字。为定量地衡量关键字的区分不同记录的能力,本文提出了&quot;字段区分度&quot;的概念。</p><p>    字段区分度:字段区分数据库中不同记录的能力,某一字段取不同值的记录个数越多,该字段的字段区分度越大。</p><p>    设数据库中一共有条记录,每条记录都个字段组成,即,对于第个字段,的区分度由公式(3-1)得到:<br />(3-1)</p><p>    其中,代表数据集中在字段一共有种取值,即如果将数据集按照字段的不同取值进行聚类,一共有簇。是一个0-1的小数,值越大,说明对应的字段对于整体数据集的区分能力越大。</p><p>    通过计算字段区分度,可以有效地衡量不同字段对整体数据集的区分能力,这是因为,相似重复记录在每个字段的内容理论上是相等的,由于印刷错误、格式不一致、人工录入等导致部分相似重复记录在某个字段表现不一致的情况在数据集中只占有较小的比例,因此,无论数据集中的重复数据所占的比例是多少,对数据集具有较大区分能力的字段的&quot;字段区分度&quot;值也较大。基于字段区分度的排序关键字选取方法的主要操作过程如算法3.1:<br />算法3.1:基于字段区分度的排序关键字选取算法</p><p>    1.读取数据集,得到待检测的数据;</p><p>    2.计算数据集字段的字段区分度并排序;</p><p>    3.确定排序关键字由个组成部分,以及每个部分的生成方案;</p><p>    4.对数据集中的每条记录优先选取区分度较大的字段,按照生成有个组成部分的排序关键字;</p><p>    本文提出的基于字段区分度的关键字选择方法,依靠已知数据集的统计特性进行关键字选择,克服了MPN算法依赖专家经验进行人工选择排序关键字的缺陷,同时,对于未知类型的数据集,人工选择关键字往往不能准确把握该类数据集的特征,人为因素对算法效果的干扰较大,而基于字段区分度的方法从统计角度出发,更能挖掘数据本身的特性和规律,人为因素影响较小。因此,在没有人工参与或者较少人工参与选取排序关键字的情况下,基于字段区分度选择排序关键字的方法更有利于在排序后将对应着不同实体的记录区分开,将对应着相同实体的重复记录聚集到相邻位置,从而提高了算法的普适性。</p><p>    &quot;排序/归并&quot;类算法在滑动窗口判重过程中,需要对邻近位置的记录进行相似判断,传统的MPN算法采用的是基于专家经验知识的规则产生式系统(OPS5),这种做法依赖人工操作,适用范围较为局限。本文在提出字段区分度的基础上,进一步提出了基于字段区分度加权的判等方法,在判等过程中,为区分度高的字段分配更大的权值,采用L距离衡量不同记录的字段的相似度。对两条记录、(均包含个字段)进行基于字段区分度加权判等的具体操作过程为:<br />(1)对于记录记录、,计算它们之间的在每一个字段下的编辑距离;</p><p>    (2)按照字段区分度由小到大,对字段进行排序,并对记录的编辑距离根据字段的相应位置进行调整,得到记录、的调整后的编辑距离向量;<br />(3)按照公式(3-2)计算赋给第个字段的权值;</p><p>    (3-2)</p><p>    (4)按照公式(3-3)计算记录、的相似度;</p><p>    (3-3)</p><p>    (5)将和阈值进行比较,若,则判定为重复,否则为非重复。</p><p>    算法3.2给出了对待判定的记录集进行判等操作的步骤。</p><p>    算法3.2:基于字段区分度的加权判等算法</p><p>    1.设记录集合中不同的两个记录和,计算记录和的编辑距离向量;</p><p>    2.根据字段区分度对中的元素进行位置调整;</p><p>    3.根据公式(3-2)计算每个字段的;</p><p>    4.计算和的相似度;</p><p>    5.将与给定阈值进行判断;</p><p>    6.对数据集中任意两个不同的记录执行步骤1-5,完成对数据全集的判等操作。<br />3.2自适应大小的滑动窗口检测方法</p><p>    MPN算法和SNM算法采用相同的滑动窗口选择方法。算法在操作过程中所采用的滑动窗口的大小都是一个固定值,记窗口大小为,本文在此基础上,提出了自适应大小的滑动窗口方法。<br />3.2.1传统的滑动窗口检测方法</p><p>    给定大小固定为的滑动窗口,首先,将数据集中的所有记录合并成一个线性序列,然后,从窗口内的首条记录开始,每次向下滑动一条记录,每当滑动到一条新纪录时,移除原来窗口中的第一个记录,始终维持窗口内有条记录,直到数据集中的最后一条记录进入窗口内。</p><p>    基于滑动窗口进行重复记录检测的主要操作过程为:初始时,取得滑动窗口内的所有条记录,将这条记录两两之间进行判断,检测它们的重复性;然后,滑动窗口每次滑动所访问到的最新的一条记录分别与之前的条记录进行比较,判断与这条记录中的任意一条是否相同。<br />图3.1是固定尺寸的滑动窗口扫描过程。</p><p>    图3.1滑动窗口扫描过程</p><p>    基于固定大小的滑动窗口检测方法需要提前设定窗口大小,所以人为因素干扰较大,其次,算法效果对窗口尺寸的依赖十分严重,同时,滑窗尺寸为时,这种检测过程具有的时间复杂度,所以,较大的滑窗会使算法运行变慢,较小的滑窗又会降低算法检测的精度。</p><p>    图3.2给出了不同窗口大小时的检测结果示意图。在图3.2中,record0_origin和record2_origin是两条不重复的原始记录,record0_dup0、record0_dup1、record0_dup2是与record0_origin重复的原始记录,分别用标号(1)-(5)简单标记这些记录。</p><p>    图3.2中分别展示了两种大小的滑动窗口,一种窗口大小为2,一种窗口大小为5。若滑动窗口的大小为2,按照传统的滑动窗口归并方法,无法检测到记录(4)与记录(1)、记录(2)是重复记录;若滑动窗口的大小为,虽然此时能够完成争取的检测,但是检测时间是第一种检测时间的2.5倍。</p><p>    通过观察可以得到,记录(1)、记录(2)相邻且是重复记录,所以应当采用较大的滑动窗口,以对尽可能多的记录进行检测,而当窗口移动到记录(3)、(4)、(5)位置的时候,这些记录互相不重复,较大的滑动窗口只会产生时间上的浪费,所以适合采用较小的滑动窗口进行检测,既不会降低检测精度,又可以节约时间。通过以上分析可以得出,SNM和MPN所采用的固定大小的滑动窗口方式仍有较大的优化空间,一个较为合理的滑动窗口检测方案应当可以根据数据内容动态变化滑动窗口的大小,以减小算法复杂度。<br />图3.2不同滑动窗口大小时的归并过程</p><p>    3.2.2改进的自适应大小的滑动窗口</p><p>    为了克服固定尺寸的滑窗的缺陷,本文提出了自适应大小的滑动窗口检测方法。</p><p>    滑动窗口的大小可以根据当前滑动窗口的数据重复情况而做出动态地调整,当窗口内的数据重复度比较高时,证明当前窗口正处于重复记录比较集中的位置附近,而且重复记录的数量可能更多,所以为了实现更精准的检测,应当扩大窗口尺寸以使得窗口包含更多的记录,对更多的记录进行检测;反之,如果滑动窗口内的数据集重复度比较低,即相似重复数据较少,则说明当前位置附近的数据之间可能互相不重复,会存在冗余的检测过程,所以如果窗口较大,就会造成这些互不重复的数据需要不断与新进入窗口的数据进行重复性检测之后才能退出滑动窗口,导致运行时间的增加,所以这时应当减小滑动窗口的大小。</p><p>    现有的自适应窗口算法[]大多是统计出当前滑动窗口内的所有的重复记录数,依据重复数据的个数占滑动窗口的大小来决定当前窗口的尺寸变化,此类方式存在很大的弊端:原本MPN的归并过程的时间复杂度只有,其中是滑动窗口的大小,是待检测的相似重复记录集合中记录的条数,但是这种方法每次要对窗口内的记录进行一对一的重复检测,使得时间复杂度升高到。</p><p>    考虑到MPN原本在滑动窗口内的比较是将新进入的一条记录与窗口内仍保留的-1条记录进行比较,当重复度较高的时候,下一次比较应当保证的是新进入的记录应该能够尽可能的照顾到即将要离开的记录,才能保证检测效果。也就是说,在当前滑动窗口内,即将离开滑动窗口的记录若和新进入的元素是相似重复记录,这时应当扩大窗口尺寸。设窗口内的重复记录在窗口内的位置依次为0、1、2...-1,其中-1是刚滑入的数据,0号位置的记录是即将被滑出的记录,则越是靠近0号位置的数据对于滑动窗口的尺寸影响越大。本文提出了动态计算滑动窗口大小的计算公式,如公式(3-2)所示:<br />(3-4)</p><p>    公式(3-2)中,常数表示滑动窗口的大小可以取的最大值,常数表示滑动窗口的最小尺寸,表示当前滑动窗口的大小,表示即将滑出滑动窗口的记录在数据集中的索引位置,代表数据集中索引为的记录是否与位置的记录互为重复,若它们重复,则=1,否则=0。通过分析公式(3-2)得到,若内的记录都是重复的,则滑动窗口大小更新为最大值,相反,若内的记录互不重复,则滑动窗口大小更新为最小值;并且距离越远位置的记录对下一个滑动窗口大小的影响越大(当其与位置的记录互为重复记录时)。<br />图3.3自适应大小的滑动窗口</p><p>    图3.3展示了自适应大小的滑动窗口检测过程,在图3.3中,R0、R0_0、R0_1、R0_2、R0_3、R0_4互相之间分别都是对方的重复的记录,记录R0、R1、R2、R3互不重复。滑动窗口内的归并过程从左向右进行。设定最大窗口为5,最小窗口为3,①表示初始时,滑动窗口大小为4;由公式(3-2)计算得到第②步所采用的滑动窗口大小变为5,因为此时窗口内的记录和R0_2全部重复,所以第②步的窗口大小被扩大;然后由公式(3-2)计算得到第③步窗口大小取最小值3,因为此时滑动窗口内的数据和R1互不重复,所以窗口大小被缩小;同理得到第④⑤⑥的滑窗大小。图3.3简明生动地表现了自适应滑动窗口的变化过程,展现了OMPN算法所使用的自适应大小的滑动窗口检测方法的优势。<br />3.3基于预标记处理排序关键字不完整的方法</p><p>    3.3.1 MPN排序方法的缺陷</p><p>    由于待清洗的数据集本身的数据质量并不高,所以记录中可能存在字段为空或者字段不完整的情况,表3.5给出了一种数据缺失情况的示例。<br />表3.5缺失数据及不完整数据示例</p><p>    Record First Name Last Name Address ID</p><p>    Jack tolfo 123 First Street 12345678<br />Jack 123 First Street 12345673</p><p>    Jack Stolpho 123 First Street 12345678</p><p>    Jacon Stiles 123 Forest Street 12345432</p><p>    在表3.5中,记录R1的Last Name字段原本应该是&quot;Stolfo&quot;,出现字段不完整而变成&quot;Sto&quot;,在生成排序关键字时若采用3.1.1中的第3种方式,即提取Last Name的前三个辅音字母是则只能得到&quot;s&quot;和&quot;t&quot;两个字母,则排序关键字位数少了一位,所以生成的关键字为&quot;TLFJCK123FRT213&quot;。记录R2的Last Name字段则直接完全缺失,所以提取的关键字为&quot;JCK123FRT213&quot;,在排序的过程中,本来属于重复记录的R1和R2由于排序关键字的首字母的差异而无法聚集在近邻的位置,使得被检测为互为重复记录的概率减小。</p><p>    传统的MPN算法在处理这种带有不完整数据和缺失数据的数据集时,就会遇到这种问题,从而使检测精度降低。为了克服这一缺点,本文提出了针对排序关键字不完整的改进方法,详细介绍在3.3.2节。<br />3.3.2改进的基于预标记的方法</p><p>    缺失数据的处理是数据清洗的另一个分支研究领域,面对缺失值常见的做法主要有三种[]:<br />(1)使用缺失数据的一些统计计算结果进行填充;</p><p>    (2)根据业务和经验选择合适的值进行填充;</p><p>    (3)从本数据集或者其他来源的数据集推测出来。</p><p>    其中第(1)种做法填充结果不够精细甚至过于粗糙,对检测结果可能造成负面影响;第(2)种做法填充结果可能较为准确但是需要人工干预,工作量较大;第(3)种做法对数据集的数据质量要求较高并且能达到的效果下限很低,因此,这几种处理缺失值的方法不能较好的适用于相似重复记录检测问题。</p><p>    针对相似重复数据检测问题,考虑到不完整数据和缺失数据会造成记录的排序关键字缺失或不完整,进而会对记录排序后的位置产生影响,所以本文针对缺失数据使用&quot;标记处理法&quot;,该方法的主要操作过程为:<br />(1)对所有关键字不完整的记录的ID进行标记;</p><p>    (2)从数据全集中去除第(1)步所标记的数据,只对排序关键字完整的记录进行排序和归并;</p><p>    (3)处理被标记的带有缺失值的记录,分别对这些记录进行检测,将其一一聚类到第(2)步得到的重复数据簇中。</p><p>    本文这种基于预标记处理缺失值做法能弥补MPN算法在排序关键字缺失的情况检测效果差的缺点,同时,对于对含有缺失字段的记录占数据集比例较低的数据集合进行操作时,时间耗费在合理的范围内,在真实数据集中,缺失值往往只占有较小的比例,因此该方法是可行的。<br />3.4 OMPN算法设计</p><p>    3.4.1算法流程设计</p><p>    结合3.1~3.3的内容可以看出,OMPN算法的改进思想在于以下三点:</p><p>    (1)基于字段区分度选取排序关键字,避免了对专家经验的依赖性。</p><p>    (2)采用可伸缩的滑动窗口检测方法,根据数据特点动态调整检测窗的大小,减少不必要的比较次数。<br />(3)预标记含有不完整排序关键字的记录,更适用于真实应用场景。</p><p>    有趟SNM过程的OMPN算法步骤如算法3.3所示:</p><p>    算法3.3:OMPN算法</p><p>    1.读取数据集,得到待检测的数据;</p><p>    2.计算数据集字段的字段区分度并排序;</p><p>    3.优先选取区分度较大的字段去生成组排序关键字;</p><p>    4.独立地执行步骤5~8次;</p><p>    5.按照排序关键字的产生方式对每条记录提取其排序关键字;</p><p>    6.对数据集按照关键字排序,如果某条记录的不完整或者为空则将该记录的ID加入到缺失关键字记录集合中,完整则正常排序;<br />7.进行可伸缩大小的滑动窗口重复检测得到重复集合;</p><p>    8.将与进行重复归并,然后计算此集合的传递闭包;</p><p>    9.将次SNM重复检测得到的集合进行归并,然后计算传递闭包得到最终的重复记录集合。<br />含有两趟SNM过程的OMPN算法流程如图3.4所示:</p><p>    图3.4含有2趟SNM过程的OMPN算法流程图</p><p>    3.4.2时间复杂度分析</p><p>    OMPN算法是在MPN算法的基础上进行的改进与创新,因此主要对这两种算法的时间复杂度进行分析。同时,理想状态下所有的数据都可以在内存中处理,不考虑磁盘I/O的情况。</p><p>    设是记录总个数,是滑动窗口尺寸,MPN算法首先创造排序关键字需要对数据集进行整体遍历,所以该阶段的时间复杂度为;排序过程采用快速排序,算法时间复杂度为;滑动窗口的归并检测过程需要进行次比较,所以产生的时间复杂度;在传递闭包的计算过程中,假设得到的记录有重复的数据集的大小为,则该阶段具有的时间复杂度。所以对于MPN算法来说,总的时间复杂度为:<br />(3-5)</p><p>    由公式(3-3)可以看出,OMPN算法首先需要对数据集中的所有字段进行区分度统计,假设每条记录的字段总数为,则区分度统计阶段的时间复杂度为;生成排序关键字过程、排序过程、以及滑动窗口归并过程与MPN算法的时间复杂度相同,分别为、、;设因为排序关键字为空而被标注的数据集包含记录数为,则与已检测识别出的数据集进行重复记录检测过程的时间复杂度为;传递闭包过程中的时间复杂度同理为,为检测结束后重复记录集合的大小。所以OMPN算法的时间复杂度为(一般情况下带有不完整排序关键字的记录数满足&gt;k并且&gt;):<br />(3-6)</p><p>    观察公式(3-3)和公式(3-4)组成部分可以发现,两者复杂度在同一数量级,所以两者的时间复杂度在特定的数据集上是一致的。若用代表常数,两个公式都可以简化成下面的式子:<br />(3-7)</p><p>    当重复记录较多时,即的值较大,此时,MPN和OMPN的时间复杂度都变为,这体现出了MPN算法和OMPN算法的时间消耗受重复数据比例的影响均较大。<br />3.5 SNM、MPN、OMPN综合对比实验</p><p>    3.5.1实验数据介绍</p><p>    为了方便研究使用,本文实验采用的数据集是由第三方的数据生成器&quot;febrl&quot;[](开源地址:https://sourceforge.net/projects/febrl/)生成的。&quot;febrl&quot;的数据源是澳大利亚某卫生部门的数据库。生成数据集中记录包含的字段及字段含义如下表所示:<br />表3.6记录字段说明</p><p>    字段名称字段描述举例1举例2</p><p>    rec_id 记录ID rec-454-org rec-454-dup-0<br />culture 文化 pak pak</p><p>    sex 性别 f f</p><p>    age 年龄3030</p><p>    date_of_birth 出生日期1987022119870221<br />title 头衔 hon hon</p><p>    given_name 名字 sophie sophie</p><p>    surname 姓氏 bozdar bozdaa</p><p>    state 州</p><p>    suburb 郊区 holsworthy holsworthy</p><p>    postcode 邮编</p><p>    street_number 街道号码4646</p><p>    address_1地址1 thurgood court thurgood court <br />address_2地址2</p><p>    phone_number 电话号码08421674140842167414<br />soc_sec_id 社保ID 3920942</p><p>    采用数据生成器的好处在于:生成器公开的接口中提供了多个参数,这些参数能够方便用户自定义数据集的大小、重复比例、字段特征、错误类型、重复记录的概率分布等,由该生成器得到的数据集非常接近现实数据;相较于真实数据,生成的数据记录拥有唯一的标识符,更方便后期对算法的查准率、查全率等进行计算和评估。<br />&quot;febrl&quot;的公开参数列表及其说明如下表所示:</p><p>    表3.7 febrl公开接口的参数说明</p><p>    参数名称参数说明</p><p>    outputFileName 输出文件名(.CSV格式)</p><p>    numberOfOriginalRecords 原始数据集大小</p><p>    numberOfDupRecords 由原始数据集生成的重复数据集大小</p><p>    maxNumOfDupPerRec 一条原始记录能够最多生成的重复记录个数<br />maxNumOfModPerRec 一个字段最多可修改数目</p><p>    maxNumOfModPerRec 一条记录最多可修改字段数目</p><p>    probabilityOfDup 重复记录在数据集中的概率分布</p><p>    (均匀分布、泊松分布或齐夫分布)</p><p>    typeOfModification 字段可能发生的错误类型(typo:印刷错误、ocr:<br />扫描错误、phonetic:发音错误或者以上所有)</p><p>    3.5.2算法的评价指标</p><p>    <span style='color:red;'>针对相似重复记录检测问题,常用的评价指标有查全率(记作:recall)、查准率(记作:precision)以及F-measure[13][14]。</span></p><p>    将算法的重复记录检测结果与实际数据集重复记录进行比较时,会出现以下四种可能的情况:</p><p>    (1)True Positive(TP):算法判定为重复记录,实际上也是重复记录;</p><p>    (2)False Positive(FP):算法判定为重复记录,但实际不是重复记录;</p><p>    (3)True Negative(TN):算法判定为非重复记录,实际也不是重复记录;</p><p>    (4)False Negative(FN):算法判定为非重复记录,但实际上却是重复记录。</p><p>    查全率(recall)代表了算法检测重复记录是否完备的能力,它的计算方法是算法检测出的正确重复数除以实际数据集中的重复记录总数,如公式(3-6)所示:<br />(3-8)</p><p>    查准率(precision)代表了算法正确识别重复记录的能力,它的计算方法是算法检测出的正确重复数除以被算法识别为重复记录的总数,如公式(3-7)所示:<br />(3-9)</p><p>    F-measure的计算公式如(3-8):</p><p>    (3-10)</p><p>    其中参数取值为1时,F-measure即为最常见的F1-measure:<br />(3-11)</p><p>    假设有8条记录、、、、、、、,其中{,,}和{,,}互为相似重复记录,若通过算法检测出的重复结果为{,,,}和{,,,}互为相似重复记录,则TP=4,FP=2,TN=2,FN=0,所以算法的查全率为4/(4+0)=100.00%,查准率为4/(4+2)=66.67%,F1-measure=2*1*0.6667/(1+0.6667)=80.00%。<br />3.5.3实验结果分析</p><p>    本文使用了多个数据集进行算法仿真,对OMPN算法、MPN算法和SNM算法的查全率和查准率进行综合对比。这三种算法的实验参数为:</p><p>    OMPN算法的实验参数:最大滑动窗口最大为=20,最小为=3,进行单趟SNM的次数=3;</p><p>    MPN算法的实验参数:固定滑动窗口大小为=5,进行单趟SNM的次数=3;SNM算法的实验参数:固定滑动窗口大小为=5。</p><p>    在字段相似度检测过程中用到的两个常数VERY_CLOSE_CONSTANT(字符串非常接近)、CLOSE_CONSTANT(字符串比较接近),对它们分别赋值:VERY_CLOSE_CONSTANT=0.8,CLOSE_CONSTANT=0.6。<br />数据集的规模与生成数据的参数取值如表3.8所示:</p><p>    表3.8测试数据集参数取值说明</p><p>    数据集</p><p>    dataset150001000311 uniform phonetic</p><p>    dataset2100002000311 uniform phonetic</p><p>    dataset3200004000311 uniform phonetic</p><p>    dataset45000010000311 uniform phonetic</p><p>    dataset58000016000311 uniform phonetic</p><p>    dataset610000020000311 uniform phonetic</p><p>    dataset720000040000311 uniform phonetic</p><p>    dataset8500000100000311 uniform phonetic</p><p>    表3.8中的参数~代表的含义分别为:-原始记录数、-重复记录数、-单个记录最多重复数、-单个字段最多修改数、-单个记录最多修改字段数、-重复记录的概率分布、错误类型。<br />本实验的实验环境配置如表3.9所示:</p><p>    表3.9实验环境配置</p><p>    操作系统 Windows 7旗舰版</p><p>    处理器 Core i7(8核心)</p><p>    内存大小8G</p><p>    JDK版本 JDK1.8.0</p><p>    JVM配置-Xmx4096m(堆内存最大4G)</p><p>    在表3.8所示的8种不同规模的据集上,分别使用SNM、MPN和OMPN进行实验,统计每种算法在每种数据集上的、和运行时间(单位:秒),实验结果分别如表3.10至表3.12所示。<br />表3.10 SNM、MPN、OMPN算法查全率对比表</p><p>    数据集大小(千条) SNM算法(%) MPN算法(%) OMPN算法(%)<br />580.6094.8098.80</p><p>    1078.1591.8098.40</p><p>    2078.0389.2898.75</p><p>    5078.0187.3997.90</p><p>    8076.3882.0898.58</p><p>    10075.8580.7698.73</p><p>    20073.8379.7299.10</p><p>    50072.9078.9196.91</p><p>    表3.11 SNM、MPN、OMPN算法查准率对比表</p><p>    数据集大小(千条) SNM算法(%) MPN算法(%) OMPN算法(%)<br />5100.0099.8999.50</p><p>    1099.94100.0099.54</p><p>    2099.97100.0098.78</p><p>    5099.8799.9896.93</p><p>    8099.8199.9295.69</p><p>    10099.9299.8794.77</p><p>    20099.7399.8989.70</p><p>    50099.5399.7088.17</p><p>    表3.12 SNM、MPN、OMPN算法运行时间对比表</p><p>    数据集大小(千条) SNM算法(s) MPN算法(s) OMPN算法(s)<br />50.5030.9381.274</p><p>    101.1962.3202.961</p><p>    203.5406.98510.327</p><p>    5017.16926.34759.420</p><p>    8047.255239.434197.439</p><p>    10067.173372.245290.903</p><p>    200237.8051668.9951391.415</p><p>    5001493.30510464.89411296.066</p><p>    根据表3.10至表3.12的实验结果,分别作出recall、precision和运行时间的形象的且直观的折线图,如图3.5至图3.7所示。<br />图3.5 SNM、MPN、OMPN算法查全率折线图</p><p>    图3.6 SNM、MPN、OMPN算法查准率折线图</p><p>    图3.7 SNM、MPN、OMPN算法运行时间折线图</p><p>    根据表3.10至表3.12计算得到三种算法的每种数据集上的F1值,如表3.13所示,并在图3.8中作出F1值的折线图,。<br />表3.13 SNM、MPN、OMPN算法F1-measure值对比表</p><p>    数据集大小(千条) SNM算法(%) MPN算法(%) OMPN算法(%)<br />589.25897.27899.149</p><p>    1087.71295.72598.967</p><p>    2087.64894.33698.765</p><p>    5087.59793.26297.413</p><p>    8086.53790.12697.114</p><p>    10086.23789.30496.709</p><p>    20084.84788.67294.166</p><p>    50084.15988.09592.334</p><p>    图3.8 SNM、MPN、OMPN算法F1-measure折线图</p><p>    由图3.5可以看出:改进的OMPN算法面对不同大小的数据集(其他条件如滑动窗口大小、数据集特征参数等均一致),查全率均高于SNM算法和MPN算法,并且OMPN算法查全率的数值稳定在96%以上。所以证明了改进的OMPN算法在查全率上相较于传统的MPN算法拥有较大的提升;随着数据集的增大,SNM算法和MPN算法的查全率均呈下降趋势,而OMPN算法的查全率较为稳定。</p><p>    由图3.6可以看出:面对不同的数据集,SNM和MPN算法表现较好,这是因为算法中采用的相似记录判等方法是基于当前数据集特征的判定规则,所以需要领域专家的经验和知识;OMPN算法采用基于字段区分度的加权判等方式,在检测大小从5000到200000的数据集时,查准率均在90%以上,属于尚可接受的范围,但是当数据集大小达到500000时,查准率低于90%,所以OMPN算法的查准率还有待改进的空间。本文的第四章针对这一问题提出了新的改进思路,并取得了良好的效果。</p><p>    由图3.7可以看出:SNM算法时间消耗最低,因为MPN和OMPN算法均包含多趟独立的SNM过程,并且含有传递闭包的计算;与MPN相比较,OMPN算法采用了自适应大小的滑动窗口,这一改进是可以减少时间消耗的,但是OMPN算法还包括对含有空(或者不完整)排序键值的记录进行归并的过程,所以总体的时间和MPN算法差距不大。</p><p>    综合以上结果可以看出,OMPN算法相对于MPN算法较为明显的改进在于:在和MPN消耗时间差距非常小的同时实现更高的查全率;算法的缺点也很明显,即随着数据量的增大,相似重复记录判等方法表现较差,导致查准率的下降。但是由图3.8可以看出,综合考虑查全率和查准率,OMPN算法的整体表现要好于MPN。<br />3.6本章小结</p><p>    本章首先介绍了MPN算法的缺点,然后在此基础上提出了一种改进的算法OMPN,并从三个方面介绍了传统MPN的处理方法的不足以及OMPN算法的对其缺点的改进。之后介绍了OMPN算法的设计与流程步骤,最后通过采用数据生成器febrl生成的不同规模的数据集进行对比实验,实验验证了OMPN算法的查全率和F1值都较高,比SNM和MPN这两个算法更优,但是也反映了OMPN算法查准率不够理想的问题,因此,本文继续对OMPN算法进行改进,详细介绍在第四章。<br />Equation Section (Next)</p><br />第四章 基于遗传神经网络改进的OMPN算法<br /><p>    OMPN算法采用&quot;排序/归并&quot;的思想,在归并过程中,需要采用有效的方式对滑动窗口内的记录进行判等,OMPN采用基于字段区分度的加权判等方式,避免了人工参与,但是这种方式表现不稳定,当数据量的增加时,OMPN的查准率下降。传统的MPN算法主要根据人工经验选择有效的字段对不同的记录进行判断,因此,受到人为干扰。为了避免这个弊端,同时提高OMPN算法的查准率,本章提出了基于遗传算法和神经网络相结合的、有监督地学习判等方法,并与OMPN的算法思想相结合,提出增强的MPN算法(Advanced - Optimized Multi-Pass Sorted Neighborhood,A-OMPN)。A-OMPN算法的查全率和查准率都优于现有算法,但是GA-ANN算法的训练耗时较大,所以,我们在A-OMPN的基础上进行简化,只训练一个BP网络,用这个训练好的网络进行判等操作,由此得到基于BP网络的MPN算法(BP-based Optimized Multi-Pass Sorted Neighborhood,BP-OMPN)。</p><p>    本章首先介绍了遗传神经网络在相似重复记录检测问题上的操作过程,然后分别给出A-OMPN算法和BP-OMPN算法的具体操作过程,并通过实验验证了本文提出的A-OMPN算法和BP-OMPN算法的性能。<br />4.1遗传神经网络用于相似重复记录检测</p><p>    4.1.1 BP神经网络的设计</p><p>    通常情况下使用Back Propagation算法进行BP网络的训练。</p><p>    图4.1进行相似重复记录检测的BP网络结构</p><p>    BP神经网络一般由3层或者3层以上神经元组成。一方面,由引理[]可以看出三层网络的较好的逼近性能。另一方面,网络层数的增加虽然可以增强表达能力,但是也会带来较高的训练复杂度。因此,对于重复记录检测,GA-ANN采用三层BP网络,图4.1表示了用于相似重复记录检测的BP网络结构,网络各层所代表的含义及其计算方法分别为:</p><p>    (1)输入层的结点数由数据集中记录的字段数目确定,输入层的取值是两条记录的相似度向量。若数据集中的记录含有个字段,则输入层结点数为。任取两条记录和,计算这两个记录在第个字段下的相似度值为,,则这和的相似度值组成的向量为,BP网络的输入层各结点的取值也随之确定,即第个结点的输入为。例如,对于表3.6所示的字段说明数据,每条记录都有16个字段,其中,第一个字段&quot;rec_id&quot;是为了方便计算算法的查重效果而设计的,不属于数据集的特征,所以这个数据集共有15个字段,因此,输入层应当有15个结点(不含一个偏置结点)。</p><p>    (2)输出层的结果代表BP网络对于两条记录相似度的计算。结点个数为1,输出的结果介于0到1之间,结果越接近1表示两条记录相似程度越高。</p><p>    (3)隐含层连接输入层与输出层,主要进行BP网络的前向计算和误差反向传播更新权值的过程。结点数目由公式(4-1)[]计算得到。<br />(4-1)</p><p>    <span style='color:red;'>其中是隐含层结点数,是输入层结点数,是输出层结点数,计算过程的结果需要四舍五入进行修整。</span>例如,如果我们使用表3.6所示的字段说明表来设计一个符合要求的BP网络结构的时候,输出数值个数是1,所以=1;15个字段对应着输入层上所含有的单个神经元的个数是=15,通过公式(4-1)计算得到=7,=24,最终得到适用于该数据集的BP网络的隐层神经元个数为=24。</p><p>    本文使用的激活函数为Sigmoid函数[39,40,41],公式(2-9)给出了它的计算形式。</p><p>    神经网络的初始权值对网络最终的收敛情况具有重要的作用,同时,初始权值也会影响训练速度的快慢[]。最理想的情况是,初始化赋值之后,每个神经元的输出接近于0,这样可以在sigmoid激活函数的导数取最大值的地方进行下一轮权值的调节与变化。</p><p>    权值更新的学习速率决定了每次训练结束后权值更新的幅度,学习速率较大会使得训练过程震荡,过小的学习速率又会使得权值在每一次更新过程中的改变量较小,进而减慢训练过程,耗时较大[]。通常,可以采用小学习速率,以保证系统稳定性而不会导致修改幅度过大,本文取值为0.15。期望误差代表着当训练后的误差结果在可接受范围之内则人为进行收敛,停止训练。</p><p>    BP神经网络训练终止的条件是训练误差达到预先设定的阈值或权值更新次数达到预先设定的迭代次数,本文在仿真实现过程中,同时采用这两种终止条件,只要满足其中一条,则训练终止。</p><p>    针对相似重复检测问题,将已知记录是否重复的数据作为训练集,用于训练神经网络,得到训练完成的网络后,用该网络对测试数据进行相似重复检测。图4.2表示了使用BP网络进行相似重复记录检测问题的求解的算法操作过程。<br />图4.2 BP网络检测过程的流程图</p><p>    4.1.2基于遗传算法改进的神经网络</p><p>    BP神经网络通过训练能够有效地对测试数据集中的相似重复记录进行检测判断,解决了大数据量情况下传统的基于&quot;排序/归并&quot;思想的检测算法检测效果较差的问题,并且拥有较好的适应性。但训练好的BP神经网络可能达到局部最优状态。GA算法[51]模拟生物自然进化的操作,它利用自然界的进化思想,<span style='color:red;'>通过选择操作、交叉操作、变异操作等过程实现种群的进化过程,并在演化过程中筛选出适应性较差的个体并将其丢弃,经过数代进化迭代之后,最终选出适应度较高的个体,得到全局的最优解[]。</span>GA在全局范围内的搜索排查能力是比较强的,所以可以将该算法的思想其应用到BP神经网络中,以解决神经网络难以跳出局部最优的问题[][]。<br />GA-ANN算法框架的元素主要有:</p><p>    1.染色体</p><p>    <span style='color:red;'>采用实数编码[]的编码方式,在这种编码方式下,每一个实数对应着一个BP网络的权值或阈值,</span>并作为一个独立的染色体,设种群规模为,则共有组神经网络权值和阈值,也就是说我们一共需要训练个BP神经网络。</p><p>    以图4.1展示的一个简单的网络结构为例,首先训练好一个BP神经网络,将训练得到的权值以及阈值作为一个个体,<span style='color:red;'>输入层有4个神经元,1个偏置单元,隐含层与6个神经元,所以这个网络的输入层与它的隐含层之间的权值一共存在着(</span>4+1)*6=30个,又因为这个网络的输出层仅仅有1个神经元,所以得到这个网络的隐含层到它的输出层之间共有6+1=7个权值,因此,该神经网络共有37个权值,1个输出层阈值,当采用实数编码方式时,染色体的长度为38。<br />2.适应度函数</p><p>    在重复检测问题中,适应度函数用于衡量相似重复检测结果和真实结果的之间的差距,差距越小,说明这个染色体所代表的的BP神经网络对数据的检测结果越准确,所以适应度值越大。本文使用公式(4-2)[]<span style='color:red;'>进行第个个体的适应度值的计算。<br />(4-2)</span></p><p>    公式(4-2)中,代表使用第个个体对应的BP神经网络进行重复记录检测时,在记录数据集上所得到的总误差,的值是用公式(4-3)进行计算。<br />(4-3)</p><p>    公式(4-3)中,代表训练数据集的总大小,代表第条记录的期望输出结果,代表第条记录的实际输出结果。<br />3.选择</p><p>    <span style='color:red;'>采用轮盘赌[]方法进行选择操作,在这种选择方式中,那些拥有较大适应度函数值的个体都会以一个比较大的概率被选择中。个体被选中的概率用公式(4-4)计算:<br />(4-4)</span></p><p>    公式(4-4)中,是种群中个体总个数,是第个个体的适应度值。</p><p>    4.交叉、变异[44]</p><p>    因为一个网络权值向量构成一个染色体,所以在该问题上,采用实数编码,因此对任意不同的两条个体上的对应位置执行数值交换,即完成一次交叉操作,本文采用两点交叉操作。</p><p>    变异算子模仿的是基因突变的过程:染色体某个位置上的基因突变成为其等位基因,从而可能引发性状表现上的变异。</p><p>    使用遗传神经网络进行相似重复记录检测的执行过程图如图4.3所示。其主要操作为:首先,进行有监督的训练学习得到组BP网络;然后,用这组BP网络的权值产生初始状态下的种群,种群中含有条染色体,种群经过遗传操作不断得到优化;最后,从进化结束后的种群中获取最优的BP网络,使用这组最优的网络权值所代表的网络对待检测的数据集进行重复性检测。</p><p>    GA-ANN算法操作过程中,需要对数据集中的任意两个不同的记录进行比较,判断他们是否相似或重复,带来较高的时间复杂度,为,存在多余的判断过程。所以需要对其进行改进,在保留遗传神经网络所具有的优势的同时,减小算法的时间复杂度。<br />图4.3遗传神经网络检测相似重复记录流程图</p><p>    4.2基于神经网络的A-OMPN算法和BP-OMPN算法</p><p>    A-OMPN算法和BP-OMPN算法的操作过程都包括两部分:(1)根据OMPN算法进行记录排序,包括使用基于字段区分度的方法进行记录的排序关键字的选择、依据所选出来的关键字对所有记录进行排序、选取自适应大小的滑动窗口;(2)使用某种判等方法,对同一个滑动窗口内的数据执行判等操作,最终得到重复记录。与GA-ANN算法相比,A-OMPN算法和BP-OMPN算法首先通过OMPN算法对数据集进行预处理,以避免大量多余的判等操作,因此时间复杂度降低。A-OMPN算法使用GA-ANN算法的思想进行判等,BP-OMPN算法仅使用BP神经网络进行判等。<br />4.2.1基于遗传神经网络的A-OMPN算法</p><p>    传统SNM算法和MPN算法使用的是基于专家经验知识的规则产生式系统(OPS5),这种判等方法主要依赖人工操作以选择进行比较的字段。第三章提出了基于字段区分度的加权判等方式,这种判等方法对小数据量的数据表现较好,当数据规模不断增大时,算法的查准率逐渐变差,性能不稳定。传统的基于遗传神经网络进行相似重度检测的算法不存在排序操作,所以需要在数据全集对数据进行两两判断,时间复杂度为。</p><p>    综合GA-ANN算法和OMPN算法,本文进一步提出了A-OMPN算法,该算法主要使用训练完成的神经网络判断滑动窗口内的记录是否重复,训练过程采GA-ANN的训练思路。A-OMPN算法实现了根据数据集的特点训练专门的用于判等的网络,减少了人工干预,同时可以提高算法对多种数据集的适应性。</p><p>    算法对于给定的训练集,共训练个BP神经网络,然后用训练得到的个BP神经网络的权值作为初始的个个体,再进行相关的遗传算法方面的操作,最后从个BP神经网络中选择最优的结果作为最终训练得到的神经网络,然后用这个神经网络进行判等操作,A-OMPN算法的操作过程如算法4.1所示:<br />算法4.1:A-OMPN算法</p><p>    1.读取待检测的数据集以及训练数据集,设定执行SNM的次数为,最大遗传进化次数;<br />2.随机产生个初始BP神经网络;</p><p>    3.分别对个BP网络进行训练,用训练完成的个BP网络的权值向量产生初始种群;<br />4.种群进行遗传操作直到达到,得到最优的个体,即对应着最优网络;</p><p>    5.根据字段区分度选取排序关键字;</p><p>    6.对每一条待检测记录:</p><p>    如果该记录的关键字存在缺失:</p><p>    将该记录的ID加入到缺失关键字记录集合中;</p><p>    7.对数据全集中的、非中的其余记录进行排序;</p><p>    8.采用进行可伸缩大小的滑动窗口重复检测,得到重复集合;</p><p>    9.在集合中检测中的记录的重复记录,得到最终的重复记录集合;</p><p>    10.独立地执行步骤5~9次,得到个不同的集合,并对这个不同的集合进行传递闭包的计算,得到最终重复记录集合;<br />使用A-OMPN算法进行相似重复记录检测的流程图如图4.4所示。</p><p>    图4.4 A-OMPN算法流程图</p><p>    与OMPN算法的基于字段区分度的加权判等操作相比,使用遗传神经网络进行判等可以有效地提高算法的查准率。同时,与传统的使用遗传神经网络求解该问题的算法相比,OMPN算法对数据集进行了预处理,只需要比较滑动窗口范围内的记录,减少了多余的判断计算,因此可以减少时间方面消耗。<br />4.2.2基于BP网络的BP-OMPN算法</p><p>    A-OMPN算法的需要较长的时间进行网络的训练,因此对该算法进行简化,提出基于BP神经网络的BP-OMPN算法。设表示BP-OMP<span style='color:red;'>N算法中所使用的BP神经网络的输入层节点数,所使用的BP网络隐含层节点个数为,</span>则一次训练过程(包括前向计算输出和误差反向更新过程)的时间复杂度为,设BP网络终止训练过程的最大次数为,遗传算法的种群数量为,则需要训练个BP网络以产生初始种群,所以种群初始化过程需要的时间,种群演化过程的时间复杂度为,所以A-OMPN算法训练过程的总时间复杂度如公式(4-8):<br />(4-5)</p><p>    可以看出算法训练过程的时间复杂度为平方级别。除此之外,BP神经网络优化算法属于高维优化问题,算法训练的结果往往是收敛于某个鞍点附近,而不是局部最小值[]。在鞍点和局部极小值的梯度都等于零,大量鞍点的存在才是神经网络优化困难的真正原因,而基于GA对BP网络进行改进的算法只有在问题拥有较多局部极值的时候效果较好,所以适用较为局限[]。因此,本节提出了简化的BP-OMPN算法,仅训练单一的BP神经网络,代替A-OMPN算法中遗传伸进网络的训练。BP-OMPN步骤如算法4.2所示:<br />算法4.2:BP-OMPN算法</p><p>    1.读取待检测的数据集以及训练数据集,设定执行SNM的次数为;</p><p>    2.使用训练数据集训练得到一个训练好的BP神经网络;</p><p>    3.根据字段区分度选取排序关键字;</p><p>    4.对每一条记录:</p><p>    如果该记录的关键字存在缺失:</p><p>    将该记录的ID加入到缺失关键字记录集合中;</p><p>    5.对数据全集中的、非中的其余记录进行排序;</p><p>    6.采用进行自适应尺寸的滑动窗口重复检测,得到重复集合;</p><p>    7.在集合中检测中的记录的重复记录,得到最终的重复记录集合;</p><p>    8.独立地执行步骤5~9次,得到个不同的集合,并对这个不同的集合进行传递闭包的计算,得到最终重复记录集合;<br />图4.5是BP-OMPN算法的流程图。</p><p>    图4.5 BP-OMPN算法流程图</p><p>    4.3 OMPN、A-OMPN、BP-OMPN综合对比实验</p><p>    本节对OMPN算法、A-OMPN算法和BP-OMPN算法在不同数据集上进行实验,并统计实验结果。</p><p>    实验环境设置和数据集设定与第三章3.5节相同,均采用8个规模不同但生成方式相同(生成器&quot;febrl&quot;的参数一致)的数据集,对于神经网络的训练,训练过程采用的数据集大小为500,即含有500条记录,使用&quot;febrl&quot;生成,生成参数与实验数据集一致,详情见表3.7与表3.8。</p><p>    对于OMPN算法,最大滑动窗口大小=20,最小滑动窗口大小=3,算法过程中进行单趟SNM的次数=3。</p><p>    对于BP神经网络的训练,<span style='color:red;'>我们在实现过程中所使用的学习速率是0.05,所使用的动量系数取值是0.9[],</span>网络最大训练次数;GA的种群初始大小,变异概率,种群最多迭代次。</p><p>    OMPN算法、A-OMPN算法、BP-OMPN算法的查全率、查准率、运行时间(单位:秒)的实验结果分别如表4.1至表4.3所示,对于A-OMPN算法和BP-OMPN算法,这里统计的运行时间是使用训练好的网络进行检测的时间,不包括训练网络的时间。<br />表4.1 OMPN、A-OMPN和BP-OMPN算法查全率对比表</p><p>    数据集大小(千条) OMPN算法(%) A-OMPN算法(%) BP-OMPN算法(%)<br />598.8098.9098.80</p><p>    1098.4098.3598.15</p><p>    2098.7598.9098.90</p><p>    5097.9097.8597.65</p><p>    8098.5898.5398.39</p><p>    10098.7398.7698.78</p><p>    20099.1099.1599.50</p><p>    50096.9197.2397.43</p><p>    表4.2 OMPN、A-OMPN和BP-OMPN算法查准率对比表</p><p>    数据集大小(千条) OMPN算法(%) A-OMPN算法(%) BP-OMPN算法(%)<br />599.50100.00100.00</p><p>    1099.54100.00100.00</p><p>    2098.78100.0099.98</p><p>    5096.9399.8798.95</p><p>    8095.6999.8598.80</p><p>    10094.7799.8898.81</p><p>    20089.7099.6897.81</p><p>    50088.1799.2197.69</p><p>    表4.3 OMPN、A-OMPN和BP-OMPN算法运行时间对比表</p><p>    数据集大小(千条) OMPN算法(s) A-OMPN算法(s) BP-OMPN算法(s)<br />51.27421.11020.800</p><p>    102.96183.16977.989</p><p>    2010.327336.404328.788</p><p>    5059.4202172.7661928.253</p><p>    80197.4395510.2015287.167</p><p>    100290.9038505.1298119.437</p><p>    2001391.41532842.00430901.765</p><p>    50011296.066204281.991193198.802</p><p>    根据表4.1至表4.3所示的查全率、查准率和运行时间(单位:秒),分别作出OMPN算法、A-OMPN算法和BP-OMPN算法的查全率折线图、查准率折线图和运行时间折线图,如图4.6至4.8所示。<br />图4.6 OMPN、A-OMPN、BP-OMPN算法查全率折线图</p><p>    图4.7 OMPN、A-OMPN、BP-OMPN算法查准率折线图</p><p>    图4.8 OMPN、A-OMPN、BP-OMPN算法运行时间折线图</p><p>    由图4.6所示的查全率对比结果可以看出,A-OMPN算法、BP-OMPN算法与OMPN算法相比,查全率非常接近,且均在96%以上,证明基于OMPN改进的A-OMPN算法和BP-OMPN算法能够保证较好的查全率,这与理论上的结果一致,因为基于神经网络改进的算法和OMPN算法的主要区别在于判等过程采用了不同的方法,而这一区别几乎不影响查全率的指标。</p><p>    由图4.7所示的查准率对比结果可以看出,A-OMPN算法和BP-OMPN算法相对于OMPN算法,查准率均有较大的提升;由图4.8所示的运行时间对比结果可以看出,A-OMPN算法和BP-OMPN算法的检测时间相近,且数倍于OMPN算法。取得此实验结果的理论原因在于:两者最主要的区别即是相似重复记录判等阶段,A-OMPN算法和BP-OMPN算法采用BP神经网络进行判等,通过学习训练数据集字段相似与整体记录相似的非线性关系,可以较为准确地对两条记录相似与否进行预测和判断,但同时神经网络前向传播的计算时间比OMPN算法采用基于权重的判等过程时间复杂度高,OMPN算法具有常数级的的时间复杂度,而改进的A-OMPN算法和BP-OMPN算法,对于个输入结点、个隐含结点的三层网络,检测过程的时间复杂度为,因此,A-OMPN算法和BP-OMPN算法的检测时间较长。</p><p>    接下来对A-OMPN算法和BP-OMPN算法在多个不同数据集上进行训练,并统计训练时间,分析这两种算法的训练效率。</p><p>    实验采用5个规模不同但生成方式相同(生成器&quot;febrl&quot;的参数一致)的数据集,训练数据集的规模与生成数据的参数取值如表4.4所示。数据集的大小分别为100、200、500、1000、2000,重复记录所占的比例均为20%。BP网络训练时的参数为:,动量系数取0.9[],最大训练次数为;GA种群初始大小,变异概率,种群最多迭代次。<br />A-OMPN算法和BP-OMPN算法训练时间的结果如表4.4所示:</p><p>    表4.4 A-OMPN和BP-OMPN算法训练时间对比表</p><p>    数据集大小(条) A-OMPN算法(s) BP-OMPN算法(s)</p><p>    100742.26038.665</p><p>    2002934.840156.076</p><p>    50018513.945968.742</p><p>    100059564.3723970.958</p><p>    2000335082.87516484.161</p><p>    由表格4.4画出A-OMPN算法和BP-OMPN算法训练时间的结果对比折线图如图4.9所示:<br />图4.9 A-OMPN、BP-OMPN算法训练时间折线图</p><p>    由图4.9可知,BP-OMPN算法训练过程的时间消耗较低,且相对于A-OMPN算法优势明显。这主要是由于A-OMPN算法基于种群进化对训练好的多个BP网络进行优化,而BP-OMPN算法只进行单一网络的训练,且没有遗传操作等寻优过程,因此A-OMPN算法的训练时间较长。</p><p>    综上,基于遗传神经网络的A-OMPN算法和基于BP神经网络的BP-OMPN算法在保证了OMPN算法较好查全率的基础上,弥补了算法查准率较低的缺陷,但是以牺牲检测时间为代价。另一方面,A-OMPN算法的训练过程的时间消耗过大。简化的BP-OMPN算法缩减了训练过程的时间。通过实验结果可以看出,A-OMPN算法的效果与BP-OMPN算法的效果差距较小,因此在实际问题中,可以综合考虑精度要求和时间要求,选择最适用于实际情况的算法。<br />4.4本章小结</p><p>    本章首先介绍了目前较为成熟的使用遗传神经网络进行相似重复记录检测的方式:使用训练数据集训练出合适的BP网络,然后针对其可能陷入局部最小值的缺点,引入遗传算法对其进行改进。然后将遗传神经网络与OMPN算法相结合提出了A-OMPN算法,A-OMPN算法在提高查准率的同时缩减了遗传神经网络进行重复记录检测的复杂度,但是A-OMPN算法训练网络的过程耗时严重,所以针对A-OMPN算法,提出了简化的BP-OMPN算法,缩减了训练过程的时间消耗。最后通过对比实验证明了A-OMPN算法和BP-OMPN算法都可以得到较高的查全率和查准率,最后,给出了这两个算法的训练时间,可以看出BP-OMPN算法训练较快。</p><br />第五章 航天情报系统中的相似重复记录检测<br /><p>    目前数据清洗技术在各行业的信息管理系统中取得了广泛的应用。本章首先介绍了航天情报信息管理系统的需求分析、概要设计以及技术实现,然后重点介绍了数据清理模块,包括数据清理模块的设计、重复记录产生的原因、OMPN算法在系统中的应用以及该算法对数据质量的提高。<br />5.1系统需求分析</p><p>    5.1.1系统建设背景与目标</p><p>    北京空间科技信息研究所为了提高科技化水平,实现航天情报数据的采集、处理、分析的信息化,于2016年开展&quot;航天情报信息管理系统&quot;项目的研究。该研究以&quot;知识结构化、成果产品化&quot;为目标,立足多年的情报信息数据积累,致力于打造一款功能丰富、实用高效的情报数据信息管理系统。<br />5.1.2需求分析</p><p>    &quot;航天情报信息管理系统&quot;主要面向研究所内部研究人员的日常办公使用,经过项目调研与分析后将系统的总体需求概括如表5.1所示:<br />表5.1需求分析总结表</p><p>    <span style='color:red;'>运行环境需求 Web 操作系统为Windows XP,浏览器为Internet Explorer </span>8<br />iOS 操作系统为iOS8.0及其以上</p><p>    Android 操作系统为Android4.0及其以上</p><p>    功能性需求(1)数据采集模块:将现有数据采集到系统中并保持和系统中的数据格式一致,包括两种采集模式:人工在线录入;从xls文件导入。<br />(2)数据清洗模块:对多源数据合并导致的重复数据进行检测清理。</p><p>    (3)数据检索模块:方便研究人员更加快捷地检索和查询所需信息。</p><p>    (4)服务支撑模块:包括用户权限管理、数据异常下载行为监视、综合营销平台建设。</p><p>    (5)移动应用模块:开发iOS手机端和Android手机端App,是系统在手机端的简化体现,方便研究人员随时查看相关信息。</p><p>    (6)数据应用模块:在已有数据集的基础上,对数据进行统计,并进行可视化展示,方便研究人员更直观地分析数据。</p><p>    非功能性需求(1)性能需求:并发用户数2000,事物平均响应时间3.0s。<br />(2)稳定性需求:双机热备方案。</p><p>    (3)安全性需求:网络/系统的安全监测与检查、反爬虫设计等。</p><p>    5.2系统设计与实现</p><p>    本节主要介绍&quot;航天情报信息管理系统&quot;的设计与实现方式,主要包括系统架构、数据库设计、功能模块实现等。<br />5.2.1系统概要设计</p><p>    根据5.1节中的系统功能性需求分析,可以将本系统按照功能模块划分成6个主要的部分,如图5.1所示:<br />图5.1六大功能模块示意图</p><p>    &quot;航天情报信息管理系统&quot;的总体设计从以下三个层面展开:</p><p>    (1)前端和移动端的交互页面设计;</p><p>    (2)服务器端逻辑功能设计;</p><p>    (3)数据持久化的实现。</p><p>    持久化层主要是负责数据的存储以及向服务器端提供增删改查的服务接口,这里存储了&quot;航天情报信息管理系统&quot;的核心数据信息。</p><p>    服务器端是处理业务逻辑的核心层,是系统的枢纽部分。数据请求由前端发给服务器端,经用户鉴权通过之后向持久化层请求数据并进行整理发送给前端页面。</p><p>    前端交互部分主要包括Web网页界面和App移动端页面,这一层是直接和用户交互的最上一层,负责接收用户的指令以及向用户呈现系统信息等。它主要包括用户的注册与登录、数据检索与查询、可视化展示、数据统计等功能页面。图5.2展示了&quot;航天情报信息管理系统&quot;的总体架构。<br />图5.2航天情报信息管理系统架构图</p><p>    &quot;航天情报信息管理系统&quot;中的数据设计是系统设计较为核心的一个环节。数据内容主要包括航天器、轨道信息、发射场、运载火箭、航天国家与机构、航天器故障信息等。其中,航天器信息数据是系统的核心数据,按照所属类别又可以将其分成8种:通信卫星、导航卫星、遥感卫星、在轨服务与空间安全卫星、空间科学卫星、技术试验卫星、空间探测器和载人航天器。系统数据库对应的ER(实体-关系)图如图5.3所示:<br />图5.3实体关系结构图</p><p>    由图5.3可知,航天器实体是系统数据库中的最关键实体,它与故障、卫星平台、航天机构、航天国家、航天发射场、运载火箭都存在直接的关系。其中,除了和航天器故障对应关系是&quot;一对多&quot;之外,和其他的几个实体的关系都是&quot;多对一&quot;。航天国家和与其相连的几个实体的关系均为&quot;一对多&quot;。<br />表5.2至表5.5是较为核心数据库字段设计表:</p><p>    (1)航天器表</p><p>    表5.2航天器字段设计表</p><p>    属性名称属性描述类型可否为空备注</p><p>    spacecraft_id 航天器ID int(11)否主键</p><p>    spacecraft_name_cn 航天器中文名称 varchar(60)否无</p><p>    spacecraft_name_en 航天器英文名称 varchar(40)否无</p><p>    spacecraft_launch_num 航天器发射编号 varchar(20)否无</p><p>    spacecraft_num 航天器编号 varchar(20)否无<br />task_property 任务性质 varchar(5)否无</p><p>    spacecraft_type 航天器类型 varchar(50)否无<br /><span style='color:red;'>country_id 所属国家ID int(11)否外键</span></p><p>    country 所属国家 varchar(20)否无</p><p>    institution_id 所属机构ID int(11)否外键</p><p>    institution_name 所属机构 varchar(200)否无<br />operator_id 运营单位ID int(11)否外键</p><p>    operator_name 所属运营单位 varchar(200)否无</p><p>    spacecraft_image 外形图片 varchar(60)是无</p><p>    由于篇幅限制表5.2只给出了部分关键字段的设计。从上表可以看出航天器的ID是标识一条航天器记录的唯一关键字,而该表中的外键:country_id、institution_id、operator_id则是航天器与&quot;所属国家&quot;、&quot;所属机构&quot;以及&quot;所属运营单位&quot;三张表的关联。<br />(2)航天国家表</p><p>    表5.3航天国家字段设计表</p><p>    属性名称属性描述类型可否为空备注</p><p>    <span style='color:red;'>country_id 国家ID int(11)否主键</span></p><p>    <span style='color:red;'>country_name_cn 国家中文名称 varchar(60)否无</span></p><p>    country_name_en 国家英文名称 varchar(60)否无</p><p>    budget_per_year_gov 政府年度航天预算 float(8,3)是无</p><p>    budget_per_year_civil 民用年度航天预算 float(8,3)是无<br />main_spacecraft 主要航天器 text 是无</p><p>    (3)航天器故障表</p><p>    表5.4航天器故障字段设计表</p><p>    属性名称属性描述类型可否为空备注</p><p>    malfunction_id 故障ID int(11)否主键</p><p>    malfunction_spacecraft_id 故障航天器ID int(11)否外键</p><p>    malfunction_level 故障等级 varchar(10)否无<br />malfunction_date 故障发生时间 date 否无</p><p>    malfunction_in_designlife 是否发生</p><p>    在寿命期 tinyint(1)否无</p><p>    malfunction_consequence 故障后果 text 是无<br />(4)卫星平台表</p><p>    表5.5卫星平台字段设计表</p><p>    属性名称属性描述类型可否为空备注</p><p>    satellite_platform_id 平台ID int(11)否主键<br />platform_dev_org_id 平台研制</p><p>    单位ID int(11)否外键</p><p>    platform_dev_data 研制时间 date 否无</p><p>    platform_descrip 平台描述 text 否无</p><p>    platform_image 平台图片 varchar(60)是无</p><p>    5.2.2系统实现</p><p>    (1)系统开发与运行环境</p><p>    表5.6给出了本文所搭建的航天情报信息系统的开发环境与运行环境。</p><p>    表5.6航天情报信息系统开发与运行环境</p><p>    服务器端 Web端 App</p><p>    iOS Android</p><p>    开发工具 Intellij idea</p><p>    JDK 1.8.0 Sublime Xcode 8 Android Studio <br />JDK 1.8.0</p><p>    数据库 MySQL SQLite SQLite</p><p>    运行环境硬件操作系统:</p><p>    Windows server</p><p>    2008以上</p><p>    内存大小:4G</p><p>    磁盘空间:300G</p><p>    基于IE内核的浏览器 iOS 8.0及以上 Android 4.0</p><p>    及以上</p><p>    软件 JDK 7.0.71</p><p>    Tomcat 7.0.54</p><p>    MySQL 5.6</p><p>    Navicat 11</p><p>    (2)技术路线</p><p>    本系统采用B/S加移动端C/S的综合技术方案进行实现。其中服务端采用较为成熟的SSM三层技术框架实现,使用Maven添加依赖。数据持久化层由MyBatis实现,它起到了对JDBC的封装作用。服务端的业务逻辑由Spring控制,而SpringMVC和MyBatis框架被Spring框架衔接起来。移动端采用经典的MVC技术路线,Model层负责沙盒内数据的封装与维护,View层负责&quot;空间瞭望&quot;App的页面展示与用户交互、包括搜索、统计、航天器信息分类浏览等,ViewController负责处理逻辑业务,如更新航天器列表、收藏航天器、统计信息提取等,并调用Model的接口更新数据库内容。<br />(3)接口设计</p><p>    服务端与前端以及移动端的数据传输采用JSON的数据格式,JSON数据更加简便易读易操作,前后端交互采用Http通信协议。核心的接口设计如表5.7所示:<br />表5.7数据接口设计表</p><p>    序号接口名称请求方式接口说明</p><p>    1 getHasLaunchedSpacecraft GET 请求已发射航天器列表</p><p>    2 getSpacecraftByCountry GET 按照国家分类返回<br />航天器列表</p><p>    3 getCountBySpacecraftType GET 请求某类型所有航天器数量</p><p>    4 getCountByCountry GET 请求某国家所有航天器数量<br />5 getSearchResult GET 按照关键字返回检索结果</p><p>    6 getMyCollection GET 返回当前登录账户</p><p>    收藏的航天器列表</p><p>    7 getSpacecraftDetailByID GET 返回某个航天器的详细信息<br />8 addToCollectionByID POST 收藏某颗航天器</p><p>    login POST 登录</p><p>    5.3数据清洗模块</p><p>    5.3.1&quot;脏数据&quot;产生原因</p><p>    &quot;航天情报信息管理系统&quot;的数据采集方式有两种,包括人工在线填报数据以及从现存的Excel表格数据批量导入到系统中。人工操作的出错是难以避免的,除此之外现存Excel数据来自于不同的子部门由不同的研究人员维护,没有统一的标准,以上即是现存数据集中的&quot;脏数据&quot;产生的主要原因。再加上数据库中的航天器信息多来自于不同的渠道,这就使得数据集中并不存在一个能唯一标识航天器的字段。<br />表5.7航天器重复记录举例</p><p>    航天器</p><p>    名称发射场发射</p><p>    结果发射时间国家研制单位运载火箭</p><p>    A Cape Canaveral 成功2010/8/1411:07美国洛克希德-马丁宇宙神-5<br />A1卡纳维</p><p>    拉尔角成功2010.08.14</p><p>    11:07 US 洛马 Atlas-5</p><p>    B 卡纳维拉尔</p><p>    角发射场失败 United.States Lockhead Martin 猎鹰-9</p><p>    表5.7展示了三条航天器记录A、A1、B(因真实数据涉及商业机密故数据略有修改)的部分信息,其中A和A1对应着同一颗航天器,B对应另外的一颗航天器。由上表可以看出待处理的数据主要有以下特征:</p><p>    (1)中英文格式不统一,如&quot;洛克希德-马丁&quot;和&quot;Lockhead Martin&quot;、&quot;宇宙神-5&quot;和&quot;Atlas-5&quot;等。<br />(2)存在缺失数据,如B的发射时间信息缺失。</p><p>    (3)中英文缩写与全拼格式不统一,如&quot;United States&quot;和&quot;US&quot;、&quot;洛克希德-马丁&quot;和&quot;洛马&quot;等。</p><p>    (4)时间格式不统一,如A的&quot;2010/8/14&quot;和A1的&quot;2010.08.14&quot;。<br />5.3.2重复记录检测算法的应用</p><p>    对于&quot;航天情报信息管理系统&quot;所读取的原始数据,需要对其进行清洗,以去除重复记录,该系统中的数据清洗模块即为实现这一目标而设计。用户首先从网页端将原始数据录入系统;然后,浏览器向服务端发送数据;服务器端收到原始数据后,对其进行时间格式的统一等简单操作;最后,服务器端调用数据清洗模块,实现对系统数据的去重。本文所实现的数据清洗模块的业务流程如图5.4所示:<br />图5.4数据清洗业务流程图</p><p>    在判重的时候,考虑到两条航天器同一时刻发射的概率非常小,所以在判重过程中可以人为设定&quot;发射时间&quot;占有较高的权重。数据预处理过程主要是按照固定的规则对数据进行检查,该系统所使用的预处理规则如表5.8所示:<br />表5.8数据预处理规则表</p><p>    规则名称规则描述</p><p>    主键判空如果记录的主键为空,则忽略该记录</p><p>    <span style='color:red;'>日期格式检查日期统一用yyyy-MM-dd HH:mm:ss格式</span></p><p>    日期非法内容检查年份超过当前年份或者当月天数超过31天,对该记录进行标记,由人工检查处理</p><p>    国家字段检查国家字段的标准格式为英文全称,将中文内容和英文缩写内容统一成标准格式</p><p>    本文共提出了OMPN算法、A-OMPN算法和A-OMPN算法,它们都在重复检测问题上具有较好的性能。在第三章与第四章的实验分析部分,分别给出了这三种算法在数据生成器产生的带标签数据集上的实验结果,通过算法的查全率和查准率验证了算法的性能。但是,数据清洗模块实际采用OMPN算法而不是A-OMPN算法或者A-OMPN算法,其原因是:(1)&quot;航天情报信息管理系统&quot;中总的数据不超过8000条,数据量比较小,OMPN算法可以满足系统对于查全率和查准率的需求。(2)数据库中的航天器信息源自于不同的渠道,并不存在一个能唯一标识航天器的字段。所以若采用基于遗传神经网络的A-OMPN算法或者基于BP神经网络的A-OMPN算法,需要提取出训练数据集对网络进行迭代训练,而没有唯一标识数据记录的字段导致提取带有标签的训练集只能由人工完成,工作量大效率较低。<br />5.4本章小结</p><p>    本章首先介绍了&quot;航天情报信息管理系统&quot;的需求分析以及系统设计,然后介绍了一些关键技术的核心实现。接着以数据清洗模块为重点进行展开,介绍了系统中的&quot;脏数据&quot;的来源,并基于本文提出的OMPN算法设计数据清洗模块,在真实的航天器重复数据检测中取得的良好效果。</p><br />第六章 总结与展望<br /><p>    6.1总结</p><p>    信息时代的发展不断地带来了剧增的数据量,由于许许多多的数据的来源的多样性、以及各种数据的存储方式和硬件设备不同、而且人为产生的错误是难以避免的等因素,这就会导致我们所获得的数据存在不同程度上的缺失或存在着相似或者重复的数据,因此这就需要更多的学者们研究出更加高效的算法,以实现对脏数据的有效的清洗操作。目前在数据清洗方面的一个比较热点的相关研究是进行重复记录的检测,本文在研究了目前使用较为广泛的算法的基础上,对现有的一些方法进行了行之有效的改进和创新,并且使用了本文所提出的高效的算法实现了实际项目中的数据清洗模块,达到了航天情报信息系统的设计要求。本文的主要的工作内容有:</p><p>    (1)提出了改进的多趟近邻排序算法OMPN。在OMPN算法中,首先,提出了基于字段区分度的关键字选取方法和基于字段区分度加权的判等方法,这种方法可以避免传统的MPN需要依赖专家经验知识的弊端,避免了人工干扰,可以根据数据特点提取有效地关键字。其次,提出了自适应大小的滑动窗口处理方法,在传统的MPN算法中,使用的滑窗大小是固定的,带来灵活度不够、存在漏检和冗余检测的问题,而在OMPN中,通过当前滑窗内记录的重复程度计算得到新的滑窗大小,避免了相似度低的记录的重复检测,也增加了对相似度高的数据的检测次数,更加灵活,效果更好。最后,传统的MPN算法对存在缺失值的数据效果较差,因此,OMPN算法对缺失数据进行预标记,避免了数据缺失带来的不准确性。实验结果表明OMPN算法相对于MPN算法具有一定的优势。</p><p>    (2)结合遗传神经网络和OMPN算法,提出增强的多趟近邻排序算法A-OMPN和基于BP神经网络的多趟近邻排序算法BP-OMPN。遗传神经网络进行检测时,准确度较高,但是需要对任意两个不同的记录的相似度向量进行检测,所以,检测过程繁杂,存在冗余操作。OMPN算法提出了基于字段区分度的判等方法,但是该方法对数据量敏感,在大规模数据上,算法的查准率下降。因此,本文综合遗传神经网络和OMPN算法,对于OMPN算法的滑动窗口内的记录,使用遗传神经网络进行判等,既避免了遗传神经网络的冗余操作,又提高了判等操作的准确度,最终得到查准率和查全率都较高的A-OMPN算法。另外,针对遗传神经网络训练速度慢的缺点,本文提出使用单一BP神经网络执行判等操作,得到BP-OMPN算法。通过进行实验,验证了A-OMPN算法和BP-OMPN算法的查准率、查全率均较高,且BP-OMPN算法的训练耗时明显小于A-OMPN算法。在实际问题中,可以综合考虑时间和精度要求,选择合适的算法。</p><p>    (3)在真实的航天情报信息管理系统中,运用本文提出的OMPN算法进行数据清洗模块的搭建。该系统所提供的真实数据量为8000条数据,且真实数据没有标签,所以使用OMPN算法进行构建。<br />6.2展望</p><p>    本文的主要研究的内容是重复记录检测方面的问题,并且针对研究过程中发现了许多已经存在的方法的缺点或者不足之处,在对这些缺点进行修正的研究中得到了以下两个未来的工作方向:</p><p>    (1)对于那些含有中文的记录的数据集,本文所研究的一些算法的所表现出的性能仍然较差,不能较好地满足实际的精度和准度的需求,因为在生成用于排序的关键字的过程中,以及基于这种方式对字符的处理所需要的字符的值的,而中文的检测方法需要分词操作,所以在中文重复记录检测方面有待于更广泛和深入地研究。<br />(2)实验部分使用的数据量的大小还远远不能达到所谓的海量数据的标准,当数据量的大小超出内存的所能容纳的上限时,提取出来的数据集和排序过程均需要作出调整。可能的解决方案包括将数据集划分为多个更小的单位,采用外部排序等。数据量增大时,算法的效率问题也是亟待考察和解决的。</p><br />
</body>
</html>

