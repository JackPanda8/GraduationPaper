**\
**

**\
**

**西安电子科技大学**

**学位论文独创性（或创新性）声明**

秉承学校严谨的学风和优良的科学道德，本人声明所呈交的论文是我个人在导师指导下进行的研究工作及取得的研究成果。尽我所知，除了文中特别加以标注和致谢中所罗列的内容以外，论文中不包含其他人已经发表或撰写过的研究成果；也不包含为获得西安电子科技大学或其它教育机构的学位或证书而使用过的材料。与我一同工作的同事对本研究所做的任何贡献均已在论文中作了明确的说明并表示了谢意。

学位论文若有不实之处，本人承担一切法律责任。

本人签名： [ ]{.underline} 日 期： [ ]{.underline}

**西安电子科技大学**

**关于论文使用授权的说明**

本人完全了解西安电子科技大学有关保留和使用学位论文的规定，即：研究生在校攻读学位期间论文工作的知识产权属于西安电子科技大学。学校有权保留送交论文的复印件，允许查阅、借阅论文；学校可以公布论文的全部或部分内容，允许采用影印、缩印或其它复制手段保存论文。同时本人保证，结合学位论文研究成果完成的论文、发明专利等成果，署名单位为西安电子科技大学。

保密的学位论文在年解密后适用本授权书。

本人签名： [ ]{.underline} 导师签名： [ ]{.underline}

日 期： [ ]{.underline} 日 期： [ ]{.underline}

摘要 {#摘要 .-1}
====

最近几年以来，随着中国移动互联网设备与传统新闻媒体行业不断深入融合和发展，新闻阅读的兴趣点由传统社交网络的短文本转向借助公众平台实时推送的新闻长文本，如何根据新闻内容划分类别然后准确的推送给用户成为新闻服务提供商的一个重点关注的问题。现阶段解决方式是首先在新闻文本收集初期使用人工手段进行类别标注，之后借助深度学习方法通过收集海量文本特征实现新闻自动化分类。海量文本特征收集过程首先需要依托强大的新闻内容服务；其次由于新闻具有实时性，文本特征库需要专业人员不定期维护。该方法虽然分类十分精确，但由于其运营成本过于昂贵，在社会应用中普及率不高。

本文在对文本聚类技术发展和研究现状进行简要介绍的基础上，首先详细地阐述了基于不同实现方式的文本聚类技术，然后在借鉴前人工作成果和总结新闻文本特点的前提下，提出和设计了一种基于先验知识改进的AHK-P混合聚类算法，该算法的主要原理是首先通过先验知识为文本预先添加一定准确度的类别属性，然后结合文本类别属性和文本词汇特征对新闻文本实现双重约束以选取纯度较高子簇，继而围绕子簇进行文本聚类。（1）该算法通过分类词库先验知识和文本词汇特征分别构建文本的类别映射向量和文本表示向量；（2）借助凝聚层次聚类使用类别映射向量在类别角度粗划分文本数据集；（3）在粗划分后的各类中使用类别映射向量和文本表示向量优化提取初始质心；（4）结合类别映射向量和文本表示向量改进文本距离计算方法，通过K-means算法细划分文本数据集，提高文本聚类的准确性。AHK-P算法不仅具有传统H-K方法聚类准确、多种聚类方法优势互补的特点，而且具有初始质心提取方式灵活可变、聚类过程更加快速的新特点。通过互联网新闻的文本聚类实验结果对比分析，本文设计的新闻文本聚类方法在聚类质量方面与传统方法相比具有明显提升。

**关键词：**互联网，新闻文本，文本聚类，AHK-P，类别映射向量，文本表示向量

ABSTRACT {#abstract .-1}
========

In recent years, on the background of the rapid integration between
China mobile Internet devices and news media, the news reading point of
interest is changing from the traditional social network short text to
the real-time long text news in the public platform, and how to push
news to users according to news content classification is a key concern
of many Internet news service providers. At this stage, the current
solution is to use the artificial means to mark the categories at the
beginning of the news text collection, and then use the deep learning
method to realize the news automation classification by collecting the
massive textual features. Firstly, massive text feature collection
process relies on a strong news content services; Secondly, in
consideration of real-time character, text feature library needs to be
maintained by professionals from time to time. Although the method is
very accurate, the cost is too expensive and the method of the social
application of the penetration rate is not widely used.

This paper first briefly describes the research background of text
clustering and the research status at home and abroad. Secondly, this
paper describes the classification of text clustering method based on
different realization principles. Finally, based on the previous study
and the characteristics of the news text, an improved AHK-P hybrid
clustering algorithm based on prior knowledge is proposed: (1) The
algorithm constructs the category mapping vector and the text
representation vector respectively through the priori knowledge of the
classification lexicon and the text lexical features; (2) The algorithm
clusters the text datasets with the category mapping vector by means of
agglomerative hierarchical clustering; (3) After the rough division, the
various categories use the category mapping vector and text
representation vector to extract the initial centroid; (4) Using the
improved text distance calculation method based on the class mapping
vector and text representation vector, the subclass data set is refined
by K-means algorithm to improve the accuracy of text partitioning. The
algorithm not only has the characteristics of accurate clustering of
traditional H-K method, but also has the characteristics of flexible
method of initial centroid extraction and more rapid clustering process.
The experimental results of text clustering for Internet news show that
the improved method has a significant improvement in the quality of
clustering.

**Keywords:** Internet, News Text, Text Clustering, AHK-P, Category
Mapping Vector, Text Representation Vector

插图索引 {#插图索引 .-1}
========

[[图1.1中国互联网各年度用户使用人数和普及程度统计]{.underline}
1](#_Toc479279430)

[[图1.2文本挖掘领域相关技术]{.underline} 3](#_Toc479279431)

[[图2.1文本聚类流程]{.underline} 7](#_Toc479279432)

[[图2.2文本特征提取流程]{.underline} 9](#_Toc479279433)

[[图2.3基于密度的聚类方法聚类过程示例]{.underline} 11](#_Toc479279434)

[[图2.4基于网格的聚类方法以不同大小单元进行聚类示例]{.underline}
11](#_Toc479279435)

[[图2.5基于模型的聚类方法示例]{.underline} 12](#_Toc479279436)

[[图3.1爬虫基本原理]{.underline} 15](#_Toc479279437)

[[图3.2深度优先搜索顺序]{.underline} 16](#_Toc479279438)

[[图3.3宽度优先搜索顺序]{.underline} 16](#_Toc479279439)

[[图3.4向量空间表示模型]{.underline} 21](#_Toc479279440)

[[图3.5共现词汇示例]{.underline} 23](#_Toc479279441)

[[图3.6计算示例1]{.underline} 24](#_Toc479279442)

[[图3.7计算示例2]{.underline} 24](#_Toc479279443)

[[图3.8计算示例3]{.underline} 24](#_Toc479279444)

[[图3.9计算示例4]{.underline} 25](#_Toc479279445)

[[图4.1传统选择初始质心缺陷示例]{.underline} 28](#_Toc479279446)

[[图4.2基于先验知识的AHK-P算法]{.underline} 29](#_Toc479279447)

[[图4.3质心二次约束提取方式的理想效果]{.underline} 33](#_Toc479279448)

[[图4.4最大间隔约束提取方式的理想效果]{.underline} 35](#_Toc479279449)

[[图4.5 AHK-P具体算法设计框架图]{.underline} 37](#_Toc479279450)

[[图5.1文本数据分类整理流程]{.underline} 42](#_Toc479279451)

[[图5.2 AHK-P算法聚类流程]{.underline} 45](#_Toc479279452)

[[图5.3凝聚层次聚类算法实现流程]{.underline} 46](#_Toc479279453)

[[图5.4初始质心提取流程]{.underline} 47](#_Toc479279454)

[[图5.5 K-means算法工作流程]{.underline} 48](#_Toc479279455)

[[图5.6 M2、M4和M5方法与真实质心距离对比直方图]{.underline}
50](#_Toc479279456)

表格索引 {#表格索引 .-1}
========

[[表1.1中国各类在线应用用户规模和使用率统计]{.underline}
2](#_Toc479170753)

[[表4.1 K-means方法优缺点与层次聚类方法优缺点比较]{.underline}
27](#_Toc479170754)

[[表4.2建立类别映射向量算法]{.underline} 31](#_Toc479170755)

[[表4.3粗划分文本数据集算法]{.underline} 32](#_Toc479170756)

[[表4.4质心一次约束提取初始质心算法]{.underline} 33](#_Toc479170757)

[[表4.5质心二次约束提取初始质心算法]{.underline} 34](#_Toc479170758)

[[表4.6质心最大间隔提取初始质心算法]{.underline} 35](#_Toc479170759)

[[表4.7细划分文本数据集算法]{.underline} 36](#_Toc479170760)

[[表4.8 AHK-P算法]{.underline} 38](#_Toc479170761)

[[表5.1实验环境配置]{.underline} 39](#_Toc479170762)

[[表5.2搜狐新闻网类别与URL映射关系]{.underline} 40](#_Toc479170765)

[[表5.3分类词库格式介绍]{.underline} 40](#_Toc479170764)

[[表5.4新闻文本数据格式介绍]{.underline} 41](#_Toc479170763)

[[表5.5文本分词示例]{.underline} 42](#_Toc479170766)

[[表5.6词库词汇统计信息示例]{.underline} 43](#_Toc479170767)

[[表5.7文本词汇特征值统计示例]{.underline} 44](#_Toc479170768)

[[表5.8建立类别映射向量信息示例]{.underline} 44](#_Toc479170769)

[[表5.9抽样数据构成成分]{.underline} 50](#_Toc479170770)

[[表5.10各类与真实质心平均距离]{.underline} 50](#_Toc479170771)

[[表5.11各方法质心与真实质心平均距离]{.underline} 50](#_Toc479170772)

[[表5.12各类别文本构成数量统计]{.underline} 51](#_Toc479170773)

[[表5.13各类文本准确率统计结果]{.underline} 52](#_Toc479170774)

[[表5.14各类文本回归率统计结果]{.underline} 52](#_Toc479170775)

[[表5.15各评价数据平均值]{.underline} 52](#_Toc479170777)

符号对照表 {#符号对照表 .-1}
==========

聚类簇

文本距离

评价系数

质心集合

文本聚类数

簇内平均距离

簇内数据对象数

准确率

回归率

特征词汇

抽样数据集合

单词抽样数据

文本词汇

初始质心集合

统计加权值

文本数据集

文本映射集

缩略语对照表 {#缩略语对照表 .-1}
============

AHC Agglomerative Hierarchical Clustering 凝聚层次聚类

BFS Breadth First Search 广度优先搜索

CPCC Cophenetic Correlation Coefficient 同表象相关系数法

DAG Directed Acyclic Graph 无回路有向图

DM Data Mining 数据挖掘

DFS Depth First Search 深度优先搜索

IDF Inverse Document Frequency 逆文本频率

IE Information Extraction 信息抽取

IP Internet Protocol 网际互联协议

IR Information Retrieval 信息检索

LSI Latent Semantic Indexing 潜在语义索引模型

ML Machine Learning 机器学习

NLP Natural Language Processing 自然语言处理

TF Term Frequency 词频

URL Uniform Resource Locator 统一资源定位符

VSM Vector Space Model 向量空间模型

目录

[[摘要]{.underline} I](#摘要)

[[ABSTRACT]{.underline} III](#_Toc479525118)

[[插图索引]{.underline} V](#_Toc479525119)

[[表格索引]{.underline} VII](#表格索引)

[[符号对照表]{.underline} IX](#符号对照表)

[[缩略语对照表]{.underline} XI](#缩略语对照表)

[[第一章]{.underline} [绪论]{.underline} 1](#_Toc479525123)

> [[1.1]{.underline} [研究背景]{.underline} 1](#研究背景)
>
> [[1.2]{.underline} [研究目的和意义]{.underline} 2](#研究目的和意义)
>
> [[1.3]{.underline} [国内外研究现状]{.underline} 4](#国内外研究现状)
>
> [[1.4]{.underline} [本文主要工作及创新点]{.underline}
> 5](#本文主要工作及创新点)
>
> [[1.5]{.underline} [本文结构安排]{.underline} 6](#本文结构安排)

[[第二章]{.underline} [文本聚类概述]{.underline} 7](#文本聚类概述)

> [[2.1]{.underline} [文本聚类概念]{.underline} 7](#文本聚类概念)
>
> [[2.2]{.underline} [文本聚类流程简介]{.underline}
> 7](#文本聚类流程简介)
>
> [[2.3]{.underline} [文本聚类关键技术]{.underline}
> 8](#文本聚类关键技术)

[[2.3.1]{.underline} [文本特征提取]{.underline} 8](#文本特征提取)

[[2.3.2]{.underline} [文本表示]{.underline} 9](#文本表示)

[[2.3.3]{.underline} [文本聚类算法介绍]{.underline}
10](#文本聚类算法介绍)

[[2.3.4]{.underline} [文本聚类评估方法]{.underline}
12](#文本聚类评估方法)

> [[2.4]{.underline} [本章小结]{.underline} 14](#本章小结)

[[第三章]{.underline} [互联网新闻文本获取与预处理]{.underline}
15](#互联网新闻文本获取与预处理)

> [[3.1]{.underline} [网页采集]{.underline} 15](#网页采集)
>
> [[3.2]{.underline} [互联网新闻文本预处理]{.underline}
> 17](#互联网新闻文本预处理)

[[3.2.1]{.underline} [WEB信息抽取]{.underline} 17](#web信息抽取)

[[3.2.2]{.underline} [中文分词]{.underline} 17](#中文分词)

[[3.2.3]{.underline} [词频统计与TF-IDF文本特征提取]{.underline}
18](#词频统计与tf-idf文本特征提取)

[[3.2.4]{.underline} [基于向量空间模型的文本表示]{.underline}
20](#基于向量空间模型的文本表示)

[[3.2.5]{.underline} [文本距离计算]{.underline} 21](#文本距离计算)

[[3.2.6]{.underline} [余弦距离稀疏化计算]{.underline}
22](#余弦距离稀疏化计算)

> [[3.3]{.underline} [本章小结]{.underline} 25](#本章小结-1)

[[第四章]{.underline} [AHK-P聚类算法设计]{.underline}
27](#ahk-p聚类算法设计)

> [[4.1]{.underline} [传统H-K方法实现过程与不足]{.underline}
> 27](#传统h-k方法实现过程与不足)
>
> [[4.2]{.underline} [AHK-P算法设计思路]{.underline}
> 29](#ahk-p算法设计思路)

[[4.2.1]{.underline} [基于先验知识粗划分文本数据集]{.underline}
30](#基于先验知识粗划分文本数据集)

[[4.2.2]{.underline} [优化初始质心提取过程]{.underline}
32](#优化初始质心提取过程)

[[4.2.3]{.underline} [基于先验知识细划分文本数据集]{.underline}
36](#基于先验知识细划分文本数据集)

> [[4.3]{.underline} [AHK-P具体算法设计]{.underline}
> 37](#ahk-p具体算法设计)
>
> [[4.4]{.underline} [本章小结]{.underline} 38](#本章小结-2)

[[第五章]{.underline} [新闻文本聚类算法实现与实验验证]{.underline}
39](#新闻文本聚类算法实现与实验验证)

> [[5.1]{.underline} [工作平台与实验数据]{.underline}
> 39](#工作平台与实验数据)

[[5.1.1]{.underline} [工作平台]{.underline} 39](#工作平台)

[[5.1.2]{.underline} [实验数据]{.underline} 39](#实验数据)

> [[5.2]{.underline} [新闻文本聚类算法实现]{.underline}
> 41](#新闻文本聚类算法实现)

[[5.2.1]{.underline} [文本数据预处理]{.underline} 41](#文本数据预处理)

[[5.2.2]{.underline} [AHK-P算法实现]{.underline} 45](#ahk-p算法实现)

> [[5.3]{.underline} [实验评价方法]{.underline} 48](#实验评价方法)
>
> [[5.4]{.underline} [实验设计与结果分析]{.underline}
> 49](#实验设计与结果分析)

[[5.4.1]{.underline} [初始质心提取对比实验]{.underline}
49](#初始质心提取对比实验)

[[5.4.2]{.underline} [AHK-P算法有效性验证实验]{.underline}
51](#ahk-p算法有效性验证实验)

> [[5.5]{.underline} [本章小结]{.underline} 53](#本章小结-3)

[[第六章]{.underline} [总结与展望]{.underline} 55](#总结与展望)

> [[6.1]{.underline} [总结]{.underline} 55](#总结)
>
> [[6.2]{.underline} [展望]{.underline} 55](#展望)

[[参考文献]{.underline} 57](#参考文献)

[[致谢]{.underline} 61](#致谢)

[[作者简介]{.underline} 63](#作者简介)

绪论
====

研究背景
--------

中国互联网经过二十多年发展，依托中国社会飞速发展取得的丰硕成果，在基础网络建设和创新应用方面取得了长足的进步。互联网应用已经渗透到中国经济和社会的各个领域，在改变中国人传统生活方式的同时也不断为中国经济带来新的增长点。随着互联网与传统行业的深入融合，促使中国互联网用户总量呈现井喷式增长，中国互联网用户群体已经成为了当今世界上规模最大的用户群体^\[1\]^。据最新发布的互联网统计报告显示，2016年我国新增互联网用户4299万，同比去年增长了6.2%，用户总量达到7.31亿，普及程度达到53.2%，与全球平均水平相比高出3.1%，与亚洲平均水平相比高出7.6%。中国使用互联网的人数已接近于欧洲人口总数^\[2\]^。

[\[CHART\]]{.chart}

[]{#_Toc479279430
.anchor}图1.1中国互联网各年度用户使用人数和普及程度统计

最新统计数据显示，即时通信、网络新闻、搜索引擎、网络视频和网络音乐的用户规模分别在互联网应用排名榜单的前五位，五类应用的用户规模均突破了5亿。同时，中国互联网用户中大约有6.14亿上网用途是浏览网络新闻，用户规模达到总使用人数的84%，与2015年相比增长8.8%，呈现每年快速递增的趋势。同时与2015年相比，网络新闻的用户规模上超过了搜索引擎，排在各类在线应用使用频次榜单第二位。由表1.1统计数据可见，互联网成为了当今新闻媒体信息发布和用户浏览新闻的主要载体。互联网技术使用的便捷性促使新闻传播更加快速，新闻总量呈井喷式发展，极大满足了用户的阅读需求，与此同时为传统新闻媒体行业表现形式创新和发展提供了一个良好的契机。

[]{#_Toc479170753 .anchor}表1.1中国各类在线应用用户规模和使用率统计

             **2016年**   **2015年**                                 
  ---------- ------------ ------------- -------------- ------------- -------------
  应用       用户数(万)   使用率（%）   用户数（万）   使用率（%）   增长率（%）
  即时通信   66628        91.1          62408          90.7          6.8
  搜索引擎   61390        84.0          56400          82.0          8.8
  网络新闻   60238        82.4          56623          82.3          6.4
  网络视频   54455        74.5          50391          73.2          8.1
  网络音乐   50313        68.8          50137          72.8          0.4
  网上支付   47450        64.9          41618          60.5          14.0
  网络购物   46670        63.8          41325          60.0          12.9
  网络游戏   41704        57.0          39148          56.9          6.5
  网上银行   36552        50.0          33639          48.9          8.7
  网络文字   33319        45.6          29674          43.1          12.3

互联网新闻作为一个基础的互联网应用，已经发展到比较成熟的阶段。互联网新闻文本成为了互联网文本库的一个重要的组成部分，新闻文本数据包含的类别信息蕴含着社会热点、商业行情和民生民情状况等重要潜在信息，为中国确定社会发展方向具有重大的引导价值。与此同时，最近几年以来，随着互联网移动设备与传统媒体行业的深入融合，许多互联网新闻服务提供商开始借助公共平台实时为用户推送长篇新闻。新闻报道内容和阅读量成为各大新闻服务提供商之间重点竞争的焦点。由于平台的互动性，新闻服务对象趋于个体化，如何为用户提供精准的分类新闻文本成为了一个重点关注的问题。

互联网新闻新的存在形式又为文本分析创造了一个新的应用环境，如何快速、准确地划分新闻文本类别再次引起了文本分析领域的兴趣。

研究目的和意义
--------------

文本分析（Text
Analytics），作为一个发展历程只有十五年的新兴研究领域，是指在海量文本数据中提取高质量信息的过程。高质量信息指源数据中具有潜在关联度、新颖性和符合用户需求等特点的信息。文本分析因在自然语言处理、数据挖掘、信息检索和机器学习等研究方向广泛使用而备受重视^\[3\]^。文本分析涉及领域如图1.2所示。

文本挖掘处理过程一般包括源文本数据结构化处理、结构化数据模式发现、主题发现和评估结论等，由此也产生了几个比较经典的研究领域：文本分类、文本聚类、概念与实体抽取、文档摘要提取、实体关系建模、语义分析等。本文研究主旨是互联网新闻类别的发现，所以本文研究主要聚焦于文本聚类。

[]{#_Toc479279431 .anchor}图1.2文本挖掘领域相关技术

文本聚类（Text Clustering），或文档聚类（Document
Clustering），是文本挖掘领域最早诞生的一项技术之一，通常被应用于文本分析的预处理阶段^\[4\]^。文本聚类在文本自动化组织、主题发现、优化搜索引擎和信息快速检索等研究领域被广泛使用，经常被用来聚合相似文本、分析用户行为和发现潜在主题等。

互联网存储的文本信息量巨大，但大多文本都是无结构的数据^\[5\]^，不能直接参与数据分析的工作，因此极大程度上降低了数据的可用性。文本聚类可以将无结构化数据转化为结构化数据，发现文本数据潜在结构特征然后提取有用知识，最终实现对文本数据分门别类的目标。互联网新闻信息主要以文本形式存在，具有更新速度快、实时聚焦社会热点和用户群体庞大等特点。互联网海量文本数据结合文本聚类分析技术，能够快速实现自动化主题提取、筛选有效信息、优化搜索结果和灵活处理用户需求等现实应用。

文本聚类分析广泛应用于政府部门政策制定、学术研究和商业数据分析等领域，是一种非常重要的针对无结构化数据知识发现的分析方法。文本聚类方法是聚类分析过程重要的技术环节，而基于层次的聚类方法和基于划分的聚类方法在距离计算方式上的简洁性和灵活性使其在聚类分析领域应用广泛。基于层次的聚类方法虽然聚类准确，应用方便，但时间代价大，而基于划分的聚类方法虽然具有收敛快速的特点，但初始质心的不确定性严重影响了聚类结果的可靠性。针对互联网新闻海量文本数据的构成特点，结合文本数据的先验知识降低聚类方法时间复杂度和提高提取初始质心的合理性，继而提高聚类质量，不仅对于改进聚类算法具有重要的研究意义，而且对于利用互联网新闻文本进行社会热点发现和舆情分析等应用领域具有重要的实用意义。

国内外研究现状
--------------

目前欧美发达国家研究机构在文本聚类分析方面研究成果巨大，不仅在理论方面研究层次不断深入，而且在文本分析应用过程中不断实践最新技术，应用范围包括：信息检索领域里的文档收集、分散收集等，自然语言处理领域的自动化批量文摘提取、舆情监控、高质量信息抽取与过滤等。在文本挖掘领域，国内还处在追赶国外先进技术的成长阶段，大多采取先引进再做兼容性改进的策略开展文本分析的研究工作。

在自动文摘研究领域，Yang等提出和设计了一种基于句子排名的文本聚类方法以实现摘要提取^\[6\]^。Ferreira等提出和设计了一种使用统计方法和语言学知识以实现多文档摘要提取的文本聚类方法^\[7\]^。Kedzie等提出和设计了一种依据灾害特征模型实时收集和更新灾害事件摘要的方法，该方法通过文本聚类挑选最新和关联度高的语句以提高摘要的质量和实时性^\[8\]^。

在信息检索研究领域，Conrad等提出和设计了一种采用半监督式事件文本聚类的信息检索方法^\[9\]^。Liu等提出和设计了一种通过构建语言模型用于检索的文本聚类方法^\[10\]^。Levi等提出和设计了一种使用选择性聚类技术进行文档检索的方法^\[11\]^。Chifu等提出和设计了一种使用谱聚类进行语义消歧的信息检索方法^\[12\]^。

在关联规则挖掘研究领域，Chalaris等通过对学生问卷信息进行文本聚类的方法发现学生未顺利毕业的原因^\[13\]^。Ordonez等提出和设计了一种使用聚类和关联度技术发现和提取关联规则的建模方法^\[14\]^。Li等提出和设计了一种通过聚类和软集技术发现和提取关联规则的方法^\[15\]^。

在提升文本分类效果研究领域，Zhang等提出和设计了一种使用半监督式聚类方法分析文本成分，以提升文本分类质量的方法^\[16\]^。Thomas等提出和设计了一种使用聚类技术生成分类模型的方法^\[17\]^。Shafiabady等提出和设计了一种使用聚类训练支持向量机进行文本分类的方法^\[18\]^。LEE等提出和设计了一种借助模糊聚类提升分类效果的方法^\[19\]^。

在文档收集研究领域，Cevahir提出和设计了一种使用K-means算法进行可伸缩相似文本查找大规模文档并收集的方法^\[20\]^。Hourdakis等提出和设计了一种应用于医学文献收集领域的基于层次聚类算法的文档收集方法^\[21\]^。Kishida提出和设计了一种使用粗聚类算法进行大规模文档收集的方法^\[22\]^。

在商业领域内，国外许多著名公司和机构利用文本聚类技术面向内部和客户开展数据分析的业务。如IBM的SPSS统计分析软件，通过聚类分析等过程为用户提供数据识别和预测分析的服务；由赛仕软件研究所开发的SAS软件套件，通过文本挖掘提供多变量统计分析、商业智能、数据管理和预测分析等服务；RapidMiner公司同样依靠先进的文本挖掘技术提供相似的数据服务。国内方面，百度结合大数据分析开展舆情监控、商业精准营销和个性化搜索等服务，网易易盾通过文本分析技术提供反垃圾文本的服务。

在安保领域，文本挖掘同样发挥着巨大作用，如美国的ECHELON系统和欧洲的OASIS系统利用文本挖掘进行敏感数据拦截、通信监控、情报分析和紧急预警等工作^\[23\]^。

本文主要工作及创新点
--------------------

通过浏览文献对传统聚类算法原理深入了解，以及对近年来国内外在算法改进研究方面深入学习的基础上，本文挑选在聚类分析过程中使用广泛，在文本距离计算和改进测试方面都比较简单灵活，使用层次聚类方法和K-means算法进行混合聚类的方法，作为本文面向互联网新闻文本开展聚类研究工作的关键方法。

本文主要工作：在总结已有的文本聚类技术和借鉴前人工作的基础上，详细阐述了文本聚类的基本原理和基本流程，继而开展针对文本聚类的研究工作。首先对文本预处理过程的文本特征提取、文本表示和文本距离计算等环节深入研究，并基于文本特点简化距离计算的复杂度，提高文本预处理的效率；其次以类别角度划分过程中结合先验知识提升划分的准确性和文本聚类的质量；最后针对文本聚类算法的改进之处的有效性开展实验对比和实验验证工作。

本文在深入研究H-K方法基本原理以及其在文本聚类工作中重要性的基础上，提出和设计了AHK-P算法，该算法通过先验知识提升文本聚类过程中识别文本类别属性的能力，改善提取初始质心的合理性，优化距离计算方法，提高文本聚类结果的质量。本文提出和设计的AHK-P算法创新之处主要有以下三个方面：

（1）在使用层次聚类方法凝聚文本过程中结合先验知识以类别角度快速划分文本数据集，降低文本处理的复杂度，提高计算速度，同时预先为文本添加一定的类别属性。

（2）结合文本类别特征和个体特征优化初始质心提取过程，使提取的初始质心之间的类别差异性尽可能大，提升提取结果的合理性。

（3）在使用K-means算法划分文本数据集过程中，结合先验知识使用改进的文本距离计算方法，提升划分文本过程中算法发现相似文本、区分不相似文本的能力。

本文结构安排
------------

本文由六章构成，主要内容结构如下：

第一章是绪论。首先在总结中国互联网发展现状和分析互联网文本重要性的前提下，重点阐述了面向互联网新闻文本聚类的研究意义和目的；其次在文本聚类研究领域分别介绍了当前国内外学术机构人员和数据公司最新工作成果和现实应用情况；最后针对本文主要工作、创新点和每章的研究内容情况进行了简要概括。

第二章是文本聚类概述。首先根据本文研究重点，简述了文本聚类技术的概念；其次总结了文本聚类研究的数据处理流程；最后重点阐述了文本聚类研究过程中几个重要的技术环节，如文本预处理、基于不同实现原理的聚类算法介绍和评价方法等。

第三章是互联网新闻文本获取与预处理。首先介绍了用于获取文本数据的网页采集技术，并详细说明了实现网页采集技术的主要方法；其次详细阐述了新闻文本预处理的关键技术环节，包括信息抽取、中文分词、词频统计、文本特征提取、文本表示和文本距离计算等过程；最后依据本文文本数据的特点，在文本距离计算过程中做出了相应的优化和改进。

第四章是AHK-P聚类算法设计。首先详细阐述了H-K方法用于聚类分析的基本原理和流程；其次通过分析H-K方法优缺点和总结传统文本聚类方法在特征提取、文本距离计算和提取初始质心等技术环节的特点，提出了结合先验知识提升提取初始质心合理性和优化文本距离计算方法的改进方案的AHK-P算法；最后详细介绍了实现AHK-P算法的设计方案。

第五章是新闻文本聚类算法实现与实验验证。首先详细介绍了实现AHK-P算法的关键过程和后续实验准备工作；其次设计了两组对比验证实验：一是AHK-P算法与K-means算法和传统H-K方法在提取初始质心环节上合理性的对比实验，二是AHK-P算法与K-means算法和传统H-K方法在聚类结果质量上的对比实验；最后通过统计和分析实验结果，对比实验数据，证明了AHK-P算法改进之处的有效性和高效性。

第六章总结与展望。在总结本文工作内容前提下，首先阐述了本文研究过程中取得的工作成果；其次针对现实应用，指出了本文方法的可改进之处；最后对未来文本聚类技术的发展方向和工作重点作出了一定程度上的预测和设想。

文本聚类概述
============

文本聚类概念
------------

文本聚类是对无结构化或半结构化文本数据进行潜在信息提取和分析的研究方法。在文本分析领域，文本聚类通常被作为一项文本预处理技术，在信息检索、自然语言处理和机器学习等领域应用广泛，具有极其重要的学术价值和应用前景。聚类就是将相似的事物聚合在一起，将不相似的事物分散开来的过程^\[24\]\[25\]^。在数据处理过程中，高效而又实用的文本聚类方法能够自动化地将无序无结构化的文本数据最终整合成一个具有层次化和逻辑化数据结构的数据集，不仅加快计算机对文本数据的自动化检索速度，而且简化用户对文本数据的查阅工作。

文本聚类流程简介
----------------

[]{#_Toc479279432 .anchor}图2.1文本聚类流程

文本聚类关键技术环节处理流程如图2.1所示，原始文本数据在开始聚类分析之前，通常需要对文本进行预处理工作。中文文本预处理一般包括格式统一化、中文分词、文本特征提取和建立表示模型等过程，文本预处理的最终目标是将无结构化文本数据使用具有逻辑概念的数学模型进行表示，以便简化后续算法的设计。文本数据经过特定算法聚类分析后，最终被分为几类。最后使用合适的评价策略对结果进行分析和评价。

文本聚类关键技术
----------------

文本聚类是数据挖掘研究领域的研究重点，而设计一个性能优秀的文本聚类方法关键在于文本特征提取、使用数学模型表示文本、聚类算法设计和聚类质量评价等处理环节的优劣，这些环节不仅左右最终聚类结果的准确性，而且对文本聚类技术方法的推广使用也有着巨大的影响。

### 文本特征提取

文本数据大多是无结构化的字符串格式，其中很多词汇对于其主旨表达并无核心作用，在文本预处理过程中通常将其简化，从而使文本数据特征化。文本特征提取（Text
Feature
Extraction）是将文本数据进行数学化表示的重要前提，在不丢失文本核心内容前提下对文本数据进行压缩处理，使后续处理过程在减少系统资源消耗的同时，也能够最大程度上改善系统的运算速度。

文本特征提取对于使用数学形式表达文本内容和简化计算过程有着重要的研究和实践的价值^\[26\]^。首先特征项应具有准确体现文本内容的作用，同时也应具有区别其他文本的能力；其次特征项个数适中，处理过程简单；最后各特征项之间也应该是无关的。在中文文本中，一般以词作为文本的特征项，词表达语义的能力比单个字和长短语作用更加突出，同时也能够压缩特征项的数量。因此，很多文本预处理过程中都将特征词作为文本特征的组成部分，用来实现文本之间的距离计算。

当一篇文本被切割为以词为单位构成时，通常需要继续进行压缩内容的过程。这个过程就是特征提取，其作用是在保留文本主旨情况下压缩该文本包含的词汇总数，节省时间和充分利用系统资源，优化处理效率。文本特征提取过程通常需要针对词汇设计特定评估函数对其进行加权处理，然后提取指定数目高分项作为文本特征。评估加权的处理过程称为词汇加权，选取的得分较高的子项组合称为最优特征集^\[26\]^。文本特征提取过程如图2.2所示。以下简要几种常用的文本特征提取方法^\[27\]\[28\]^：

（1）基于统计的特征提取方法：该方法主要通过实现评分函数，对文本特征集中每个元素进行打分评价,然后提取高分值的特征项组成最优特征子集表达文本实体。这种方法实现原理简单，不依赖文本数据语言类别，但同时也有以下不足：特征项多导致计算量大、忽略低频词影响计算准确度。基于统计的特征提取方法主要有：TF-IDF、互信息和信息增益等方法。

（2）基于本体论的文本提取方法：该方法借助本体论知识创建词汇网络，实现计算特征项权重方法，进而表达文本特征，对所有特征项位置及关联性的充分理解，使文本特征提取结果更为精确。

（3）基于语境框架的文本特征提取方法：该方法通过构造语境内容实现语义提取算法对文本数据语义立场进行评估，具有情感分析、褒贬判断、同义理解等能力。

（4）基于知网的概念特征提取方法：该方法基于向量空间模型，通过相应的语义知识对文本内容包含词汇进行同义分析合并同义词，进而压缩向量维度，降低冗余度，使文本表达更加准确。

[]{#_Toc479279433 .anchor}图2.2文本特征提取流程

### 文本表示

> 文本表示是将以字符格式组成的文本信息转化为数字形式的特征信息并使用相对应的数学模型表达其实体存在的方法。文本数据经过加权处理和特征提取的过程，建立对应的数学模型，使自身具有结构化特点并可以直接参与数学计算，简化了数据处理过程。文本表示常用的方法有^\[29\]\[30\]\[31\]^：
>
> （1）布尔模型（Boolean
> Model）表示法是一种最简单的构建文本表示模型的方法。布尔模型使用布尔变量针对文本特征是否满足某一条件进行二值表示。当特征项满足条件时，表示为1，否则为0。布尔模型原理简单明了，计算时速度快，但是文本表达能力较差，缺乏灵活性。
>
> （2）向量空间模型（Vector Space
> Model）表示法在构建文本表示模型过程中假设文本各特征项之间线性无关，认为每个文本特征项在向量空间某一维度上都能够使用特定数值表示，同时文本使用这些矢量化的数据转化为空间内的一个特定向量。
>
> （3）概率模型（Probabilistic
> Model）表示法基于概率统计原则对特征项与文本之间的关系进行概率评估的方法。该方法采用特征项出现概率递减排队原则，然后通过概率做出相关性判断。该方法表达相关性比较灵活，能够发现文本词汇之间的相关性，比较全面的考虑了文本结构特点。
>
> （4）潜在语义索引模型（Latent Semantic Indexing
> Model）表示法是一种使用向量构建表示模型的优化方法，该方法使用统计方法，提取语义信息，发现和合并同义词，然后压缩向量表示的维度，从而降低冗余使文本表示更加简单和准确。

### 文本聚类算法介绍

文本聚类算法是文本聚类技术重要的组成部分，常用的文本聚类算法分为基于划分的聚类方法、基于层次的聚类方法、基于密度的聚类方法、基于网格的聚类方法和基于模型的聚类方法^\[32\]\[33\]^。

（1）基于划分的聚类（Partitional
Clustering）方法首先必须提取K个数据对象作为初始簇的质心，之后在迭代过程中依据数据点与质心最邻近原则不断更新簇结构，最终达到簇内对象分布紧密簇间对象远离的聚类效果。这种聚类方法为了能够达到全局最优的效果需要遍历所有划分的可能，计算量比较大，在实际应用时通常使用启发式方式进行改进。常用基于划分的聚类算法有：K-means算法、K-medoids算法等。

（2）基于层次的聚类（Hierarchical
Clustering）方法是指按照一定判断标准对处理对象按层级聚合或分裂的方法。"自顶向下"的方式对处理对象进行分裂的操作，"自底向上"的方式对象数据对象实现聚合的操作。使用"自底向上"方法时，开始时将处理对象中每一元素视为一个单独的簇，在之后处理过程中，通过优先聚合最相邻簇的方法，直到所有数据点聚合为一个簇为止。"自顶向下"方法的处理过程与"自底向上"方法的处理过程正好相反，采用分裂的办法最终将所有处理对象分裂为一个个仅有一个元素构成的簇。

基于层次的聚类方法在使用过程中非常灵活，不仅可以采用传统距离计算方式判断簇的关系，而且可以通过数据对象局部分离度和连通性来判断它们的相关性。基于层次的聚类方法不足之处是如果一个迭代过程完成，那么簇的分裂结果或聚合结果将是不可更改的。常用的基于层次的聚类算法有：BIRCH算法、CURE算法等。

（3）基于密度的聚类（Density-based
Clustering）方法是指通过某一区域数据点分布的紧密程度来构造簇的方法。该方法可以解决基于划分的聚类方法只能发现球形簇的缺陷。该方法实现的基本原理就是，如果在给定范围内数据对象的个数超过某一阈值，那么就将聚合到最相邻的簇中。基于密度的聚类方法聚类过程如图2.3所示。

[]{#_Toc479279434 .anchor}图2.3基于密度的聚类方法聚类过程示例

（4）基于网格的聚类（Grid-based
Clustering）方法通过将数据映射为空间内由相同单元组成的网格的处理方式，使其处理数据能以单元为单位进行。该方法处理数据速度与其规模大小没有关系，而仅仅与划分的单元数有关。如图2.4所示，基于网格的聚类方法能够以不同大小单元作为单位进行数据划分，所以处理速度较快。基于网格的聚类算法有：STING算法、CLIQUE算法等。

[]{#_Toc479279435
.anchor}图2.4基于网格的聚类方法以不同大小单元进行聚类示例

（5）基于模型的聚类方法（Model-based
Methods）在最开始时为每个簇构建对应的特征模型，在之后迭代过程中筛选符合条件限制的数据对象。模型的具体形式有很多种，常用的是数据空间内密度分布函数等，基于密度分布函数的模型假设前提就是提取的数据子集满足概率分布。基于神经网络模型的聚类方法如图2.5所示，通过计算层拓扑关系分类整理输入层的数据，整个过程模拟神经系统传递信号的过程。

[]{#_Toc479279436 .anchor}图2.5基于模型的聚类方法示例

### 文本聚类评估方法

文本聚类是为发现无结构化或半结构化文本数据潜在结构特征的分析过程。不管是否真正具有一定的结构特征，文本数据集经过聚类算法分析之后总会得到一个结构性的结论。不仅如此，不同类型算法或同一算法不同参数设置、数据排列顺序的不同也会使最终聚类结果不相同，因此文本聚类需要一定的技术方法对其处理结果进行评价以提升其结论的可信度。

评估方法必须是客观的，不因算法不同导致评价结果发生偏斜。评估方法经常用来回答诸如"数据中是否真的存在这样的划分结果？""数据中存在多少个类？"或者"为什么选择使用这个聚类算法？"的问题。通常评估方法分为外部评价方法和内部评价方法两种^\[34\]^。

（1）外部评价方法（External
Index）：依据先验知识获取处理数据的结构特征作为标准对划分结果进行评价。常用的外部指标评价方法有值、统计方法和杰卡德系数等方法。

值是一种非常常用的外部指标方法，依靠准确率（）和回归率（）进行统计分析工作。划分结果中类别的值计算方法如公式2-1所示：

假设为数据集先验模型，是聚类产生的模型，存在和属于，和存在以下四种情形：和属于中同一类，同时属于中同一类；和属于中同一类但不属于中同一类；和不属于中同一类但属于中同一类；和都不同属于和中任意一类。、、、分别表示上述四种情形出现的数量，表示所有情形的数量。以下列举几种常用的外部指标测量与模型的匹配度。

杰卡德系数（Jaccard coefficient）：

统计方法（statistics）：。

（2）内部评价方法（Internal
Index）：在完全独立于先验知识条件下直接对聚类后的数据结构特征进行评价。常用的方法包括轮廓系数法、CH指标、DB指标和同表象相关系数法四种。

轮廓指数（Silhouette
Coefficient）评估方法依据同一属性数据的内聚度和不同属性数据的分离度来评价聚类结果，可在同一数据实验基础原则下对不同算法、或者对同一算法下不同测试方式产生的实验结果进行评测。以下是轮廓系数公式：

代表数据对象总数，代表数据对象与本类其它构成元素距离之和的平均值，代表数据对象到其它类所有构成元素距离之和的平均值。轮廓系数取值最大为为1，最小为-1。当数值越大时表示对同一属性数据的内聚度和对不同属性数据的分离度的综合评估效果越好。

CH指标（Caliński-Harabasz index）：

其中，分别表示不同类之间的散度矩阵和同一类内的散度矩阵的迹。

DB指标（Davies-Bouldin Index）：

其中分别表示簇和簇内的平均距离，表示簇质心与簇质心的距离，表示簇与其它簇的最大差异度。

同表象相关系数法（CoPhenetic Correlation
Coefficient，CPCC）是对层次聚类算法聚类效果评价的一种方法。假设存在相似矩阵，同表象矩阵，中元素表示第一次数据点和被首次分在同一簇中的临近层，分别表示和的平均值，公式定义如下：

本章小结
--------

本章主要对现今文本聚类原理和处理流程进行总体介绍的工作。首先介绍了文本聚类的概念知识，其次简要说明了文本聚类的处理流程，最后详细阐述了文本聚类过程中的关键技术：文本特征提取、文本表示、五种常用的聚类方法以及对其处理结果的评价方法。

互联网新闻文本获取与预处理
==========================

互联网新闻文本通过网页采集技术从相关新闻门户网站获取，在应用于聚类分析之前，需要经过文本过滤、分词、提取文本特征和建立文本表示模型等预处理过程，从而使文本可以直接参与数学计算，简化处理过程。本章主要介绍互联网新闻文本获取和预处理过程中采用相关技术和工具，并针对新闻文本之间共现词汇少的特点提出和设计了一种在文本距离计算时采用稀疏化计算的改进方法。

网页采集
--------

网络爬虫是实现网页采集的主要技术方法，网络爬虫主要作用是将互联网网页保存到本地，然后组合成为一个包含html标签和信息文本的数据库。

网络爬虫工作基本原理：网络爬虫借助相关搜索遍历算法，借助指定网页链接以第一次获取网页作为根节点开始，依照搜索策略提取网页上新的网页链接添加到搜索队列。根据搜索队列的网页链接获取其对应服务器IP地址，并将对应的网页备份到本地然后归类整理，清除搜索队列里已遍历的网页链接后重复以上过程直到网页链接的搜索队列为空时结束网页采集过程^\[35\]^。爬虫的基本原理如图3.1所示。

[]{#_Toc479279437 .anchor}图3.1爬虫基本原理

网络爬虫按照相应的搜索策略爬取网页信息，搜索策略就是按照一定的顺序获取网页链接然后添加到搜索队列的方案，通常分为深度优先策略、宽度优先策略和最佳最优策略三种^\[35\]^。

（1）深度优先（Depth First
Search）策略是指从父节点遍历开始，然后最先遍历其最近子节点，子节点重复以上遍历过程直到根节点遍历完其子节点。以图3.2为例，A节点作为根节点。

[]{#_Toc479279438 .anchor}图3.2深度优先搜索顺序

[]{#_Toc479279439 .anchor}图3.3宽度优先搜索顺序

（2）宽度优先（Breadth First
Search）策略是指从遍历父节点开始优先遍历完父节点所有子节点之后再遍历所有子节点的子节点，直到遍历完所有节点。以图3.3为例，A节点作为根节点。当需要获取尽量多页面时，通常采用宽度优先策略实现网络爬虫^\[36\]^。

（3）最佳优先（Best-first
Search）策略在采用一些先验知识情况下首先评估候选网页的权重，然后只搜索高权重网页。这种方法优点明显，搜索速度快，但在评估方法不当情况下，也容易忽略很多相关网页，通常改进方法是结合现实应用环境选择最佳评估方法^\[37\]^。

互联网新闻文本预处理
--------------------

### WEB信息抽取

信息抽取（Information
Extraction）是指根据一定规则将信息从文本中提取出来，然后通过统一格式化处理的方式，组合成一个线下文本库以方便用户后续进行查询和比较工作^\[38\]^。

互联网近十年来的迅速发展为社会创造了一个巨大的在线文本库，由于同一主题的内容通常分布在不同站点上，造成信息表达形式不统一，所以在网页采集过程中获得的信息结构也就存在不一致的情况。信息抽取可以将无序的文本内容进行统一格式化处理，转化为具有同一逻辑概念的文本组织形式。在互联网海量文本库中使用信息抽取技术将使获取指定信息的整个过程变得完全简便化、自动化。

信息抽取技术按照实现方法原理不同分为基于规则的方法、基于自然语言信息的方法和基于统计的方法等^\[39\]^。本研究在结合网页的特点和实验平台的情况下，采用基于正则表达式规则信息抽取的方法。通过使用awk和sed等工具对新闻网页标签进行分析，提取新闻文本的题头和正文部分进行统一的结构化处理。

awk工具语法简单一致，只有awk \'{\<匹配模式\>\<执行动作\>}\' 和awk
\'\<匹配模式\>
{\<执行动作\>}\'两种语法形式，工作原理是根据模式匹配扫描输入数据的每一行，匹配指定内容后然后执行指定指令，否则继续处理下一行输入内容。

awk具有强大的文本处理功能，是包括Linux
在内许多平台中使用最为广泛、功能最为强大的文本处理工具之一。实际上，awk也是一种具有独立编程语言的工具，其中编程语言类似Shell，正式名为样式扫描处理语言，awk通过提供样式包装、流控制、数学运算、进程控制、变量函数使用等功能使其具备了数据处理过程中丰富而精美的特性^\[40\]^。

### 中文分词

中文分词（Chinese Word
Segmentation）是将汉字字符串按照语法规范以单词作为划分单位进行划分的过程。常用分词方法根据不同的实现原理分为下面几种^\[41\]^：

（1）基于字符串匹配的方法：该方法应用词法知识、字典知识或及其它知识进行分词，这种方法简单高效,但汉语知识结构复杂多样，在知识完备性、规则统一性等问题上使其难以灵活高效的处理大批量文本。

（2）基于统计的方法：该方法主要基于词频统计的方法进行分词，如把临近的词汇关系、词频及相应的组合情况等应用到分词过程中，这些信息基本上通过研究真实数据可以轻松获得，所以这种分词方法在应用比较广泛。

（3）基于知识理解的方法：该方法实际上是一种分析文本词汇构成的构词方法，即整个过程分解为字在文本构成中的标注问题，分词时认为字在特定词汇中都存在着一个词位，通过不同词位的标注将不同的词汇分离。

本文在文本预处理过程借助了开源项目Jieba中文分词系统对互联网新闻开展中文分词处理工作。Jieba中文分词系统同时提供有词性标注、停用词过滤、关键字提取和比较文本相似度等扩展应用功能，具有开源使用、分词处理快速和分词效果较好等优点。现挂载在GitHub平台进行管理。

Jieba中文分词系统是一种基于python脚本语言编写的开源库，其代码逻辑清晰，应用过程中扩展性较好，通过对记录词汇和未记录词汇进行相关算法分析。Jieba中文分词系统分词具体过程如下：

首先载入词典和输入文本数据，划分句子，去除一定数量停用词后，根据词典知识勾勒出该句子的有向无环图（DAG）；其次对于未记录词汇使用基于隐式马尔科夫模型的viterbi算法进行中文分词，全部分词完毕后使用动态规划方法求取有向无环图的最大概率路径；最后输出分词结果。

本文使用Jieba中文分词系统对文本数据进行中文分词，文本数据先后经过新闻文本分词，去停用词，词性标注等过程将新闻文本处理为可分割的词汇集合。Jieba分词工具处理一万篇新闻文章只需要30s左右，运行速度快，分词结果良好。

### 词频统计与TF-IDF文本特征提取

词频（Term
Frequency）是指某一词汇包含在某一文本中的个数。词频统计对于后续计算词汇权重、提取文本特征、建立文本表示模型具有重要的作用。新闻文本经过中文分词处理后变为由一个一个词汇组成的词汇集合，这时进行词频统计可以将词库内出现频率低、覆盖程度小的词汇过滤掉，从而降低文本距离计算过程的资源消耗。本研究过程中使用awk工具统计词汇信息，将新闻文本经过中文分词后出现的词汇汇总为一个总词库，总词库中每条记录包含词汇序号、汉字词汇、词汇总频率、词汇包含文本数。

本文在互联网新闻文本预处理过程中使用TF-IDF方法进行文本特征提取工作。TF-IDF包含的TF是指某一文本特定词汇出现的数目，IDF是指词库中所有文本个数与包含某一词汇所有文本个数比值的对数，称为逆文本率（Inverse
Document
Frequency）^\[42\]^。TF-IDF统计方法将以上两个数值相乘，其主要意义是：对于包含在某一文本中的指定词汇的TF-IDF统计结果大小同该词汇的词频成正比，同其在整个词库中的文本频率成反比。通俗来说，当词汇在整个词库中出现过于普遍，那么认为该词汇不具有特定类别的特征，而当其在某一文本中出现频率高时，那么认为该词汇对于提取这一文本的特征作用就更加重要。

经过中文分词处理后，很多无核心语义的常用词都被过滤掉，剩下的词汇都被称为构成本篇文本的词汇。TF-IDF首先通过统计词汇在一个文本出现的数目来确定其在单个文本中的比重，其次通过统计词汇在词库中出现的文本个数来确定其在本类文章中的比重，最后根据文本词汇两个比重值，采取乘法计算实现加权操作。TF-IDF公式：

代表第个文本中标号为的词汇权重。代表第个文本中标号为的词汇个数。表示第个文本词汇总数。表示包含标号为词汇的文本总数。表示所有文本总数。

在对文本预处理研究过程中，文本是由特征词汇组成的集合，词库是由所有构成文本的词汇构成的集合。文本之间相互独立，同样词汇之间也相互独立，也就是某一文本的出现概率不受其它文本影响，某一词汇的出现概率不受其它词汇影响。正因为如此，文本出现概率公式可以表示为：

表示文本的出现概率，表示词汇包含在文本中的出现概率。两边取对数：

文本中有很多词汇出现不止一次，简化后：

词频处理后：

表示文本的总数，表示包含该词汇文本的总数，对于文本中词汇的出现概率计算方法为。

是一个负数，对公式两边取反：

词库中序号为的词汇在序号为的文本中权重为：

TF-IDF统计方法具有易于理解，计算简单快捷，提取文本特征准确的优点，能够有效的将文字构成的文本轻松转化为数字表示，是一种针对文本常用的加权方法。所有文本经过中文分词、词汇频率统计后，首先将词库中文本频率过大和出现文本数过小的词汇过滤掉，其次使用TFIDF统计方法为每个词汇计算权重值，最后在将加权的词汇视为特征的基础上建立特征集合，作为文本特征。

### 基于向量空间模型的文本表示

文本表示（Text
Representation）是将以字符格式组成的文本信息转化为数字形式的特征信息并使用相对应的数学模型表达其实体存在的方法。文本经过数学形式的转化，简化了文本处理过程，明确了文本数学运算中的逻辑概念。常用的文本表示模型有向量空间表示型、布尔表示型、概率表示型以及混合表示型等，向量空间表示模型是一种非常经典的且应用比较广泛的文本建模方法^\[42\]^。向量空间模型如图3.4所示。

向量空间模型（Vector Space
Model）在构建文本模型时使用统计的方法的表示文本，其主要思想是：文本可以使用数学形式的向量进行表示，向量空间内各个维度代表规范矢量化的词汇。文本表示向量，文本表示向量中每个维度由特征词汇和其权重值组成的二元组构成。特征词汇权重值通过相应的统计方法得到，统计方法的基本原则：首先能够表达文本词汇构成特点；其次能够区分其他文本，尽可能保持文本之间的独立性。向量空间表示模型方法能够将无预先认识结构的文本数据批量转化为向量模型，便于数据计算。

向量空间表示模型使得文本内容转化为数学上可以计算处理的数学模型，将文本内容结构组织更加逻辑化。但是不可避免，由大量正交矢量化词汇组成的文本表示向量的维数过于庞大，在处理计算时不仅耗费资源和时间，也极有可能影响计算的准确性。鉴于以上情况，在判断文本相似性之前需要对文本表示向量采取降维优化处理。通常情况下根据文本中特征词汇统计权重值进行排序处理，研究文本构成特点，根据实际情况截取制定个数词汇作为文本的特征集。

[]{#_Toc479279440 .anchor}图3.4向量空间表示模型

文本之间由于共现特征词汇比较少，所以每个文本表示向量中有很多词汇代表的维度值为0，因此可以用稀疏向量表示法表示文本。这样可以节省内存空间，同时在计算处理是可以加快程序的运行效率。

向量经过稀疏化表示为：，表示某一词汇在指定文本范围内存在情况下的统计信息。以上方法不仅节省了内存空间，同时缩短了聚类过程中因大量计算消耗的时间。

### 文本距离计算

文本距离（Text
Distance）指的是文本经过数学模型表示后通过一定方法计算文本之间的差异性，以相似性角度看待文本也叫文本相似度，与文本距离的数值表示意义截然相反。

本文在文本预处理过程采用向量空间模型进行构建文本的表示模型，所以采用了基于距离的方法判断文本相似性。通常方法有：欧氏距离方法、曼哈顿距离方法、Jaccard距离方法和余弦距离方法等^\[43\]^。下面简要介绍几种距离计算方法：

欧氏距离（EuclideanDistance）方法：欧氏距离是指在维空间内计算对象之间以各维度上差值平方的累加和的算数平方根。在文本聚类中，由于文本长度不一，使用欧氏距离会造成较大误差，通常计算距离之前需要归一化向量。欧氏距离计算方法如公式3-8所示：表示点，表示点。

曼哈顿距离（Manhattan
Distance）方法：是指计算对象在各维度上差值的绝对值之和。曼哈顿距离计算方法如公式3-9所示，表示，表示。

余弦距离（Cosine
Distance）方法：余弦距离是指1减去计算对象之间的余弦值。距离计算方法如公式3-10所示，为，为。

Jaccard距离（Jaccard
Distance）方法：Jaccard距离在数值表达上即为1减去Jaccard相似系数。Jaccard距离计算方法如公式3-11所示，表示向量，表示向量。

### 余弦距离稀疏化计算

本文使用向量空间模型构建文本表示的模型，同时使用余弦计算方式进行文本距离计算。在文本预处理过程中，根据余弦距离计算方法的特点对文本表示和文本距离计算进行了稀疏化改进。

首先采用稀疏向量的表示方法进行文本表示；其次为文本词库中所有词汇分配唯一的序号并在每个经过中文分词处理和词频统计处理之后的新闻文本中按照词汇序号递增排列词汇；最后对任意两个文本之间进行余弦距离计算时，在求取文本表示向量的模长后只对两个文本共现的词汇进行同维度权重值相乘操作。

图3.5为编号ffcc18539a831c96-60413306c0bb3300的新闻文本（左）和编号ff98efc697831c96-60413306c0bb3300的新闻文本（右）共现关系示例，两个文本中共现词汇有序号为6、20、22、23、41、72、74、83、84、158和176一共11个，所以求取两个文本的表示向量内积只需计算11次。相对于文本包含的上百个不同词汇，只计算共现词汇极大减少了计算量。

[]{#_Toc479279441 .anchor}图3.5共现词汇示例

利用文本稀疏化向量进行文本表示，结合大多数文本之间共现词汇比较少和余弦计算方法的特点，采用稀疏化计算方法可以节省超过90%的计算量，运算效率明显提高。现详细说明其改进原理。

如图3.6所示，i与j分别表示文本a与文本b的词汇索引，数字代表每个词汇的唯一序号，新闻文本中的所有词汇按照序号递增排列，初始计算时索引都位于文本的第一个词汇的位置。

当文本a表示向量当前维度词汇索引序号1小于文本b表示向量对应的词汇索引序号2时，i为当前控制索引，向后移动直到词汇序号大于等于j对应的词汇序号。此时当前索引变为j。

[]{#_Toc479279442 .anchor}图3.6计算示例1

如图3.7所示，文本a中i对应序号8大于文本b中j对应序号2时，j向后移动直到词汇序号大于等于i对应的词汇序号。此时索引控制权交还文本X，i又变为当前索引。

[]{#_Toc479279443 .anchor}图3.7计算示例2

[]{#_Toc479279444 .anchor}图3.8计算示例3

如图3.8所示，文本a中索引i向后移动直到对应序号与文本b索引j对应序号相同时，表示两个词汇相同，分别使用词汇加权值进行相乘操作，将乘积结果计入两个文本表示向量的内积累加和之中。

[]{#_Toc479279445 .anchor}图3.9计算示例4

如图3.9所示，每一次完成乘法操作后，两个文本的索引i和j均向后移动一位，然后重复上面的整个过程，直到任一索引移动到其文本尾端为止。

本章小结
--------

本章按照互联网新闻文本获取和预处理先后处理的次序，详细介绍了其主要技术环节。首先在网页采集过程中介绍了网络爬虫技术的实现原理和应用情况；其次在统一格式化网页信息的基础上，介绍了网页抽取的作用和基于不同原理的实现方式，然后具体介绍了在实验过程中使用的awk文本处理工具；最后重点介绍了本文预处理工作的关键环节，包括文本特征提取、建立文本表示模型和计算文本距离等过程，并重点阐述了为降低文本距离计算量进行余弦距离稀疏化计算的改进工作。

AHK-P聚类算法设计
=================

通过分析传统H-K（Hierarchical
K-means）方法^\[44\]^实现方式的优势与不足，本文提出一种基于先验知识的AHK-P（Agglomerative
Hierarchical K-means Clustering Based on Priori
Knowledge）算法，开展针对新闻长文本的聚类研究工作。该算法首先在类别角度上基于先验知识粗划分文本数据集，其次在粗划分基础上结合文本特征词汇优化提取初始质心方式，最后采用优化的距离计算方式，结合K-means算法对新闻文本开展细划分处理工作，提高文本聚类的质量。

传统H-K方法实现过程与不足
-------------------------

许多研究表明，仅仅依靠一种方法不能够对所有数据集作出最优的聚类分析和评价，通常情况下不同方法的混合使用可以起到相互辅助的作用^\[44\]^。H-K方法源于综合利用层次聚类和K-means方法优点，同时抑制两种方法缺点的想法，以达到提高聚类的质量和降低时间消耗的目的。表4.1为以上两种方法优缺点比较介绍。

[]{#_Toc479170754 .anchor}表4.1
K-means方法优缺点与层次聚类方法优缺点比较

  聚类方法   K-means方法                                                                    层次聚类方法
  ---------- ------------------------------------------------------------------------------ ----------------------------------------------------------
  优点       实现简单、收敛速度快、聚类过程动态更新、扩展性强、处理大规模数据集性能优异。   兼容数据集任意属性和形状、聚类粒度灵活可控、聚类质量高。
  缺点       只能识别凸形分布、需要初始化聚类中心、对噪声点非常敏感。                       时间复杂度高、不可动态变更聚类结果。

H-K方法设计的关键之处是K-means方法初始质心如何提取，通常有两种基本组织形式：

（1）先采用层次聚类方法聚类后再使用K-means方法聚类：该方法使用层次聚类方法在某种程度上对数据对象进行区分，优化提取初始质心的质量，降低K-means方法运行过程中只能发现局部最优值缺陷造成的误差^\[45\]^。

（2）先使用K-means方法聚类后再使用层次聚类方法聚类：该方法首先迭代使用K-means方法分裂数据集产生一个质心数据集，再对质心数据集进行层次聚类后发现K个新质心，最后继续使用K-means进行聚类^\[46\]^。

H-K方法虽然综合利用了混合聚类方法聚类准确、聚类粒度可控和适用于大规模数据集等特点，但是其在参与文本聚类过程中仍存在以下缺陷：

（1）时间消耗：文本基于语言组织形式存在，语言内容描述的丰富性致使提取的文本特征尤为繁多，文本表示向量经常以高维度形式存在。传统的H-K方法采用混合聚类方法多次扫描数据进行聚类分析时资源消耗会非常大。

（2）欧氏距离：欧氏距离对于向量模数比较敏感，导致区分文本差异性时过于向文体体积属性倾斜。文本体积大小的不确定性使得基于欧氏距离进行划分的H-K方法在文本聚类过程中产生的误差变得尤为明显。

（3）提取初始质心：传统H-K方法的混合聚类方法都是单纯基于文本之间共现特征词汇对数据集进行划分，然后提取初始质心。在文本聚类过程中由于新闻长文本之间共现词汇比较少，个体差异较大，只采用基于共现特征词汇的划分方式不能有效区分不同类别的长文本，提取的质心很可能大量掺入其它类别的特征词汇，导致最终聚类结果簇内部组织比较松散，掺入很多其它类别的文本，降低最终结果的可靠性。除此之外，由于文本数据结构的未知性，提取质心过程中还会出现以下两个问题：

①传统H-K方法一开始进行初始质心提取时具有随机性，如果选择的位置不合适，提取的初始质心数据集中极有可能包含离群的噪声点。一旦噪声点作为初始质心将会使聚类质量变得很差，效果如图4.1左部分所示，五角星表示提取的质心。

![](media/image136.jpeg){width="6.102083333333334in"
height="2.3673611111111112in"}

[]{#_Toc479279446 .anchor}图4.1传统选择初始质心缺陷示例

②当存在某一些类的直径很大或者类之间分布比较均匀的情况下，提取的初始质心中很可能有多个属于同一个类，聚类过程中会导致一个类别被分裂为多个，极大影响聚类质量。效果如图4.1右部分所示，五角星表示提取的质心。

以上缺点是由于只将文本个体的构成异同作为判断指标，忽略类内部文本之间如何分布的情况下造成的。通常情况下，改进办法是多次抽样提取质心，然后进行聚类评价，选择聚类质量最好的一组作为初始质心。上述改进方法并不能判断迭代的最佳次数，导致测试结果只是一种局部最优的情况。

针对以上时间消耗、距离计算和初始质心提取的问题，本文将结合一定的先验知识，采用基于混合聚类的改进算法，从而达到降低时间消耗、改善提取初始质心的合理性和提高区分文本差异性的能力。本文选用分类词库作为先验知识，结合凝聚层次聚类方法和K-means方法，设计一种改进的基于先验知识的文本聚类算法，该算法首先在类别角度预先对文本数据集进行粗划分，其次结合文本之间的共现特征词汇提取初始质心，最后细划分文本数据集。

AHK-P算法设计思路
-----------------

[]{#_Toc479279447 .anchor}

图4.2基于先验知识的AHK-P算法

针对传统H-K方法不足之处，本文提出和设计了一种改进的基于先验知识的H-K方法，即AHK-P算法，如图4.2所示。本文提出的AHK-P算法首先结合先验知识在类别角度上采用凝聚层次聚类方法对文本数据集进行粗划分，得到不同类别的文本集合；其次根据粗划分结果结合文本特征词汇采用质心一次约束方式、质心二次约束方式和质心最大间隔约束方式优化提取初始质心方式；最后采用优化距离计算方法结合K-means方法进行细划分文本数据集的处理工作。

（1）基于先验知识的AHK-P算法通过类别映射向量粗划分文本数据集，降低了由于文本高维向量带来的时间消耗。

（2）基于先验知识的AHK-P算法在提取初始质心时综合利用了文本类别属性和文本个体属性，在一定程度上提升了提取初始质心的合理性。

（3）基于先验知识的AHK-P算法通过类别映射向量与文本表示向量使用K-means方法细划分文本数据集，优化了文本距离计算方式，提高了区分文本差异性的能力。

### 基于先验知识粗划分文本数据集

基于先验知识粗划分文本数据集是指采用凝聚层次聚类方法结合一定的先验知识划分文本数据集的方法。该方法首先利用分类词库与各新闻文本之间特征词汇的映射关系，分别为每个新闻文本建立类别映射向量；其次通过凝聚层次聚类方法根据各文本类别映射向量距离关系粗划分文本数据集。

类别映射向量依据特定类别特征词汇区分不同类别新闻文本，在向量空间为每个新闻文本确立唯一的位置，使得新闻文本获得了粗粒度的类别差异性。由于新闻文本词汇的丰富性，该方法并不能作为新闻文本类别划分的准确依据，但可以作为先验知识应用于聚类过程中初始质心定向提取和文本距离计算等环节。

在类别角度上的差异通过计算类别表示向量之间的余弦距离进行判断，从而使AHK-P算法对新闻文本聚类分析之前获得一定程度上的先验知识，即文本之间类别的差异性。新闻文本与各分类词库之间通过共现词汇建立映射关系。映射关系采用稀疏化向量表示，向量的每个维度与唯一分类词库一一对应，维度值为该文本与对应分类词库所有共现词汇TF-IDF加权值的累加和，计算方法如公式4-1所示，表示文本与分类词库共现词汇个数。

表4.2为新闻文本与每个分类词库建立映射向量的算法流程设计。

文本数据集，其中为文本个数，为，为包含在文本的词汇的加权值；分类词库集合，表示分类词库的个数。

[]{#_Toc479170755 .anchor}表4.2建立类别映射向量算法

+----------------------------------------------------------+
| **算法1 建立类别映射向量**                               |
+==========================================================+
| 1.输入文本数据集、分类词库，文本映射集；                 |
|                                                          |
| 2.                                                       |
|                                                          |
| 使用公式4-1统计文本与分类词库所有共现词汇加权值的累计和; |
|                                                          |
| ；                                                       |
|                                                          |
| ；                                                       |
|                                                          |
| ；                                                       |
|                                                          |
| 3.输出。                                                 |
+----------------------------------------------------------+

基于先验知识粗划分文本数据集结合分类词库先验知识采用层次聚类方法以类别角度对文本数据集进行粗划分。在使用层次聚类方法的研究过程中，由于凝聚方法比较次简单实用，凝聚层聚类方法常用于聚类研究^\[47\]^。

本文使用凝聚层次聚类方法开展粗划分文本数据集的研究工作。凝聚层次聚类开始时将每个数据对象视为只有一个元素构成的簇，在之后每一次迭代处理过程中合并两个距离最近的簇，直至所有数据对象凝聚为一个簇或指定个数的簇为止。该方法不仅聚类准确、无需设置额外参数、易孤立噪声点或离群点，而且可根据现实应用调整距离计算方式，实现聚类粒度可控，优点十分明显。

凝聚层次聚类方法簇之间的距离计算方法如公式4-2所示：

公式4-2中，、分别为簇和，、分别表示簇、内的单个数据对象。

经过基于先验知识粗划分处理后，文本数据集变为不同类别的集合，从而使每个新闻文本获得了类别属性，不仅改善了后续提取初始质心的合理性，而且提升了划分过程中判断文本异同性的准确性。

表4.3为本文提出和设计的粗划分文本数据集算法的具体流程：

[]{#_Toc479170756 .anchor}表4.3粗划分文本数据集算法

+-----------------------------------------+
| **算法2粗划分文本数据集**               |
+=========================================+
| 1.使用算法1文本类别映射向量集；         |
|                                         |
| 2.初始化划分结果集，；                  |
|                                         |
| 3.输入集合和聚类数；                    |
|                                         |
| 4.                                      |
|                                         |
| 使用公式4-2发现中两个距离最小的簇和，； |
|                                         |
| ；                                      |
|                                         |
| ；                                      |
|                                         |
| ；                                      |
|                                         |
| 5.输出。                                |
+-----------------------------------------+

### 优化初始质心提取过程

粗划分处理后每个文本具有了类别特征，本节将文本类别特征与其词汇特征相结合优化提取初始质心的过程，与传统提取初始质心单纯使用词汇特征的方法相比，提升了提取过程的合理性。

本文将文本与分类词库建立的映射关系表示为类别映射向量，将文本在文本数据集空间的表示称为文本表示向量。在经过粗划分处理后，对文本数据集依据文本表示向量计算距离提取初始质心的行为称为约束。本文提出质心一次约束、质心二次约束和质心最大间隔约束三种方式实现优化提取初始质心。

（1）质心一次约束是指文本数据集在被粗划分后使用文本表示向量求取每个类内算术平均值作为初始质心的方法。质心一次约束具体描述如下：

传统提取质心方式单纯使用文本表示向量提取质心，本文提出的质心一次约束方法基于数据对象所属类别不同角度上，求取类别的算术平均值作为质心，实现了类别特征和数据对象个体特征的结合。更新质心方式如公式4-3所示。

上式中表示包含文本的个数，表示所有文本表示向量的算术平均值。

表4.4为本文提出和设计的质心一次约束算法提取初始质心的具体设计流程。

[]{#_Toc479170757 .anchor}表4.4质心一次约束提取初始质心算法

+-------------------------------------------------+
| **算法3质心一次约束提取初始质心**               |
+=================================================+
| 1.文本数据集经过算法2处理后获得文本划分集合，； |
|                                                 |
| 2.初始质心集合，输入聚类数，设定。              |
|                                                 |
| 3.                                              |
|                                                 |
| 使用公式4-3更新中的质心，；                     |
|                                                 |
| ；                                              |
|                                                 |
| ；                                              |
|                                                 |
| 4.输出质心集合。                                |
+-------------------------------------------------+

（2）质心二次约束是指提取过程中两次使用文本表示向量计算距离求取类内算术平均值的方法。首先使用一次约束方法求取每个类别的算术平均值，并判断类内数据对象与所有类别算术平均值相比是否与该类算术平均值距离最小；其次将仍与原类别算术平均值距离最小的数据点聚合为原类别的子类；最后求取每个子类算数平均值作为初始质心。质心二次约束算法提取初始质心的实现效果如图4.3所示，五角星表示中心区域。

[]{#_Toc479279448 .anchor}图4.3质心二次约束提取方式的理想效果

使用公式4-4求取仍在原类中的子类。

本文提出的质心二次约束不仅结合数据对象类别特征和个体特征优化初始质心提取过程，而且实现了子类精细提取的过程，在质心一次约束方式基础上进一步优化了提取过程。表4.5为本文提出和设计的质心二次约束算法提取初始质心的具体流程。

[]{#_Toc479170758 .anchor}表4.5质心二次约束提取初始质心算法

+-----------------------------------------------------------------------+
| **算法4质心二次约束提取初始质心**                                     |
+=======================================================================+
| 1.文本数据集经过算法2处理后获得划分集合，，经过算法3处理后获得初始质心集； |
|                                                                       |
|                                                                       |
| 2.初始化质心集合，输入聚类数，设定；                                  |
|                                                                       |
| 3.                                                                    |
|                                                                       |
| 使用公式4-4更新中的构成元素，；                                       |
|                                                                       |
| 使用公式4-3更新中质心，；                                             |
|                                                                       |
| ；                                                                    |
|                                                                       |
| ；                                                                    |
|                                                                       |
| 4.输出质心集合。                                                      |
+-----------------------------------------------------------------------+

（3）质心最大间隔约束是指文本数据集在被粗划分后，基于不同类别数据对象之间的最大距离提取初始质心的方法。该方法受启发于K-means++^\[48\]^提取初始质心的方法，本文实现方法改进为最大距离优先，而且提取的每个数据对象源于不同类别。最大距离提取初始质心方法基于文本之间距离与文本类别差异性正相关的假设。

提取方法如公式4-5、公式4-6所示。、表示文本，、表示簇，是计算文本、距离的函数。

本文提出的质心最大间隔约束方法首先借助一定的先验知识以类别角度区分文本，然后再采用距离最大化方式提取初始质心。最大间隔约束算法提取初始质心效果如图4.4所示，五角星表示质心。表4.6为本文提取和设计的最大间隔约束算法提取初始质心的具体流程。

[]{#_Toc479170759 .anchor}表4.6质心最大间隔提取初始质心算法

+---------------------------------------------------------------+
| **算法5质心最大间隔约束提取初始质心**                         |
+===============================================================+
| 1.利用算法2处理文本数据集后获得文本集合，，其中表示单个文本； |
|                                                               |
| 2.初始质心集合，输入聚类数；                                  |
|                                                               |
| 3.使用公式4-5获取最大距离对象和，，执行；                     |
|                                                               |
| 4.执行，其中，；                                              |
|                                                               |
| 5.初始化；                                                    |
|                                                               |
| 6.                                                            |
|                                                               |
| 使用公式4-6提取质心；                                         |
|                                                               |
| ；                                                            |
|                                                               |
| ；                                                            |
|                                                               |
| ；                                                            |
|                                                               |
| 7.输出质心集合。                                              |
+---------------------------------------------------------------+

[]{#_Toc479279449 .anchor}图4.4最大间隔约束提取方式的理想效果

### 基于先验知识细划分文本数据集

细划分是指使用先验知识分类词库获得类别映射向量，与文本表示向量采用余弦距离方法划分文本数据集的过程。首先由于文本预处理后多以稀疏向量的形式存在，余弦计算方法易于表达稀疏向量相关性^\[49\]^，其次将类别映射向量结合文本表示向量判断文本之间的距离，使算法具有区分文本类别和个体差异的能力，提升聚类质量。本文使用优化的距离计算方法借助K-means算法开展细划分文本数据集的工作。表4.7为本文设计和提出的细划分文本数据集算法的具体流程。

集合，，代表以文本表示向量表示的质心集合，代表以类别映射向量形式表示的质心集合；代表簇集合，其中和分别以文本表示向量和类别表示向量形式表示簇的质心，。

[]{#_Toc479170760 .anchor}表4.7细划分文本数据集算法

+-----------------------------------------------------------------------+
| **算法6 细划分文本数据集**                                            |
+=======================================================================+
| 1.利用算法3、算法4或算法5获得初始质心集合，；                         |
|                                                                       |
| 2.使用公式4-1为集合中每个质心建立类别映射向量，质心；                 |
|                                                                       |
| 3.确定最大迭代次数，初始化代价值，设定；                              |
|                                                                       |
| 4.                                                                    |
|                                                                       |
| 通过公式4-7获得文本与所有质心之间的距离，求得最小距离簇，然后将文本划分到； |
|                                                                       |
|                                                                       |
| 分别使用文本表示向量和类别表示向量求取各簇内算术平均值作为质心，更新和； |
|                                                                       |
|                                                                       |
| 使用公式4-8记录代价函数值，执行；                                     |
|                                                                       |
| ；                                                                    |
|                                                                       |
| 5.输出中最小值对应的划分结果。                                        |
+-----------------------------------------------------------------------+

公式4-7、4-8为改进的距离计算方法、K-means算法代价函数。

表示通过文本表示向量之间的余弦值，表示通过类别映射向量之间的余弦值，和表示文本、的文本表示向量，和表示文本、的类别映射向量，表示经验系数，表示属于簇的文本，、表示以文本表示向量、类别映射向量形式表示的质心。

AHK-P具体算法设计
-----------------

[]{#_Toc479279450 .anchor}图4.5 AHK-P具体算法设计框架图

本文设计的AHK-P算法主要包括结合分类词库先验知识使用凝聚层次聚类算法粗划分文本数据集，优化初始质心的提取过程，结合分类词库先验知识使用K-means算法细划分文本数据集三个过程。

AHK-P具体算法设计框架如图4.5所示，首先在粗划分文本数据集环节上采用基于先验知识的凝聚层次聚类方法实现以类别角度粗粒度的快速划分文本，将文本数据集划分为K类；其次在提取初始质心环节上结合粗划分结果实现文本类别特征与个体特征的双重约束，提升提取K个初始质心的合理性；最后结合上一步提取的初始质心采用优化距离计算方法的K-means方法开展文本聚类的工作，并在划分过程中采用余弦计算方法，从而达到降低文本体积不确定性对聚类结果产生误差的目的。

AHK-P算法不仅实现凝聚层次方法和K-means方法在聚类过程中优势互补，而且AHK-P算法在如何提取初始质心环节上进行了非常灵活的设计，从而达到降低传统H-K方法的时间消耗和提升聚类质量的目的。本文设计的AHK-P算法具体流程如表4.8所示。

AHK-P算法具体流程描述如下：

[]{#_Toc479170761 .anchor}表4.8 AHK-P算法

+-------------------------------------------------------------+
| **AHK-P算法**                                               |
+=============================================================+
| 1.输入聚类数，文本数据集，分类词库；                        |
|                                                             |
| 2.利用算法1处理，获得类别映射集，满足映射关系；             |
|                                                             |
| 3.利用算法2处理进行文本数据集粗划分，获得划分结果；         |
|                                                             |
| 4.利用算法3、算法4或算法5对处理后获得初始质心集合；         |
|                                                             |
| 5.利用算法1对处理后获得初始质心的类别映射集，满足映射关系； |
|                                                             |
| 6.利用算法6处理、、和进行细划分文本数据集；                 |
|                                                             |
| 7.输出划分结果。                                            |
+-------------------------------------------------------------+

本章小结
--------

本章主要阐述了AHK-P算法设计的实现原理和方法，首先介绍了传统H-K方法的实现过程与不足之处；其次提出了改进的AHK-P算法基于先验知识粗划分文本数据集、优化初始质心提取和基于先验知识细划分文本数据集三个改进思路；最后详细阐述了AHK-P算法设计的具体流程。

新闻文本聚类算法实现与实验验证
==============================

工作平台与实验数据
------------------

### 工作平台

[]{#_Toc479170762 .anchor}表5.1实验环境配置

  分类       参数名称       配置
  ---------- -------------- -------------------------
  硬件环境   CPU            Intel Core i7 2.5G \* 8
             内存           4GB
  软件环境   操作平台       Linux Ubuntu 16.04 LTS
             开发语言       Shell、Python
             数据处理工具   awk、sed
             中文分词工具   Jieba中文分词系统
             开发编辑工具   vim、gedit

工具及应用介绍如下：

（1）Shell中运用awk、sed等工具进行数据预处理和最终结果的统计工作，首先数据预处理工作中结合正则表达式进行数据提取工作；其次对各文本词汇进行词频统计、文本率统计和TF-IDF加权处理工作；最后对使用相应的评估方法对实现结果开展分析评价工作。

（2）Python在实验过程中主要进行两个工作：前期实验预处理过程中调用Jieba中文分词库接口进行中文分词工作，后期使用python脚本语言编程实现面向互联网新闻的文本聚类算法和其它算法，开展实验仿真工作。

### 实验数据

（1）实验使用的数据包括分类词库和从新闻门户网站获取的新闻文本数据。

（2）新闻的类别与URL一一对应，类别与URL的映射关系如表5.2所示。

（3）新闻文本数据是由搜狗实验室提供的2012年7月到2012年8月期间新闻文本（SogouCS
2012），分类词库文本数据由搜狗输入法官方提供。SogouCS
2012新闻数据主要来源网站有搜狐新闻网。表5.3和表5.4分别为分类词库格式介绍和新闻文本数据格式介绍。

[]{#_Toc479170765 .anchor}表5.2搜狐新闻网类别与URL映射关系

  汽车   http://auto.sohu.com/
  ------ -----------------------------------------
  财经   http://business.sohu.com/
  IT     http://it.sohu.com/
  健康   http://health.sohu.com/
  体育   http://sports.sohu.com/
  旅游   http://travel.sohu.com/
  教育   http://learning.sohu.com/
  招聘   http://career.sohu.com/
  文化   http://cul.sohu.com/
  军事   http://mil.news.sohu.com/
  社会   http://news.sohu.com/shehuixinwen.shtml
  国内   http://news.sohu.com/guoneixinwen.shtml
  国际   http://news.sohu.com/guojixinwen.shtml
  房产   http://house.sohu.com/
  娱乐   http://yule.sohu.com/
  时尚   http://women.sohu.com/
  传媒   http://media.sohu.com/
  公益   http://gongyi.sohu.com/
  母婴   http://baobao.sohu.com/

[]{#_Toc479170764 .anchor}表5.3分类词库格式介绍

+-----------------------------------+-----------------------------------+
| 新闻类别词汇语料库                |
+===================================+===================================+
| 数据来源                          | 搜狗输入法官网                    |
+-----------------------------------+-----------------------------------+
| 数据名称                          | 分类词库                          |
+-----------------------------------+-----------------------------------+
| 数据大小                          | 每个类别库约为1MB                 |
+-----------------------------------+-----------------------------------+
| 数据内容                          | 由搜狗输入法官方统计各类词汇的输入出现频次。 |
+-----------------------------------+-----------------------------------+
| 数据格式                          | 类别库中每条纪录是由词频、词汇汉语拼音、汉字词汇组成的三元组。如： |
|                                   |                                   |
|                                   |                                   |
|                                   | {151}achangta 阿昌塔。            |
+-----------------------------------+-----------------------------------+

[]{#_Toc479170763 .anchor}表5.4新闻文本数据格式介绍

+-----------------------------------+-----------------------------------+
| 互联网新闻文本数据集              |
+===================================+===================================+
| 数据来源                          | 搜狗数据实验室                    |
+-----------------------------------+-----------------------------------+
| 数据名称                          | SougouCS 2012（全网新闻数据）     |
+-----------------------------------+-----------------------------------+
| 数据大小                          | 648MB（压缩包格式：tar.gz）       |
+-----------------------------------+-----------------------------------+
| 数据内容                          | 包含各大新闻网2012.6-2012.7期间体育、娱乐、汽车、IT |
|                                   | 、军事、股票等18个类别的新闻数据。 |
+-----------------------------------+-----------------------------------+
| 数据格式说明                      | 所有新闻数据集中压缩在一个文本文件中，每个新闻纪录格式通过以下格式 |
|                                   | 区分：                            |
|                                   |                                   |
|                                   | \<doc\>                           |
|                                   |                                   |
|                                   | \<url\> URL \</url\>              |
|                                   |                                   |
|                                   | \<docno\> ID \</docno\>           |
|                                   |                                   |
|                                   | \<contenttile\>题头\<contenttile\> |
|                                   |                                   |
|                                   |                                   |
|                                   | \<content\>正文内容\</content\>   |
|                                   |                                   |
|                                   | \<doc/\>                          |
+-----------------------------------+-----------------------------------+

新闻文本聚类算法实现
--------------------

### 文本数据预处理

（1）新闻文本抽取：SogouCS
2012新闻文本数据存放形式是以单个文本集合所有新闻文本数据的形式，而实验过程中需要以新闻文本作为单位进行数据处理工作，所以需要进行拆分工作。工作流程如下：

①利用awk和sed工具与Shell语言工具应用正则表达式将最初的文本数据集拆分为单个文本。

②利用Shell语言工具按照文本的新闻ID和新闻URL映射的类别进行组合命名，为后续实验结果的统计工作提供确认和分类依据。

③按照新闻URL映射的类别进行分类存档工作，使用Shell工具语言统计各类别文本总数。

图5.1为awk、sed文本处理工具进行数据整理的示意图。

[]{#_Toc479279451 .anchor}图5.1文本数据分类整理流程

（2）处理无效文本数据：首先使用Shell语言工具过滤无内容文本，其次借助awk和sed工具去除无类别映射的文本。

（3）中文分词：借助Jieba中文分词系统对每个新闻文本进行中文分词处理工作，将处理后的数据按相同文件名转存到对应的文本库中。如表5.5展示的分词示例。

[]{#_Toc479170766 .anchor}表5.5文本分词示例

（4）词汇库建立：首先使用Shell语言工具记录所有出现的词汇；其次使用Shell语言工具和awk工具对文本库中的词汇进行去重，词频、文本频率进行统计的工作；最后去除文本频率与总文本数的比值小于0.01，文本频率大于0.8的词汇，并按照词汇出现顺序和递增方式对词库中的所有记录进行ID标注，如表5.6所示。

（5）词汇权重统计：借助Shell语言工具和awk工具，使用TF-IDF统计方法对词库中词汇进行权重统计工作。词汇特征统计加权值示例如表5.7所示。

（6）文本特征提取与文本表示：首先去除权值过低的词汇，压缩文本表示向量维度数；其次利用词汇ID序号进行递增排列；最后使用稀疏化向量形式进行文本表示。

表5.7中词汇对应文本使用稀疏化向量可表示为：

（\<6，0.723477\>，\<20，0.186760\>，\<22，0.208886\>，\<23，0.080930\>，\<41，0.074692\>，\<70，0.013832\>，\<72，0.099437\>，\<74，0.100776\>，\<82，0.103413\>，\<83，0.094409\>，\<84，0.092267\>，\<87，0.107287\>，\<90，0.102287\>，\<93，0.105838\>，\<97，0.106798\>**...**），向量每个维度值由\<ID序号，词汇权重值\>二元组形式构成。

（7）类别映射向量建立：统计分类词库的文本数作为类别映射向量的维度总数，设定分类词库与指定维度一一对应；其次依据各文本类别映射向量的维度统计与对应词库共现词汇的加权值累加和作为此维度的数值；最后合成向量，如表5.8所示。

[]{#_Toc479170767 .anchor}表5.6词库词汇统计信息示例

  **词汇ID**   **汉字词汇**   **总词频**   **文本频率**
  ------------ -------------- ------------ --------------
  0            月             8458         3523
  1            公司           7908         1756
  2            年             7576         2887
  3            日             6963         3137
  4            中             5403         2677
  5            市场           5364         1520
  6            产品           5035         1569
  7            投资           4984         1178
  8            中国           4878         1679
  9            银行           4211         808
  10           元             4156         943
  11           后             4053         2181
  12           经济           3978         1210
  13           记者           3200         1567
  ...          ...            ...          ...

[]{#_Toc479170768 .anchor}

表5.7文本词汇特征值统计示例

  **词汇ID**   **汉字词汇**   **权重值**
  ------------ -------------- ------------
  6            产品           0.723477
  20           系列           0.186760
  22           容量           0.208886
  23           系统           0.080930
  41           更多           0.074692
  70           华硕           0.013832
  72           尺寸           0.099437
  74           英寸           0.100776
  82           屏幕           0.103413
  83           操作           0.094409
  84           参数           0.092267
  87           芯片           0.107287
  90           硬盘           0.102287
  93           主频           0.105838
  97           内存           0.106798
  ...          ...            ...

> []{#_Toc479170769 .anchor}表5.8建立类别映射向量信息示例

  **类库ID**   **文本词汇1**   **文本词汇2**   **文本词汇3**   **...**   **向量维度值**
  ------------ --------------- --------------- --------------- --------- ----------------
  1            0               0               0                         0
  2            1               0               1                         0.0759963
  3            0               0               0                         0
  4            1               0               0                         0.0301156
  5            0               0               0               1         0
  6            0               1               0               0         0.1257903
  7            0               0               0               0         0
  8            0               0               0               0         0.0045396
  9            0               1               1               0         0.0348920
  10           0               0               0               0         0
  ...          ...             ...             ...                       ...

### AHK-P算法实现

AHK-P算法实现包括凝聚层次聚类算法实现、初始质心提取实现和K-means算法实现，实现流程如图5.2所示。

[]{#_Toc479279452 .anchor}图5.2AHK-P算法聚类流程

（1）凝聚层次聚类算法实现：在采用第四章表4.3算法设计方法实现算法的基础上，首先接收聚类数参数，其次结合类别映射向量使用余弦方法计算数据对象之间的距离，凝聚层次聚类算法实现流程如图5.3所示。

算法具体设计如下：

①初始时簇只有一个数据对象单独构成，簇数为数据对象的个数。

②采用余弦计算方法将最近的两个簇聚合为一个新簇。

③重复②过程直至簇数缩小为指定的数目。

[]{#_Toc479279453 .anchor}图5.3凝聚层次聚类算法实现流程

（2）初始质心提取实现：AHK-P算法在凝聚层次聚类部分过程执行结束后产生K个类别簇，按一定提取方法从每个类别簇中提取一个数据对象组合为AHK-P算法初始化质心集合，初始质心提取实现流程如图5.4所示。提取方式分为三种：

①质心一次约束：首先使用文本表示向量代表所有数据对象，然后依据类别不同，求取每个类别簇的算数平均值作为初始质心。

②质心二次约束：使用文本表示向量代表所有数据对象，依据类别不同，求取每个类别簇的算数平均值；再次使用所有文本表示向量计算与K个质心的余弦距离，求取K个仍在原类别簇中的数据对象组成的子簇；最后使用文本表示向量求取子簇的算术平均值作为初始质心。

③质心最大间隔约束：借鉴K-means++算法提取方法，直接选择类别不同的K个距离最大的数据对象作为初始质心。

[]{#_Toc479279454 .anchor}图5.4初始质心提取流程

（3）使用优化文本距离计算方式的K-means算法实现细划分文本数据集，图5.5为其具体实现流程。算法设计如下：

①首先使用（2）过程提取的质心集合初始化K-means的质心集合。

②根据质心文本表示向量各维度代表的词汇与分类词库的映射关系，使用公式4-1为其分别建立类别映射向量。

③使用公式4-8计算文本之间的距离，依据与质心余弦距离最小的办法进行数据集划分，记录K个子集的数据构成。

④首先通过计算每个划分子集内的类别映射向量和文本表示向量的算术平均值更新每个划分子集的质心。

⑤重复③④过程，直至K-means算法迭代更新后代价函数满足最大迭代次数阈值限定。

[]{#_Toc479279455 .anchor}图5.5 K-means算法工作流程

实验评价方法
------------

本实验共进行两组实验，分别是初始质心提取对比实验、AHK-P算法有效性验证实验。针对以上实验的结果，分别采用以下方法进行评价分析：

（1）初始质心提取验证实验主要目标是验证AHK-P算法提取初始质心的合理性，采用与类别真实质心余弦距离大小对比的方法进行分析验证。类别真实质心是指将属于某一类别所有文本表示向量的算术平均值作为质心。

（2）AHK-P算法有效性验证实验的目标是与其它算法对比验证AHK-P算法改进之处的有效性。统计新闻文本聚类结果使用正确率、回归率和值方法进行评价。

实验说明：簇的正确文本数指簇中划分类别正确的文本数；每个类别文本总数根据新闻类别URL映射关系统计获取。

实验设计与结果分析
------------------

本文从SougouCS数据集中随机提取10000篇新闻文本作为本次新闻文本聚类算法实验验证的样本数据集。

### 初始质心提取对比实验

（1）实验设计如下：

①随机在样本数据集中抽取500篇新闻文本，首先利用文本的URL进行类别标记，确定实验提取质心个数，即K值；其次统计抽样数据的构成成分和每个类别的真实质心。真实质心是指归属某一类别的所有文本表示向量的算术平均值。

②设计以下五组实验进行初始质心提取的操作：

第一组实验：采取随机抽样的办法提取K个质心。

第二组实验：使用传统H-K实现方法提取K个质心。

第三组实验：采用质心最大间隔约束方式提取K个质心。

第四组实验：采用质心一次约束方式提取K个质心。

第五组实验：采用质心二次约束方式提取K个质心。

③上述五组实验分别重复进行10次，记录每次K个数据对象与对应类别的真实质心之间的余弦距离。

④求取五组实验数据的平均值，然后对比分析。

（2）实验数据统计如表5.9所示，实验结果如表5.10、表5.11、如图5.6所示。

实验说明：

①余弦距离最大为1，最小为0，实验中余弦距离越小表明计算对象之间越接近。

②使用M1代表随机提取质心方法，M2代表使用传统H-K方法提取质心方法^\[46\]^，M3代表质心最大间隔约束提取质心方法，M4代表质心一次约束提取质心方法，M5代表质心二次约束提取质心方法。

[]{#_Toc479170770 .anchor}表5.9抽样数据构成成分

  **类别**   体育   军事   科技   财经
  ---------- ------ ------ ------ ------
  **数量**   159    114    128    99

> []{#_Toc479170771 .anchor}

表5.10各类与真实质心平均距离

+--------------+----------+--------+--------+--------+--------+
| **组别**     | 余弦距离 |
|              |          |
| **新闻类别** |          |
+==============+==========+========+========+========+========+
|              | M1       | M2     | M3     | M4     | M5     |
+--------------+----------+--------+--------+--------+--------+
| 体育         | 0.7590   | 0.0909 | 0.6715 | 0.0516 | 0.0476 |
+--------------+----------+--------+--------+--------+--------+
| 军事         | 0.7407   | 0.1126 | 0.0405 | 0.0664 | 0.0638 |
+--------------+----------+--------+--------+--------+--------+
| 科技         | 0.4112   | 0.0397 | 0.2035 | 0.0319 | 0.0080 |
+--------------+----------+--------+--------+--------+--------+
| 财经         | 0.6801   | 0.0807 | 0.3255 | 0.0715 | 0.0467 |
+--------------+----------+--------+--------+--------+--------+

[]{#_Toc479170772 .anchor}表5.11各方法质心与真实质心平均距离

  **方法**       M1       M2       M3       M4       M5
  -------------- -------- -------- -------- -------- --------
  **平均距离**   0.6478   0.0810   0.3103   0.0554   0.0415

[\[CHART\]]{.chart}

[]{#_Toc479279456 .anchor}图5.6 M2、M4和M5方法与真实质心距离对比直方图

> （3）实验分析：

①根据表5.10数据显示，M3（最大间隔方式）与M1（传统K-means算法）相比，与真实类别质心平均距离减小了0.3375，与M2（传统H-K实现算法）相比平均距离增大了0.2293。M3方法由于具有了一定的类别属性，在提取初始质心过程中增加了一定的方向性和目的性，所以提取的初始质心与M1方法相比更具合理性；同时，由于提取的初始质心仍为原数据的实例，所以合理性上仍不如经过多次迭代更新优化的M2方法。

②通过图5.7与真实类别质心平均距离对比结果显示，M4（质心一次约束方式）与M2相比，在余弦距离区间范围内平均距离减小了0.0256；M5（质心二次约束方式）与M2相比，在余弦距离区间范围内平均距离减小了0.0395，与M4相比，平均距离减小了0.0139。M4和M5方法由于综合利用了类别映射向量和文本表示向量提取初始质心，使算法不仅具有区分数据个体差异的能力，也具有了一定的区分类别的能力，有效提升了提取过程的合理性。

### AHK-P算法有效性验证实验

（1）实验设计：本组实验采用K-means算法、传统H-K算法^\[46\]^与基于本文第四章设计的三种AHK-P算法实现形式进行实验对比分析。

实验说明：使用E1表示K-means算法聚类实验，E2表示传统实现H-K方法的聚类实验，E3表示采用质心最大间隔约束的AHK-P聚类实验，E4表示采用质心一次约束实现的AHK-P聚类实验，E5表示采用质心二次约束实现的AHK-P聚类实验；采用准确率、回归率和F1值方法对实验结果进行分析评价。

①在样本数据集中随机抽样互联网新闻文本500篇，设定K值不同情况下进行聚类分析，然后记录聚类结果的轮廓系数。重复以上过程十次，根据最优轮廓系数确定K值。

②对包含10000篇新闻文本的样本数据集重复进行E1、E2、E3、E4和E5聚类实验20次。

③根据文本预处理过程提取的类别URL，统计各类别文本构成的数量；计算实验结果的准确率、回归率和F1值，然后填入表格进行对比分析。

（2）统计结果和实验结果以下表格所示。

[]{#_Toc479170773 .anchor}表5.12各类别文本构成数量统计

  **类别**   体育   军事   科技   娱乐   汽车   财经
  ---------- ------ ------ ------ ------ ------ ------
  **数量**   2373   2071   1875   1531   1359   791

[]{#_Toc479170774 .anchor}表5.13各类文本准确率统计结果

  **文本类别**   **准确率（%）**                              
  -------------- ----------------- -------- -------- -------- --------
                 **E1**            **E2**   **E3**   **E4**   **E5**
  **体育**       60.2              64.9     63.1     65.3     69.4
  **军事**       60.9              67.4     63.3     71.2     70.6
  **科技**       57.6              71.2     60.7     66.7     72.4
  **娱乐**       65.5              74.3     73.4     78.5     81.9
  **汽车**       53.7              70.2     59.1     63.9     66.5
  **财经**       52.6              65.3     61.4     68.8     69.7

[]{#_Toc479170775 .anchor}表5.14各类文本回归率统计结果

  **文本类别**   **回归率（%）**                              
  -------------- ----------------- -------- -------- -------- --------
                 **E1**            **E2**   **E3**   **E4**   **E5**
  **体育**       57.9              70.3     64.1     72.9     76.3
  **军事**       72.3              81.6     70.9     80.5     79.7
  **科技**       59.2              85.9     68.2     83.4     82.3
  **娱乐**       53.7              68.4     69.4     69.8     74.5
  **汽车**       63.6              72.3     68.3     75.3     80.8
  **财经**       59.4              66.2     62.8     65.7     65.9

[]{#_Toc479170777 .anchor}表5.15各评价数据平均值

  **文本类别**   **平均值（%）**                              
  -------------- ----------------- -------- -------- -------- --------
                 **E1**            **E2**   **E3**   **E4**   **E5**
  **准确率**     58.4              68.9     63.5     69.1     71.8
  **回归率**     61.0              74.1     67.3     74.6     76.6
  **F1 值**      59.7              71.4     65.3     71.7     74.1

> （3）实验分析：

①根据表5.15准确率和回归率统计数据显示，E3与E1相比，在准确率上提高了5.1%，在回归率上提高了6.3%；E4、E5和E2比E1在准确率、回归率和F1值上均提高了10%以上。

②根据表5.15数据显示，E4、E5与E2相比，在保证聚类结果不降低回归率的同时，E4准确率比E2准确率提高了0.2%，E5准确率比E2准确率提高了2.9%，同时E5回归率比E2回归率提高了2.5%。

③E4聚类结果的F1值比E2的F1值提高了0.3%，E5的F1值比E2的F1值提高了2.7%。

④通过分析以上实验结果，不仅验证了AHK-P算法的高效性，同时也验证了本文提出的改进传统H-K方法设计方案的合理性和正确性。通过先验知识粗划分文本，优化提取初始质心，然后结合类别映射向量与文本表示向量优化文本距离计算方法对文本进行细划分，最终提高了聚类结果的质量。

本章小结
--------

本章通过设计和实现AHK-P算法，仿真传统H-K算法和K-means算法，开展面向互联网新闻的文本聚类对比实验工作。首先详细介绍了实现新闻文本聚类算法的基本流程：文本预处理、AHK-P算法设计和聚类结果评价；其次设计提取初始质心的合理性对比实验和仿真传统算法与本文AHK-P算法对比实验；最后对比分析具体实验数据，证明了本文提出和设计的AHK-P算法改进之处的有效性。

总结与展望
==========

总结
----

伴随中国互联网技术的快速发展，文本数据必定呈井喷式增长。借助文本聚类能够自动化将从互联网获取的文本数据组织成为层次清晰和具有逻辑概念的结构化数据。文本聚类分析在搜索引擎优化、信息系统检索、情报分析等领域具有重大的研究和应用价值。在商业上，文本聚类分析根据社交媒体的热点分析能够轻松掌握人群的购买兴趣所在。在政府制定政策时，可以通过聚类分析展开舆情分析。

传统文本聚类算法主要面对以下几个关键问题：首先在处理大规模数据集时需要多次迭代扫描，耗费大量资源和时间；其次由于聚类分析处理的数据多以无结构化或半结构化形式存在，所以聚类算法在初始化环节上多采用随机方法，这就需要多次初始化进行聚类分析才能够逼近最优值，导致分析过程极其繁琐；最后如何根据文本数据构成成分准确界定文本之间的异同性也是研究文本聚类算法的一个关键问题。

针对以上问题，本文在总结前人研究的基础上，首先设计了一套完整的互联网新闻文本聚类框架，该框架主要包括文本预处理、文本聚类分析和聚类结果评价三个过程；其次结合分类词库先验知识，借助余弦距离在文本聚类的实用性，实现了划分文本数据集时类别属性与个体独立性属性的融合，提升了算法运算效率和划分合理性；最后使用凝聚层次聚类和K-means算法实现了AHK-P算法，该算法不仅借鉴了H-K方法聚类准确、多方法混合使用实现优势互补等优点，而且具有初始质心提取方式灵活多变、聚类更加快速的新特点，通过实验对比，验证了AHK-P算法面向互联网新闻进行文本聚类的高效性。

本文提出的改进方法虽然能够在一定程度上加快聚类分析的速度和提升聚类质量，但同样也存在一些改进的地方，首先借助互联网文本的规模，收集大量文本，提取共现词汇，确定分类词库之间的界限，提高文本集划分的可靠性；其次加大测试数据集的力度，尽量扩展到大多数应用场景开展实验验证工作，提高聚类结果和最终结论的全面性。

展望
----

现今的互联网上存在着一个在线的具有海量数据的文本库，如何针对这些文本数据进行快速而准确的文本分析是令人感兴趣的的研究方向。互联网新闻文本关注社会热点，在中国有着海量用户，其潜在的应用价值对促进经济社会发展具有重大的意义。如今的文本聚类方法多种多样，分别适应不同的数据环境，如何设计一套通用的文本聚类方法，使文本分析过程能够适应纷杂的应用环境、适应数据的多变和数据噪声影响，使数据处理过程保持可靠性、实用性，仍然是一个十分棘手的问题。社交媒体聚焦海量人群热点话题，搜索引擎基于用户行为的不断深入优化，信息检索系统的快速响应，情报分析的高时效性等现实要求，无不迫切需要聚类分析应用向更广泛更深入方向发展。

未来互联网新闻文本聚类的研究会着重以下几个问题：如何准确文本特征提取、如何压缩文本体积而又不丢失文本核心内容、如何准确构建文本表示模型、还有如何使文本聚类的应用更具兼容性和扩展性，不仅具有抗噪性，而且能适应多变格式的文本数据。这些问题都是文本聚类研究面临的巨大难题，也是以后针文本聚类研究的重点和兴趣点。

参考文献 {#参考文献 .-1}
========

1.  周婉娇. 我国正从网络大国迈向网络强国\[N\]. 中国青年报报, 2015(03).

2.  中国互联网络信息中心.第39次中国互联网络发展状况统计报告\[R\]. CNNIC,
    2017(1): 1-115.

3.  HU X, LIU H. Text Analytics in Social Media\[M\]// Charu C.
    Aggarwal，Zhai C X. Mining Text Data. New York: Springer, 2012:
    387-408.

4.  MINER G, DELEN D, ELDER J, et al. Practical Text Mining and
    Statistical Analysis for Non-structured Text Data Applications:
    Clustering Words and Documents\[M\]. Waltham: ELSEVIER, 2012:
    959-961.

5.  LEE I, ON B W, An Effective Web Document Clustering Algorithm Based
    on Bisection and Merge\[J\]. Artificial Intelligence Review, 2011,
    36(1): 69-85.

6.  YANG L, CAI X, ZHANG Y, et al. Enhancing Sentence-level Clustering
    with Ranking-based Clustering Framework for Theme-based
    Summarization\[J\]. Information Sciences, 2014(260): 37-50.

7.  FERREIRA R, CABRAL L D S, FREITAS F, et al. A Multi-document
    Summarization System Based on Statistics and Linguistic
    Treatment\[J\]. Expert Systems with Applications, 2014(41):
    5780-5787.

8.  KEDZIE C, MCKEOWN K, DIAZ F. Predicting Salient Updates for Disaster
    Summarization\[C\]. Beijing: Association for Computational
    Linguistics, 2015.

9.  CONRAD J. G, BANDER M. Semi-Supervised Events Clustering in News
    Retrieval\[C\]. European Conference on Information Retrieval, 2016.

10. LIU X, CROFT W B. Cluster-Based Retrieval Using Language
    Models\[C\]. New York: ACM, 2004.

11. LEVI O, RAIBER F, KURLAND O, et al. Selective Cluster-Based Document
    Retrieval\[C\]. New York: ACM, 2016.

12. CHIFU A G, HRISTEA F, MOTHE J, et al. Word Sense Discrimination in
    Information Retrieval: A Spectral Clustering-based Approach\[J\].
    Information Processing & Management, 2015, 51(2): 16-31.

13. CHALARIS M, CHALARIS I, SKOURLASS C, et al. Extraction of Rules
    Based on Students' Questionnaires\[J\]. Procedia - Social and
    Behavioral Sciences, 2013(73): 510-517.

14. ORDONEZ C. Models for Association Rules based on Clustering and
    Correlation\[J\]. Intelligent Data Analysis, 2009, 13(2): 337-358.

15. LI B, PEI Z, QIN K. Association Rules Mining Based on Clustering
    Analysis and Soft Sets\[C\]. Washington: IEEE Computer
    Society, 2015.

16. ZHANG W, TANG X, YOSHIDA T. TESC: An Approach to Text Classification
    Using Semi-supervised Clustering\[J\]. Knowledge-Based Systems,
    2015(75): 152-160.

17. THOMAS A. M, Resmipriya M G. An Efficient Text Classification Scheme
    Using Clustering\[C\]. Amsterdam: ELSEVIER, 2015.

18. SHAFIABADY N, LEE L H, RAJKUMAR R. Using Unsupervised Clustering
    Approach to Train the Support Vector Machine for Text
    Classification\[J\]. Neurocomputing, 2016(211): 4-10.

19. LEE SJ, J JY. Multi label Text Categorization Based On Fuzzy
    Relevance Clustering\[J\]. IEEE TRANSACTIONS ON FUZZY SYSTEMS, 2014,
    22(6): 1457-1471.

20. CEVAHIR A. Scalable Textual Similarity Search on Large Document
    Collections Through Random Indexing and K-means Clustering\[C\].
    Berlin: Springer International Publishing, 2014.

21. HOURDAKIS N, ARGYRIOU M, PETRAKIS EGM, et al. Hierarchical
    Clustering in Medical Document Collections: The BIC-means
    Method\[J\]. Journal of Digital Information Management, 2010,
    8(2):71-77.

22. KISHIDA K. High-Speed Rough Clustering for Very Large Document
    Collections\[J\]. Journal of the Association for Information Science
    and Technology, 2010, 61(6):1092-1104.

23. DELEN D. Real-World Data Mining: Applied Business Analytics and
    Decision Making\[M\]. Upper Saddle River: Pearson Education,
    2014:196-197.

24. Jain AK, Murty M N, Flynn P J. Data Clustering: A Review\[J\]. ACM
    Computing Surveys, 1999, 31(3): 264-323.

25. Jain AK Dubes RC．Algorithms for Clustering Data\[M\]. Upper Saddle
    River: Prentice Hall Advanced Reference Series, 1988: 1-334．

26. 庞景安. Web文本特征提取方法的研究与发展\[J\]. 情报理论与实践, 2006,
    29(3): 338-340.

27. 张海龙, 王莲芝. 自动文本分类特征选择方法研究\[J\]. 计算机工程与设计,
    2006(2): 3838---3841.

28. 姜芳, 李国, 岳翔. 基于语义的文档特征提取研究方法\[J\]. 计算机科学,
    2016, 43(2): 254-258.

29. 王娟琴. 三种检索模型的比较分析研究\--布尔、概率、向量空间模型\[J\].
    情报科学, 1998, 16(3): 225-230.

30. 张文进. 文本信息检索中的概率模型\[J\]. 情报杂志, 2005, 24(3):
    107-110.

31. 林鸿飞, 战学刚, 姚天顺. 基于潜在语义索引的文本分析方法\[J\].
    模式识别与人工智能, 2000, 13(1): 47-51.

32. 贺玲, 吴玲达, 蔡益朝. 数据挖掘中的聚类算法综述\[J\]. 计算机应用研究,
    2007(1): 10-13.

33. MCNICHOLAS PD. Model-Based Clustering\[J\]. Journal of
    Classification, 2016(33): 1-43.

34. Liu Y, Li Z, Xiong H, et al. Understanding Of Internal Clustering
    Validation Measures\[C\]// IEEE, International Conference on Data
    Mining. IEEE, 2010:911-916.

35. 周立柱, 林玲. 聚焦爬虫技术研究综述\[J\]. 计算机应用, 2005, 25(9):
    1965-1969.

36. CHO J, GARCIA-MOUNA H, PAGE L．Efficient Crawling through URL
    Ordering\[J\]. Computer Network, 2012, 56(18): 3849-3858.

37. GUO Q, GUO H, ZHANG ZQ, et al. Schema Driven Topic and Specific Web
    Crawling\[C\]. New York: ACM, 2005.

38. 刘迁, 焦慧, 贾慧波. 信息抽取技术的发展现状及构建方法的研究\[J\].
    计算机应用研究, 2007, 24(7): 6-9.

39. 李斌.浅谈web信息抽取\[J\]. 大众科技, 2010(4): 48-49.

40. ROBBINSA. Effective Awk Programming\[M\].Boston: Free Software
    Foundation, 2014: 13-25.

41. 龙树全, 赵正文, 唐华. 中文分词算法概述\[J\]. 电脑知识与技术, 2009,
    5(10): 2605-2607.

42. 郭庆琳, 李艳梅, 唐琪. 基于VSM的文本相似度计算的研究\[J\].
    计算机应用研究, 2008, 25(11): 3256-3258.

43. HUANG A. Similarity Measures for Text Document Clustering\[C\].
    Christchurch: NZCSRSC, 2008.

44. CHEN TS, TSAI TH, CHEN YT, et al. A Combined K-Means And
    Hierarchical Clustering Method For Improving The Clustering
    Efficiency Of Microarray\[C\]. Hong Kong: IEEE Press, 2005.

45. 李文超, 周勇, 夏士雄. 一种新的基于层次和K-means方法的聚类算法\[C\].
    张家界: 中国学术期刊电子出版社, 2007

46. ARAI K, BARAKBAH AR. Hierarchical K-means: an Algorithm for
    Centroids Initialization for K-means\[J\]. Reports of the Faculty of
    Science and Engineering, 2007, 36(1): 25-31.

47. HAN J, KAMBER M, PEI J. Data Mining Concepts and
    Techniques\[M\].Burlington: Morgan Kaufmann Publishers, 2011:
    457-470.

48. ARTHUR D, VASSILVITSKII S. K-means++: The Advantages of Careful
    Seeding\[C\]. New York: ACM, 2007.

49. DHILLON I S, MODHA D S. Concept Decompositions for Large Sparse Text
    Data Using Clustering\[J\]. Machine Learning, 2001(42): 143-175.

致谢 {#致谢 .-1}
====

时光匆匆，三年研究生学习生活马上就要结束，也预示着我的求学路程即将结束。此刻回忆满满，令我万分感慨，首先在导师的谆谆教导中学习了很多人生的大道理，坚持不懈，克服困难，勇往直前，其次在自己一直坚持的研究方向上不断深入，接触到了很多大家的思想。感谢自己的母校西安电子科技大学对自己的培养，为自己提供了十分优越和宽容的学习氛围。

自己由衷的感激刘志镜老师和姚勇老师，无论在工作中还是学习生活中都给予了我莫大的支持。刘志镜老师是一位做事认真，治学严谨，宽容待人，极具无私奉献精神的科技工作者。刘老师在本校计算机院名声赫赫，在计算机应用技术领域知识丰富，不仅在研究工作中对我耐心指导，而且每当生活中遇到不如意的事情时对我给予充分的支持。姚勇老师是一位年轻有为的老师，在数据挖掘领域有着极为丰富的研究经验。每当我的研究工作遇到困难时，经过他开拓性想法的指导，总使我的研究工作能够不断推进和深入。以上两位老师都给予了我莫大的帮助。

感谢实验室的武文骁硕士、别芮硕士、王炳华硕士、黄辉煌硕士和张木杰硕士等在这三年的研究生生活中给予我的支持和帮助。很多时候大家一起进行学术讨论，共同制定实验策略，一起解决课题上的学术难题，他们都为我的研究工作提出了很多建设性的意见，让我收获颇丰。虽然在这些过程中曾经有过激烈争论的场景，但更重要的是大家都共同追求的是在学术研究上更上一层楼，在知识理解上更加深入。有过欢笑，有过争论，不断的深入合作，让我们这一路上工作更加默契，友谊更加深厚。总之，在这三年中，他们是都是我人生中遇到的不可多得的好伙伴，这是我人生难以忘怀的时光。

感谢我的父母，感谢这么多年来对我无私的付出，感谢无时无刻对我的支持、鼓励和赞赏。每当我处在意志消沉的时候，每当我生活和工作遇到不顺心的事情的时候，都给予了我无私的关怀。感谢我的姐姐，在二十多年来给予我的宽容和忍让，无私的帮助，总让我在困难的时候越加坚强，越挫越勇，最终坚持完成自己的目标。祝我美丽的姐姐一切顺利，人生幸福。

十分感谢答辩组所有老师，不辞劳苦对本人论文的细心审阅，感谢您们的对论文中不足之处进行批评和指正。

最后，向所有曾经关心和帮助自己的人表示由衷的感谢，并致以崇高的敬意。

作者简介 {#作者简介 .-1}
========

##### 基本情况

闫玉华，男，山东济南人，西安电子科技大学计算机学院计算机应用技术专业2014级硕士研究生。

##### 教育背景

2008.09～2012.07 山东科技大学，本科，专业：计算机科学与技术

2014.09～至今 西安电子科技大学，硕士研究生，专业：计算机应用技术

##### 攻读硕士学位期间参与的科研项目

1.  农掌门信息管理系统，2015.07\~2015.10，系统已完成开发，参与系统后台开发。

2.  某部队气象信息管理系统,2015.08\~2016.04，系统已完成开发，参与系统后台开发。
